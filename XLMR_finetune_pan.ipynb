{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyOlJXnvAtms/hR7Z0wSOa/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2bf11afe14504c0781a7fa7c07cbfcee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_433381e211c844669cad84a7ec594169",
              "IPY_MODEL_1c81b0cb46f24708b12a7f88fcfde6d3",
              "IPY_MODEL_3284f4d688e9466b80d7d6f48bffea05"
            ],
            "layout": "IPY_MODEL_8b29592afe014e17b19b49fe0b616718"
          }
        },
        "433381e211c844669cad84a7ec594169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab1d40eb4ba849bbb7c4f5195356c4c2",
            "placeholder": "​",
            "style": "IPY_MODEL_656889a2d5044589ac89bae6c3ee1be1",
            "value": "100%"
          }
        },
        "1c81b0cb46f24708b12a7f88fcfde6d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1d5aa511df547eeab414c798a7788e0",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_180abcbce96d4332be2ea276d97b03ac",
            "value": 3
          }
        },
        "3284f4d688e9466b80d7d6f48bffea05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9bf3094831a944808d063431e46a180c",
            "placeholder": "​",
            "style": "IPY_MODEL_9d6a257b88214ac9a59a434d7fec1a95",
            "value": " 3/3 [00:00&lt;00:00, 191.43it/s]"
          }
        },
        "8b29592afe014e17b19b49fe0b616718": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab1d40eb4ba849bbb7c4f5195356c4c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "656889a2d5044589ac89bae6c3ee1be1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1d5aa511df547eeab414c798a7788e0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "180abcbce96d4332be2ea276d97b03ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9bf3094831a944808d063431e46a180c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d6a257b88214ac9a59a434d7fec1a95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79526ed32928410c843edf773ab49ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ed61e9db22a84f8084ed6dd454d47de9",
              "IPY_MODEL_07766b8a3cb94ed7b5646badc6b10268",
              "IPY_MODEL_201c3da4a45143c6b2db3cc474fa0212"
            ],
            "layout": "IPY_MODEL_4c3128422302490abb62029c9ef6724d"
          }
        },
        "ed61e9db22a84f8084ed6dd454d47de9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e4ec6916a13490988fff0cd7c02ebd7",
            "placeholder": "​",
            "style": "IPY_MODEL_3a50e12d19bf4afabb8fbd3b2f27d431",
            "value": "100%"
          }
        },
        "07766b8a3cb94ed7b5646badc6b10268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b9c7761fd8946fa88727ac5c0b2ee41",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3623138e8f734bbda55bd32f03ad6ca6",
            "value": 3
          }
        },
        "201c3da4a45143c6b2db3cc474fa0212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_147cf949a9954e60bb60ac75f6c60d80",
            "placeholder": "​",
            "style": "IPY_MODEL_5092b83a123341ff95bdc9fd4a702025",
            "value": " 3/3 [00:00&lt;00:00, 175.93it/s]"
          }
        },
        "4c3128422302490abb62029c9ef6724d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4ec6916a13490988fff0cd7c02ebd7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a50e12d19bf4afabb8fbd3b2f27d431": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b9c7761fd8946fa88727ac5c0b2ee41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3623138e8f734bbda55bd32f03ad6ca6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "147cf949a9954e60bb60ac75f6c60d80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5092b83a123341ff95bdc9fd4a702025": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19d19f391f31488d82d5f98ccb472d30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c9f2cf7cf15048f5b1fa29e7cae6b75e",
              "IPY_MODEL_5619e418937747c2bb23ee66917534a7",
              "IPY_MODEL_32728b64f99b47d699c0b8c942fb2163",
              "IPY_MODEL_fd735e7855ee4a0194f5188d912bf9b9",
              "IPY_MODEL_e41754377b274ee19f0a48a6863a15e6"
            ],
            "layout": "IPY_MODEL_4e13e08f0d84428c9198697637bf0a25"
          }
        },
        "c9f2cf7cf15048f5b1fa29e7cae6b75e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3be4d6d48624fccbddf3fd2c1e6d101",
            "placeholder": "​",
            "style": "IPY_MODEL_adad0dafc0aa44938bc83b8236f9e21f",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "5619e418937747c2bb23ee66917534a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_8d1fb831efd340cfbcfe4a168a9af265",
            "placeholder": "​",
            "style": "IPY_MODEL_e2306127cfc84816b459733ac70dbe46",
            "value": ""
          }
        },
        "32728b64f99b47d699c0b8c942fb2163": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_a025a79dbb3b4053ac6227438c8c1580",
            "style": "IPY_MODEL_e7dd974585da4637b835bbb426716756",
            "value": false
          }
        },
        "fd735e7855ee4a0194f5188d912bf9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_08835a7aeff04494a82657034d83881d",
            "style": "IPY_MODEL_dd5e85f4361043f0aba742d3991e80fa",
            "tooltip": ""
          }
        },
        "e41754377b274ee19f0a48a6863a15e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d6ff1e2307e4d2ca5da42bf1d92d48f",
            "placeholder": "​",
            "style": "IPY_MODEL_a5ad016a215c4732a1ae1d5d4f0271fe",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "4e13e08f0d84428c9198697637bf0a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "e3be4d6d48624fccbddf3fd2c1e6d101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "adad0dafc0aa44938bc83b8236f9e21f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d1fb831efd340cfbcfe4a168a9af265": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2306127cfc84816b459733ac70dbe46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a025a79dbb3b4053ac6227438c8c1580": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7dd974585da4637b835bbb426716756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "08835a7aeff04494a82657034d83881d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd5e85f4361043f0aba742d3991e80fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "6d6ff1e2307e4d2ca5da42bf1d92d48f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5ad016a215c4732a1ae1d5d4f0271fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2bd902565da3409cb441dd8d9c1e5fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6c772409b5248a696b7663e604e98ca",
              "IPY_MODEL_f733929bd8aa48e6b7115aacd245a558",
              "IPY_MODEL_6c93104af8a84130988d3716e403a34e"
            ],
            "layout": "IPY_MODEL_b67b4b2ddafd42aeb82021d358ff41dc"
          }
        },
        "f6c772409b5248a696b7663e604e98ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_78e6f3da4ce349dbb065608e703cf566",
            "placeholder": "​",
            "style": "IPY_MODEL_061b2f0f66144553813a0ad856d40cd9",
            "value": "Upload file pytorch_model.bin: 100%"
          }
        },
        "f733929bd8aa48e6b7115aacd245a558": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95581e28744341cfb8e2b425858c2c28",
            "max": 1109920109,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18355ff63cf94f1cb83548bf41fb19ab",
            "value": 1109920109
          }
        },
        "6c93104af8a84130988d3716e403a34e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d7bdf9bfdbf40208861ccf665472ef1",
            "placeholder": "​",
            "style": "IPY_MODEL_41f5d400f65145e58163b9adadee6e43",
            "value": " 1.03G/1.03G [04:18&lt;00:00, 4.73MB/s]"
          }
        },
        "b67b4b2ddafd42aeb82021d358ff41dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78e6f3da4ce349dbb065608e703cf566": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "061b2f0f66144553813a0ad856d40cd9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "95581e28744341cfb8e2b425858c2c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18355ff63cf94f1cb83548bf41fb19ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d7bdf9bfdbf40208861ccf665472ef1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41f5d400f65145e58163b9adadee6e43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4229582572dc44c598064b32c93a95e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4af31c739e2e43f1ba112147911d377b",
              "IPY_MODEL_2717bfca4ff9464298f9c9a01aed3764",
              "IPY_MODEL_ed8f15fe667b43d7ba2fb193573174e2"
            ],
            "layout": "IPY_MODEL_e24eb9a5f3dd46c3b7bb838f498cfa44"
          }
        },
        "4af31c739e2e43f1ba112147911d377b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd21778c05e43678d12839bfc2a0144",
            "placeholder": "​",
            "style": "IPY_MODEL_800aac9c0d4a4344a4f28b082a675c85",
            "value": "Upload file sentencepiece.bpe.model: 100%"
          }
        },
        "2717bfca4ff9464298f9c9a01aed3764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6480352cac5d4817be0b79f6974ea2a8",
            "max": 5069051,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a7b003855c3840238a42d33d8c793307",
            "value": 5069051
          }
        },
        "ed8f15fe667b43d7ba2fb193573174e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4b136e92ea014d5381321e311dff4193",
            "placeholder": "​",
            "style": "IPY_MODEL_812ab68c1726436483bbe36723a469f6",
            "value": " 4.83M/4.83M [04:18&lt;00:00, 5.22MB/s]"
          }
        },
        "e24eb9a5f3dd46c3b7bb838f498cfa44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6dd21778c05e43678d12839bfc2a0144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "800aac9c0d4a4344a4f28b082a675c85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6480352cac5d4817be0b79f6974ea2a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a7b003855c3840238a42d33d8c793307": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4b136e92ea014d5381321e311dff4193": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "812ab68c1726436483bbe36723a469f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4916f09e34d646d68e0e7852a503621c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f01c19169c1d4f22ac84129b2b996619",
              "IPY_MODEL_eaf985d32e484885a828839aaac78e9b",
              "IPY_MODEL_e06590f8e6a34492a0b31530fa420354"
            ],
            "layout": "IPY_MODEL_1a751103c0e24f288db2f8cd9116676d"
          }
        },
        "f01c19169c1d4f22ac84129b2b996619": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_95f825d1965245e8a65838380499d81a",
            "placeholder": "​",
            "style": "IPY_MODEL_d1ba6e38802e4269aa03d0ccdaf2fc66",
            "value": "Upload file training_args.bin: 100%"
          }
        },
        "eaf985d32e484885a828839aaac78e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1813578b10044392b8f0f08559366f22",
            "max": 2875,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_55f9a258f9084e7c90a8e98cee4a83c9",
            "value": 2875
          }
        },
        "e06590f8e6a34492a0b31530fa420354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6897c957756147d68ca2a26714364e5c",
            "placeholder": "​",
            "style": "IPY_MODEL_60d3f1889c3747b7ab99e3f848868254",
            "value": " 2.81k/2.81k [04:18&lt;00:00, 15.3MB/s]"
          }
        },
        "1a751103c0e24f288db2f8cd9116676d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95f825d1965245e8a65838380499d81a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d1ba6e38802e4269aa03d0ccdaf2fc66": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1813578b10044392b8f0f08559366f22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55f9a258f9084e7c90a8e98cee4a83c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6897c957756147d68ca2a26714364e5c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60d3f1889c3747b7ab99e3f848868254": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "509e4199d93942eebdbf99ccb35ee6ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e3a57c4debe45059414d73617aa164e",
              "IPY_MODEL_0ab8083d5d0d4e46bc111366154484fe",
              "IPY_MODEL_af706c4ce1a04c1c9ff6c88dd8eb892e"
            ],
            "layout": "IPY_MODEL_e3def8ec302e46c79e1754c1c7492929"
          }
        },
        "0e3a57c4debe45059414d73617aa164e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38728af8b711466ab7510d5cc4de23d5",
            "placeholder": "​",
            "style": "IPY_MODEL_f7a49df0a6e640b0829419b586097546",
            "value": "Upload file runs/Apr14_14-04-19_7ded55b56291/1681481133.6566057/events.out.tfevents.1681481133.7ded55b56291.48074.13: 100%"
          }
        },
        "0ab8083d5d0d4e46bc111366154484fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7f9289e5e954791a1183873a3844ee1",
            "max": 4612,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e75f9345347c4ad29ec3c4ab451be13c",
            "value": 4612
          }
        },
        "af706c4ce1a04c1c9ff6c88dd8eb892e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_39555820013f45a1a0ef8fc72fd462f3",
            "placeholder": "​",
            "style": "IPY_MODEL_b4714e1f4c41437f99beb37fb7b832f0",
            "value": " 4.50k/4.50k [04:18&lt;00:00, 15.6MB/s]"
          }
        },
        "e3def8ec302e46c79e1754c1c7492929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38728af8b711466ab7510d5cc4de23d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7a49df0a6e640b0829419b586097546": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b7f9289e5e954791a1183873a3844ee1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e75f9345347c4ad29ec3c4ab451be13c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "39555820013f45a1a0ef8fc72fd462f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4714e1f4c41437f99beb37fb7b832f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0ce179a36504419da80fc25372613d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1c76b4f7792d496e8b10eb821a2b44ea",
              "IPY_MODEL_d39cf3cdfd6544d6b40313de8290efd1",
              "IPY_MODEL_ba1e9472a2f74ee0989061b3aab83e1d"
            ],
            "layout": "IPY_MODEL_3909d3f91ff243328a1700c528114cfa"
          }
        },
        "1c76b4f7792d496e8b10eb821a2b44ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_deccb00a6c68446ea717cedd3bea350e",
            "placeholder": "​",
            "style": "IPY_MODEL_7e4ce39479564642a30b389132747de2",
            "value": "Upload file runs/Apr14_14-04-19_7ded55b56291/events.out.tfevents.1681481133.7ded55b56291.48074.12: 100%"
          }
        },
        "d39cf3cdfd6544d6b40313de8290efd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed5e341c847a41d2afdbf214864ae88a",
            "max": 69310,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b64e166771cb4b0c92e9dd454ac463dc",
            "value": 69310
          }
        },
        "ba1e9472a2f74ee0989061b3aab83e1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20eae14efe634a549b3e1dd0c8103a05",
            "placeholder": "​",
            "style": "IPY_MODEL_6edc9187e5fb431782e53814dceab32a",
            "value": " 67.7k/67.7k [04:18&lt;00:00, 15.7MB/s]"
          }
        },
        "3909d3f91ff243328a1700c528114cfa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "deccb00a6c68446ea717cedd3bea350e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e4ce39479564642a30b389132747de2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed5e341c847a41d2afdbf214864ae88a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64e166771cb4b0c92e9dd454ac463dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20eae14efe634a549b3e1dd0c8103a05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6edc9187e5fb431782e53814dceab32a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/marendtz/TransformerNER/blob/master/code_snippets_XLMRforTC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Preparations**"
      ],
      "metadata": {
        "id": "8wOOf8-SYD1I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#clean up model\n",
        "import shutil\n",
        "try:\n",
        "  shutil.rmtree('/content/xlm-roberta-base-finetuned-panx-en')\n",
        "except:\n",
        "  print(\"no such folder\")"
      ],
      "metadata": {
        "id": "xvQSqB5SxNFY"
      },
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "#get github access token for collab\n",
        "token = getpass.getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWCm19HMZAFN",
        "outputId": "6cd568bb-d215-4dd0-c2bc-e78c06a5f8b7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/\n",
        "%rm -r /content/*\n",
        "%ls -la\n",
        "%pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "id": "FesltGt6VmIW",
        "outputId": "58217ec1-eb31-4054-9457-9409a9b29d6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "total 16\n",
            "drwxr-xr-x 1 root root 4096 Apr 14 12:45 \u001b[0m\u001b[01;34m.\u001b[0m/\n",
            "drwxr-xr-x 1 root root 4096 Apr 14 09:21 \u001b[01;34m..\u001b[0m/\n",
            "drwxr-xr-x 4 root root 4096 Apr 12 13:33 \u001b[01;34m.config\u001b[0m/\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# clone github repo\n",
        "!git clone https://{token}@github.com/marendtz/TransformerNER.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XEyMOa-KU2o4",
        "outputId": "22c5a7d6-6d1e-4a66-f64b-82740f9d1793"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'TransformerNER'...\n",
            "remote: Enumerating objects: 57, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (51/51), done.\u001b[K\n",
            "remote: Total 57 (delta 24), reused 18 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (57/57), 113.65 KiB | 270.00 KiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -r /content/TransformerNER/requirements.txt\n"
      ],
      "metadata": {
        "id": "LVCEfji7V_NF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e97264b-d805-4e7f-e360-2e4f2515a2d6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3 in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 1)) (4.11.3)\n",
            "Requirement already satisfied: datasets[audio]==1.16.1 in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 2)) (1.16.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 3)) (3.7.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 4)) (1.5.3)\n",
            "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 5)) (7.7.1)\n",
            "Requirement already satisfied: seqeval==1.2.2 in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.9/dist-packages (from -r /content/TransformerNER/requirements.txt (line 7)) (0.2.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.11.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.27.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2022.10.31)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.0.53)\n",
            "Requirement already satisfied: huggingface-hub>=0.0.17 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.13.4)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.10.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (6.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.22.4)\n",
            "Requirement already satisfied: tensorflow>=2.3 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.12.0)\n",
            "Requirement already satisfied: onnxconverter-common in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.13.0)\n",
            "Requirement already satisfied: keras2onnx in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: optuna in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.20.3)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92,>=0.1.91 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.1.98)\n",
            "Requirement already satisfied: onnxruntime>=1.4.0 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: onnxruntime-tools>=1.4.2 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.7.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.2.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (8.4.0)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.9/dist-packages (from transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.0.0+cu118)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.70.14)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (3.2.0)\n",
            "Requirement already satisfied: pyarrow!=4.0.0,>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (9.0.0)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (3.8.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.3.6)\n",
            "Requirement already satisfied: librosa in /usr/local/lib/python3.9/dist-packages (from datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.10.0.post2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (4.39.3)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (1.0.7)\n",
            "Requirement already satisfied: importlib-resources>=3.2.0 in /usr/local/lib/python3.9/dist-packages (from matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (5.12.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.9/dist-packages (from pandas->-r /content/TransformerNER/requirements.txt (line 4)) (2022.7.1)\n",
            "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (3.0.7)\n",
            "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (3.6.4)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (7.34.0)\n",
            "Requirement already satisfied: ipykernel>=4.5.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (5.5.6)\n",
            "Requirement already satisfied: traitlets>=4.3.1 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (5.7.1)\n",
            "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.9/dist-packages (from ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.9/dist-packages (from evaluate->-r /content/TransformerNER/requirements.txt (line 7)) (0.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (6.0.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.3.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (22.2.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.8.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.9/dist-packages (from aiohttp->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.9/dist-packages (from huggingface-hub>=0.0.17->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (4.5.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in /usr/local/lib/python3.9/dist-packages (from importlib-resources>=3.2.0->matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (3.15.0)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (6.1.12)\n",
            "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.9/dist-packages (from ipykernel>=4.5.1->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (6.2)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (4.8.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (2.14.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (67.6.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.1.6)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.18.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (3.0.38)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.9/dist-packages (from ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (4.4.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.4.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.11.1)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.4.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.9/dist-packages (from onnxruntime>=1.4.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (23.3.3)\n",
            "Requirement already satisfied: onnx in /usr/local/lib/python3.9/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.13.1)\n",
            "Requirement already satisfied: py-cpuinfo in /usr/local/lib/python3.9/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (9.0.0)\n",
            "Requirement already satisfied: py3nvml in /usr/local/lib/python3.9/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.2.7)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.9/dist-packages (from onnxruntime-tools>=1.4.2->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (5.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.9/dist-packages (from python-dateutil>=2.7->matplotlib->-r /content/TransformerNER/requirements.txt (line 3)) (1.16.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.26.15)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-learn->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.6.3)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.53.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.2.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (16.0.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.12.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.8.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.32.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.14.1)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.4.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch>=1.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.0.0)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (16.0.1)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch>=1.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.25.2)\n",
            "Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.9/dist-packages (from widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (6.4.8)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.9/dist-packages (from keras2onnx->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.5.0)\n",
            "Requirement already satisfied: pooch<1.7,>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.6.0)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.56.4)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.3.5)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.2)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.9/dist-packages (from librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (3.0.0)\n",
            "Requirement already satisfied: cmaes>=0.9.1 in /usr/local/lib/python3.9/dist-packages (from optuna->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.9.1)\n",
            "Requirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.9/dist-packages (from optuna->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.10.3)\n",
            "Requirement already satisfied: colorlog in /usr/local/lib/python3.9/dist-packages (from optuna->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (6.7.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from optuna->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.0.9)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from sacremoses->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (8.1.3)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.9/dist-packages (from alembic>=1.5.0->optuna->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.2.4)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.0.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from jedi>=0.16->ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.8.3)\n",
            "Requirement already satisfied: argon2-cffi in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (21.3.0)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (6.5.4)\n",
            "Requirement already satisfied: Send2Trash>=1.8.0 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (1.8.0)\n",
            "Requirement already satisfied: terminado>=0.8.3 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.17.1)\n",
            "Requirement already satisfied: prometheus-client in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.16.0)\n",
            "Requirement already satisfied: jupyter-core>=4.6.1 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (5.3.0)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (23.2.1)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (5.8.0)\n",
            "Requirement already satisfied: nest-asyncio>=1.5 in /usr/local/lib/python3.9/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (1.5.6)\n",
            "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /usr/local/lib/python3.9/dist-packages (from numba>=0.51.0->librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (0.39.1)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.9/dist-packages (from pexpect>4.3->ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.7.0)\n",
            "Requirement already satisfied: appdirs>=1.3.0 in /usr/local/lib/python3.9/dist-packages (from pooch<1.7,>=1.0->librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.4.4)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=4.0.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.2.6)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.9/dist-packages (from soundfile>=0.12.1->librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (1.15.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.9/dist-packages (from sqlalchemy>=1.3.0->optuna->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.4.3)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.2.3)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.8.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.17.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.9/dist-packages (from coloredlogs->onnxruntime>=1.4.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (10.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch>=1.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (2.1.2)\n",
            "Requirement already satisfied: xmltodict in /usr/local/lib/python3.9/dist-packages (from py3nvml->onnxruntime-tools>=1.4.2->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.13.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->onnxruntime>=1.4.0->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.9/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa->datasets[audio]==1.16.1->-r /content/TransformerNER/requirements.txt (line 2)) (2.21)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.9/dist-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (3.2.0)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (6.3.0)\n",
            "Requirement already satisfied: argon2-cffi-bindings in /usr/local/lib/python3.9/dist-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (21.2.0)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: nbclient>=0.5.0 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.7.3)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (1.5.0)\n",
            "Requirement already satisfied: tinycss2 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (1.2.1)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.8.4)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (4.9.2)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (6.0.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (4.11.2)\n",
            "Requirement already satisfied: jupyterlab-pygments in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.2.2)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.9/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.7.1)\n",
            "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (2.16.3)\n",
            "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.9/dist-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (4.3.3)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.9/dist-packages (from jsonschema>=2.6->nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.19.3)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow>=2.3->transformers[onnxruntime,optuna,sentencepiece,sklearn,tf,torch,vision]==4.11.3->-r /content/TransformerNER/requirements.txt (line 1)) (3.2.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.9/dist-packages (from beautifulsoup4->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (2.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.9/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.6.0->ipywidgets->-r /content/TransformerNER/requirements.txt (line 5)) (0.5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import defaultdict\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datasets import load_dataset_builder, get_dataset_config_names, load_dataset, DatasetDict\n",
        "\n",
        "from transformers import AutoTokenizer, TrainingArguments, DataCollatorForTokenClassification, Trainer\n",
        "import nltk.data\n",
        "nltk.download('punkt')\n",
        "\n",
        "import torch.nn as nn\n",
        "from transformers import XLMRobertaConfig, AutoConfig, XLMRobertaForTokenClassification\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "\n",
        "from huggingface_hub import notebook_login\n",
        "from seqeval.metrics import f1_score, precision_score, recall_score, accuracy_score, classification_report\n",
        "from seqeval.scheme import IOB2\n",
        "\n",
        "\n",
        "from torch.nn.functional import cross_entropy\n",
        "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hJjfwslMYSNs",
        "outputId": "0d49ecb0-c268-4d76-c415-d58bbcd860e1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get test data and tokenise as example**"
      ],
      "metadata": {
        "id": "QuY8E4A4ebYr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# setup for tokenization\n",
        "xlmr_model_name = \"xlm-roberta-base\"\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
      ],
      "metadata": {
        "id": "mzLgy7j4YqoW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get company text \n",
        "with open('/content/TransformerNER/data/adidas_2022.txt', 'r') as file:\n",
        "    data_text = file.read()\n",
        "# split company text into sentenques: str --> list[string]\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
        "sentence_list=tokenizer.tokenize(data_text)\n",
        "print(sentence_list)\n",
        "print(sentence_list[0])"
      ],
      "metadata": {
        "id": "hWyfOFU_fcuj",
        "outputId": "c91521eb-46db-48b0-ca46-9df01e91b923",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Our commitment to sustainability is embedded into how we have done business for over two decades.', 'It is rooted in our purpose ‘Through sport, we have the power to change lives.’ In 2021, we have doubled\\ndown on our commitment to sustainability and defined a roadmap for 2025 and beyond that allows us to\\ncreate a positive impact across relevant areas, always focusing on the most material topics – for us and\\nour stakeholders.', 'We will continue to move to a comprehensive, consumer-facing sustainable article\\noffering at scale, expand our circular services, and work toward achieving climate neutrality (CO2e) across\\nour entire value chain.', 'We continue to empower our employees to become sustainability ambassadors,\\njust as we invite consumers globally to engage and connect with us on the topic of sustainability.', 'Lastly, we\\naim to uphold the highest social compliance standards in our supply chain.', 'We believe that moving toward achieving the targets we have defined for 2025 will set us up for future\\nsuccess.', 'Yet we know that we cannot achieve these alone.', 'We will leverage our long-term relationships\\nwith suppliers to ensure they can continue moving with us in alignment with our decarbonization efforts,\\nand work closely with partners to scale innovative materials and recycling technologies.', 'A robust governance structure ensures timely and direct execution of programs that drive the\\nachievement of our set of targets for 2025 and beyond.', 'The head of Sustainability reports directly to the\\nmember of the Executive Board responsible for Global Operations, who is responsible for the\\ndevelopment, coordination, and execution of our sustainability strategy and also leads the ‘Sustainability\\nSponsor Board,’ which is composed of senior representatives from Global Brands, Global Operations,\\nDigital, Sales, and other relevant functions across the company.', 'The ‘Sustainability Sponsor Board’\\nensures cross-functional alignment, transparent end-to-end management, and execution of agreed-upon\\nsustainability goals within their functions.', 'This includes reviewing and signing-off on policies as required.', 'We also maintain a separate compliance function which is operated as the Social and Environmental\\nAffairs (‘SEA’) Team to evaluate supplier-facing social and environmental compliance performance and\\nhuman rights impacts, reporting, through the General Counsel, to the CEO.', 'We have set up regular sustainability networking calls for all employees involved in sustainability projects\\nand programs in the organization to ensure company-wide alignment on all levels.', 'On top of this, adidas\\ncontinued to offer the company-wide sustainability training program available to all employees, educating\\nthem on how to think and act sustainably, enabling them to become sustainability ambassadors, and\\nencouraging everyone to make personal and professional commitments to contribute to a cleaner planet.', 'We also initiated sustainability training for our retail colleagues, with the objective of informing, engaging,\\nand inspiring our entire team and all consumers we interact with on a daily basis, around the globe.', 'Throughout 2022, adidas conducted a full-scope materiality analysis to confirm non-financial topics\\nrelevant to the company’s external reporting.', 'The process was based on existing and future regulatory\\ndisclosure requirements applicable to adidas.', \"These requirements, in combination with existing material\\ntopics, were the starting point for creating a long list of potentially material ESG ('environmental, social,\\nand governance’) topics.\", 'In a series of workshops with internal stakeholders, including responsible\\nexperts and senior management of relevant functions, we identified and validated related impacts, risks\\nand opportunities for these topics.', 'The analysis was carried out from an impact materiality perspective as\\nwell as from a financial materiality perspective, each of which was assessed both qualitatively and\\nquantitatively.', 'This has ultimately led us to form a two-dimensional materiality matrix and a list of\\nmaterial topics, which forms the basis of the non-financial statement presented in this report.', 'Notably, all\\nexisting material topics were fully confirmed.', 'The topic of biodiversity was identified as a new material\\ntopic.', 'Engaging openly with stakeholders and establishing ways to increase transparency and disclosure has\\nlong been central to our approach.', 'Our stakeholders are those people or organizations who affect or are\\naffected by our operations, including our employees, consumers, suppliers and their workers, customers,\\ninvestors, media, governments, and NGOs.', 'The adidas ‘Stakeholder Relations Guideline’ specifies key\\nprinciples for the development of stakeholder relations and details the different forms of stakeholder\\nengagement.', 'adidas participates in a variety of industry associations, multi-stakeholder organizations, and\\nnon-profit initiatives.', 'Through these memberships, we work closely with leading companies from different\\nsectors to develop sustainable business approaches and debate social and environmental topics on a\\nglobal, regional, and local level.', 'We use collaborations and partnerships to build leverage for systemic\\nchange in our industry, such as for efforts to mitigate the carbon footprint in our industry’s supply chain, to\\nstrengthen chemical management practices, and to raise social and environmental standards in the textile\\nand leather supply chain.', 'In addition, we build awareness, capacity, and knowledge of laws and rights\\namong factory management and workers by partnering with leading providers such as the International\\nLabour Organization’s (‘ILO’) ‘Better Work’ program, as well as with the United Nations International\\nOrganization for Migration (‘IOM’) with the objective of ensuring that the labor rights of foreign and migrant\\nworkers are upheld in the adidas supply chain.']\n",
            "Our commitment to sustainability is embedded into how we have done business for over two decades.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sentence in sentence_list:\n",
        "  xlmr_tokens = xlmr_tokenizer(sentence).tokens()\n",
        "  print(xlmr_tokens)"
      ],
      "metadata": {
        "id": "QGay0Y8kfYJi",
        "outputId": "dd4e93c2-dbe1-4249-b8cd-ecc87d29ca2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '▁Our', '▁commitment', '▁to', '▁sustain', 'ability', '▁is', '▁', 'embe', 'dded', '▁into', '▁how', '▁we', '▁have', '▁done', '▁business', '▁for', '▁over', '▁two', '▁de', 'cade', 's', '.', '</s>']\n",
            "['<s>', '▁It', '▁is', '▁root', 'ed', '▁in', '▁our', '▁purpose', '▁‘', 'Th', 'r', 'ough', '▁sport', ',', '▁we', '▁have', '▁the', '▁power', '▁to', '▁change', '▁lives', '.', '’', '▁In', '▁2021', ',', '▁we', '▁have', '▁double', 'd', '▁down', '▁on', '▁our', '▁commitment', '▁to', '▁sustain', 'ability', '▁and', '▁define', 'd', '▁a', '▁road', 'map', '▁for', '▁2025', '▁and', '▁beyond', '▁that', '▁allows', '▁us', '▁to', '▁create', '▁a', '▁positive', '▁impact', '▁across', '▁relevant', '▁areas', ',', '▁always', '▁focus', 'ing', '▁on', '▁the', '▁most', '▁material', '▁topic', 's', '▁–', '▁for', '▁us', '▁and', '▁our', '▁stake', 'holder', 's', '.', '</s>']\n",
            "['<s>', '▁We', '▁will', '▁continue', '▁to', '▁move', '▁to', '▁a', '▁comprehensive', ',', '▁consumer', '-', 'fac', 'ing', '▁sustainable', '▁article', '▁offering', '▁at', '▁scale', ',', '▁expand', '▁our', '▁circular', '▁services', ',', '▁and', '▁work', '▁toward', '▁a', 'chie', 'ving', '▁climate', '▁neutral', 'ity', '▁(', 'CO', '2', 'e', ')', '▁across', '▁our', '▁entire', '▁value', '▁chain', '.', '</s>']\n",
            "['<s>', '▁We', '▁continue', '▁to', '▁em', 'power', '▁our', '▁employees', '▁to', '▁become', '▁sustain', 'ability', '▁amb', 'assa', 'dors', ',', '▁just', '▁as', '▁we', '▁invite', '▁consumer', 's', '▁global', 'ly', '▁to', '▁engage', '▁and', '▁connect', '▁with', '▁us', '▁on', '▁the', '▁topic', '▁of', '▁sustain', 'ability', '.', '</s>']\n",
            "['<s>', '▁Last', 'ly', ',', '▁we', '▁a', 'im', '▁to', '▁up', 'hold', '▁the', '▁highest', '▁social', '▁compliance', '▁standard', 's', '▁in', '▁our', '▁supply', '▁chain', '.', '</s>']\n",
            "['<s>', '▁We', '▁believe', '▁that', '▁moving', '▁toward', '▁a', 'chie', 'ving', '▁the', '▁target', 's', '▁we', '▁have', '▁define', 'd', '▁for', '▁2025', '▁will', '▁set', '▁us', '▁up', '▁for', '▁future', '▁success', '.', '</s>']\n",
            "['<s>', '▁Yet', '▁we', '▁know', '▁that', '▁we', '▁cannot', '▁achieve', '▁these', '▁alone', '.', '</s>']\n",
            "['<s>', '▁We', '▁will', '▁lever', 'age', '▁our', '▁long', '-', 'term', '▁relationships', '▁with', '▁supplier', 's', '▁to', '▁ensure', '▁they', '▁can', '▁continue', '▁moving', '▁with', '▁us', '▁in', '▁', 'align', 'ment', '▁with', '▁our', '▁de', 'car', 'bon', 'ization', '▁efforts', ',', '▁and', '▁work', '▁close', 'ly', '▁with', '▁partners', '▁to', '▁scale', '▁innovative', '▁materials', '▁and', '▁re', 'cycling', '▁technologies', '.', '</s>']\n",
            "['<s>', '▁A', '▁robust', '▁govern', 'ance', '▁structure', '▁ensure', 's', '▁time', 'ly', '▁and', '▁direct', '▁execut', 'ion', '▁of', '▁programs', '▁that', '▁drive', '▁the', '▁achieve', 'ment', '▁of', '▁our', '▁set', '▁of', '▁target', 's', '▁for', '▁2025', '▁and', '▁beyond', '.', '</s>']\n",
            "['<s>', '▁The', '▁head', '▁of', '▁Sus', 'tain', 'ability', '▁reports', '▁directly', '▁to', '▁the', '▁member', '▁of', '▁the', '▁Executive', '▁Board', '▁responsible', '▁for', '▁Global', '▁Operation', 's', ',', '▁who', '▁is', '▁responsible', '▁for', '▁the', '▁development', ',', '▁coordina', 'tion', ',', '▁and', '▁execut', 'ion', '▁of', '▁our', '▁sustain', 'ability', '▁strategy', '▁and', '▁also', '▁lead', 's', '▁the', '▁‘', 'S', 'usta', 'in', 'ability', '▁Sponsor', '▁Board', ',', '’', '▁which', '▁is', '▁compose', 'd', '▁of', '▁senior', '▁representativ', 'es', '▁from', '▁Global', '▁Brand', 's', ',', '▁Global', '▁Operation', 's', ',', '▁Digital', ',', '▁Sales', ',', '▁and', '▁other', '▁relevant', '▁function', 's', '▁across', '▁the', '▁company', '.', '</s>']\n",
            "['<s>', '▁The', '▁‘', 'S', 'usta', 'in', 'ability', '▁Sponsor', '▁Board', '’', '▁ensure', 's', '▁cross', '-', 'function', 'al', '▁', 'align', 'ment', ',', '▁transparent', '▁end', '-', 'to', '-', 'end', '▁management', ',', '▁and', '▁execut', 'ion', '▁of', '▁agreed', '-', 'u', 'pon', '▁sustain', 'ability', '▁goals', '▁within', '▁their', '▁function', 's', '.', '</s>']\n",
            "['<s>', '▁This', '▁includes', '▁review', 'ing', '▁and', '▁sig', 'ning', '-', 'off', '▁on', '▁policies', '▁as', '▁required', '.', '</s>']\n",
            "['<s>', '▁We', '▁also', '▁maintain', '▁a', '▁separate', '▁compliance', '▁function', '▁which', '▁is', '▁operate', 'd', '▁as', '▁the', '▁Social', '▁and', '▁Environmental', '▁Affairs', '▁(', '‘', 'SE', 'A', '’', ')', '▁Team', '▁to', '▁evaluat', 'e', '▁supplier', '-', 'fac', 'ing', '▁social', '▁and', '▁environmental', '▁compliance', '▁performance', '▁and', '▁human', '▁rights', '▁impact', 's', ',', '▁report', 'ing', ',', '▁through', '▁the', '▁General', '▁Co', 'un', 'sel', ',', '▁to', '▁the', '▁CEO', '.', '</s>']\n",
            "['<s>', '▁We', '▁have', '▁set', '▁up', '▁regular', '▁sustain', 'ability', '▁networking', '▁call', 's', '▁for', '▁all', '▁employees', '▁involved', '▁in', '▁sustain', 'ability', '▁projects', '▁and', '▁programs', '▁in', '▁the', '▁organization', '▁to', '▁ensure', '▁company', '-', 'wide', '▁', 'align', 'ment', '▁on', '▁all', '▁levels', '.', '</s>']\n",
            "['<s>', '▁On', '▁top', '▁of', '▁this', ',', '▁adidas', '▁continued', '▁to', '▁offer', '▁the', '▁company', '-', 'wide', '▁sustain', 'ability', '▁training', '▁program', '▁available', '▁to', '▁all', '▁employees', ',', '▁educat', 'ing', '▁them', '▁on', '▁how', '▁to', '▁think', '▁and', '▁act', '▁sustain', 'ably', ',', '▁en', 'a', 'bling', '▁them', '▁to', '▁become', '▁sustain', 'ability', '▁amb', 'assa', 'dors', ',', '▁and', '▁en', 'cour', 'aging', '▁everyone', '▁to', '▁make', '▁personal', '▁and', '▁professional', '▁commitment', 's', '▁to', '▁contribute', '▁to', '▁a', '▁clean', 'er', '▁planet', '.', '</s>']\n",
            "['<s>', '▁We', '▁also', '▁initiat', 'ed', '▁sustain', 'ability', '▁training', '▁for', '▁our', '▁retail', '▁colleagues', ',', '▁with', '▁the', '▁objective', '▁of', '▁inform', 'ing', ',', '▁enga', 'ging', ',', '▁and', '▁inspir', 'ing', '▁our', '▁entire', '▁team', '▁and', '▁all', '▁consumer', 's', '▁we', '▁interact', '▁with', '▁on', '▁a', '▁daily', '▁basis', ',', '▁around', '▁the', '▁glob', 'e', '.', '</s>']\n",
            "['<s>', '▁Through', 'out', '▁2022', ',', '▁adidas', '▁conduct', 'ed', '▁a', '▁full', '-', 'scope', '▁material', 'ity', '▁analysis', '▁to', '▁confirm', '▁non', '-', 'financi', 'al', '▁topic', 's', '▁relevant', '▁to', '▁the', '▁company', '’', 's', '▁external', '▁report', 'ing', '.', '</s>']\n",
            "['<s>', '▁The', '▁process', '▁was', '▁based', '▁on', '▁existing', '▁and', '▁future', '▁regulator', 'y', '▁dis', 'closure', '▁requirements', '▁applicable', '▁to', '▁adidas', '.', '</s>']\n",
            "['<s>', '▁These', '▁requirements', ',', '▁in', '▁combination', '▁with', '▁existing', '▁material', '▁topic', 's', ',', '▁were', '▁the', '▁starting', '▁point', '▁for', '▁creating', '▁a', '▁long', '▁list', '▁of', '▁potential', 'ly', '▁material', '▁ES', 'G', '▁(', \"'\", 'environ', 'mental', ',', '▁social', ',', '▁and', '▁govern', 'ance', '’', ')', '▁topic', 's', '.', '</s>']\n",
            "['<s>', '▁In', '▁a', '▁series', '▁of', '▁workshops', '▁with', '▁internal', '▁stake', 'holder', 's', ',', '▁including', '▁responsible', '▁experts', '▁and', '▁senior', '▁management', '▁of', '▁relevant', '▁function', 's', ',', '▁we', '▁identified', '▁and', '▁valida', 'ted', '▁related', '▁impact', 's', ',', '▁risk', 's', '▁and', '▁opportunities', '▁for', '▁these', '▁topic', 's', '.', '</s>']\n",
            "['<s>', '▁The', '▁analysis', '▁was', '▁carried', '▁out', '▁from', '▁an', '▁impact', '▁material', 'ity', '▁perspective', '▁as', '▁well', '▁as', '▁from', '▁a', '▁financial', '▁material', 'ity', '▁perspective', ',', '▁each', '▁of', '▁which', '▁was', '▁assess', 'ed', '▁both', '▁qualitativ', 'ely', '▁and', '▁quantitat', 'ive', 'ly', '.', '</s>']\n",
            "['<s>', '▁This', '▁has', '▁ultima', 'tely', '▁led', '▁us', '▁to', '▁form', '▁a', '▁two', '-', 'dimensional', '▁material', 'ity', '▁matri', 'x', '▁and', '▁a', '▁list', '▁of', '▁material', '▁topic', 's', ',', '▁which', '▁form', 's', '▁the', '▁basis', '▁of', '▁the', '▁non', '-', 'financi', 'al', '▁statement', '▁presente', 'd', '▁in', '▁this', '▁report', '.', '</s>']\n",
            "['<s>', '▁Not', 'ably', ',', '▁all', '▁existing', '▁material', '▁topic', 's', '▁were', '▁fully', '▁confirm', 'ed', '.', '</s>']\n",
            "['<s>', '▁The', '▁topic', '▁of', '▁', 'biodiversi', 'ty', '▁was', '▁identified', '▁as', '▁a', '▁new', '▁material', '▁topic', '.', '</s>']\n",
            "['<s>', '▁Eng', 'aging', '▁open', 'ly', '▁with', '▁stake', 'holder', 's', '▁and', '▁establish', 'ing', '▁ways', '▁to', '▁increase', '▁trans', 'pare', 'ncy', '▁and', '▁dis', 'closure', '▁has', '▁long', '▁been', '▁central', '▁to', '▁our', '▁approach', '.', '</s>']\n",
            "['<s>', '▁Our', '▁stake', 'holder', 's', '▁are', '▁those', '▁people', '▁or', '▁organization', 's', '▁who', '▁affect', '▁or', '▁are', '▁affected', '▁by', '▁our', '▁operation', 's', ',', '▁including', '▁our', '▁employees', ',', '▁consumer', 's', ',', '▁supplier', 's', '▁and', '▁their', '▁workers', ',', '▁customers', ',', '▁investor', 's', ',', '▁media', ',', '▁government', 's', ',', '▁and', '▁NGO', 's', '.', '</s>']\n",
            "['<s>', '▁The', '▁adidas', '▁‘', 'Sta', 'ke', 'holder', '▁Relation', 's', '▁Guide', 'line', '’', '▁specifi', 'es', '▁key', '▁princip', 'les', '▁for', '▁the', '▁development', '▁of', '▁stake', 'holder', '▁relations', '▁and', '▁details', '▁the', '▁different', '▁form', 's', '▁of', '▁stake', 'holder', '▁engagement', '.', '</s>']\n",
            "['<s>', '▁adidas', '▁participat', 'es', '▁in', '▁a', '▁variety', '▁of', '▁industry', '▁associations', ',', '▁multi', '-', 'sta', 'ke', 'holder', '▁organization', 's', ',', '▁and', '▁non', '-', 'profit', '▁initiative', 's', '.', '</s>']\n",
            "['<s>', '▁Through', '▁these', '▁membership', 's', ',', '▁we', '▁work', '▁close', 'ly', '▁with', '▁leading', '▁companies', '▁from', '▁different', '▁sector', 's', '▁to', '▁develop', '▁sustainable', '▁business', '▁approach', 'es', '▁and', '▁debate', '▁social', '▁and', '▁environmental', '▁topic', 's', '▁on', '▁a', '▁global', ',', '▁regional', ',', '▁and', '▁local', '▁level', '.', '</s>']\n",
            "['<s>', '▁We', '▁use', '▁collaboration', 's', '▁and', '▁partnership', 's', '▁to', '▁build', '▁lever', 'age', '▁for', '▁system', 'ic', '▁change', '▁in', '▁our', '▁industry', ',', '▁such', '▁as', '▁for', '▁efforts', '▁to', '▁mit', 'iga', 'te', '▁the', '▁carbon', '▁foot', 'print', '▁in', '▁our', '▁industry', '’', 's', '▁supply', '▁chain', ',', '▁to', '▁strength', 'en', '▁chemical', '▁management', '▁practice', 's', ',', '▁and', '▁to', '▁raise', '▁social', '▁and', '▁environmental', '▁standard', 's', '▁in', '▁the', '▁textil', 'e', '▁and', '▁leath', 'er', '▁supply', '▁chain', '.', '</s>']\n",
            "['<s>', '▁In', '▁addition', ',', '▁we', '▁build', '▁awareness', ',', '▁capacity', ',', '▁and', '▁knowledge', '▁of', '▁laws', '▁and', '▁rights', '▁among', '▁factor', 'y', '▁management', '▁and', '▁workers', '▁by', '▁partner', 'ing', '▁with', '▁leading', '▁provider', 's', '▁such', '▁as', '▁the', '▁International', '▁La', 'bour', '▁Organization', '’', 's', '▁(', '‘', 'ILO', '’', ')', '▁‘', 'Be', 'tter', '▁Work', '’', '▁program', ',', '▁as', '▁well', '▁as', '▁with', '▁the', '▁United', '▁Nations', '▁International', '▁Organization', '▁for', '▁Migration', '▁(', '‘', 'IO', 'M', '’', ')', '▁with', '▁the', '▁objective', '▁of', '▁en', 's', 'uring', '▁that', '▁the', '▁labor', '▁rights', '▁of', '▁foreign', '▁and', '▁migrant', '▁workers', '▁are', '▁up', 'held', '▁in', '▁the', '▁adidas', '▁supply', '▁chain', '.', '</s>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "xlmr_tokenizer.encode(sentence_list[-1], return_tensors=\"pt\")\n"
      ],
      "metadata": {
        "id": "80xGJkHsqFkB",
        "outputId": "528ba844-5797-45e5-f767-23a6569cbd21",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[     0,    360,  66044,      4,    642,  45367, 188926,      4, 177399,\n",
              "              4,    136,  51359,    111, 131703,    136,  38109,  54940,  31461,\n",
              "             53,  24365,    136, 133325,    390,   4755,    214,    678, 105207,\n",
              "          81450,      7,   6044,    237,     70,   8357,    239,  38648, 173101,\n",
              "             26,      7,     15,    371, 107078,     26,     16,    204,   6766,\n",
              "           3055,  27985,     26,   1528,      4,    237,   5299,    237,    678,\n",
              "             70,  14098, 145704,   8357, 173101,    100, 180809,     15,    371,\n",
              "          17780,    594,     26,     16,    678,     70, 151814,    111,     22,\n",
              "              7,  53089,    450,     70,  18940,  38109,    111, 110613,    136,\n",
              "          43017, 133325,    621,   1257, 100038,     23,     70, 144585, 100677,\n",
              "         121293,      5,      2]])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Get already defined model class XLMRobertaForTokenClassification and supply own config + test output with random weights**"
      ],
      "metadata": {
        "id": "SBjlIajWX_VM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "\n",
        "# get info from dataset later used for training our model\n",
        "# load dataset to get the tags used, so we later take the same...\n",
        "lang = \"en\"\n",
        "ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
        "tags = ds[\"train\"].features[\"ner_tags\"].feature\n",
        "print(tags)\n",
        "\n",
        "# generate function to convert name and id of tags\n",
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}\n",
        "print(index2tag)\n",
        "print(tag2index)"
      ],
      "metadata": {
        "id": "M9NikK7Hh-36",
        "outputId": "dd49e7c3-d4c8-4680-d49f-ba7dff62b1c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 142,
          "referenced_widgets": [
            "2bf11afe14504c0781a7fa7c07cbfcee",
            "433381e211c844669cad84a7ec594169",
            "1c81b0cb46f24708b12a7f88fcfde6d3",
            "3284f4d688e9466b80d7d6f48bffea05",
            "8b29592afe014e17b19b49fe0b616718",
            "ab1d40eb4ba849bbb7c4f5195356c4c2",
            "656889a2d5044589ac89bae6c3ee1be1",
            "f1d5aa511df547eeab414c798a7788e0",
            "180abcbce96d4332be2ea276d97b03ac",
            "9bf3094831a944808d063431e46a180c",
            "9d6a257b88214ac9a59a434d7fec1a95"
          ]
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset xtreme (/root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bf11afe14504c0781a7fa7c07cbfcee"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None)\n",
            "{0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG', 5: 'B-LOC', 6: 'I-LOC'}\n",
            "{'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4, 'B-LOC': 5, 'I-LOC': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# hide_output\n",
        "\n",
        "# create model\n",
        "import torch\n",
        "\n",
        "# passing keyword arguments to the from_pretrained() method overrides default values\n",
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,num_labels=tags.num_classes, id2label=index2tag, label2id=tag2index)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "print(device)\n",
        "xlmr_model = (XLMRobertaForTokenClassification\n",
        "                .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
        "                .to(device))"
      ],
      "metadata": {
        "id": "JGTLBk-1nT3B",
        "outputId": "90b1ac0a-b814-4853-a2fc-6242b1f17552",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize with sentence tokenizer\n",
        "example_sentence= sentence_list[1]\n",
        "xlmr_tokens = xlmr_tokenizer(example_sentence).tokens()\n",
        "input_ids = xlmr_tokenizer.encode(example_sentence, return_tensors=\"pt\")\n",
        "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
      ],
      "metadata": {
        "id": "KvrWSY-kn11p",
        "outputId": "c7d1f5be-8340-46c8-efcd-660cc98d461e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            0     1    2      3    4    5     6         7    8      9   ...  \\\n",
              "Tokens     <s>   ▁It  ▁is  ▁root   ed  ▁in  ▁our  ▁purpose   ▁‘     Th  ...   \n",
              "Input IDs    0  1650   83  74855  297   23  2446     60042  204  20800  ...   \n",
              "\n",
              "           68    69    70    71    72      73      74 75 76    77  \n",
              "Tokens     ▁–  ▁for   ▁us  ▁and  ▁our  ▁stake  holder  s  .  </s>  \n",
              "Input IDs  46   100  1821   136  2446  145054   31958  7  5     2  \n",
              "\n",
              "[2 rows x 78 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-16c88e7a-5ae0-48a8-8cd0-455f85474d14\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁It</td>\n",
              "      <td>▁is</td>\n",
              "      <td>▁root</td>\n",
              "      <td>ed</td>\n",
              "      <td>▁in</td>\n",
              "      <td>▁our</td>\n",
              "      <td>▁purpose</td>\n",
              "      <td>▁‘</td>\n",
              "      <td>Th</td>\n",
              "      <td>...</td>\n",
              "      <td>▁–</td>\n",
              "      <td>▁for</td>\n",
              "      <td>▁us</td>\n",
              "      <td>▁and</td>\n",
              "      <td>▁our</td>\n",
              "      <td>▁stake</td>\n",
              "      <td>holder</td>\n",
              "      <td>s</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Input IDs</th>\n",
              "      <td>0</td>\n",
              "      <td>1650</td>\n",
              "      <td>83</td>\n",
              "      <td>74855</td>\n",
              "      <td>297</td>\n",
              "      <td>23</td>\n",
              "      <td>2446</td>\n",
              "      <td>60042</td>\n",
              "      <td>204</td>\n",
              "      <td>20800</td>\n",
              "      <td>...</td>\n",
              "      <td>46</td>\n",
              "      <td>100</td>\n",
              "      <td>1821</td>\n",
              "      <td>136</td>\n",
              "      <td>2446</td>\n",
              "      <td>145054</td>\n",
              "      <td>31958</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 78 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16c88e7a-5ae0-48a8-8cd0-455f85474d14')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-16c88e7a-5ae0-48a8-8cd0-455f85474d14 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-16c88e7a-5ae0-48a8-8cd0-455f85474d14');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create predictions of NER tags\n",
        "outputs = xlmr_model(input_ids.to(device)).logits\n",
        "predictions = torch.argmax(outputs, dim=-1)\n",
        "print(predictions)\n",
        "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
        "print(f\"Shape of outputs: {outputs.shape}\")"
      ],
      "metadata": {
        "id": "4fr9hg4Doeea",
        "outputId": "3575daf8-0e60-444d-e9c7-7d5e94bc906c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[2, 3, 3, 4, 3, 4, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 4, 3, 3,\n",
            "         3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 6, 6, 3,\n",
            "         3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 3, 3, 3, 3, 3, 3, 6, 3, 3, 3, 3, 3, 4,\n",
            "         4, 3, 4, 4, 3, 2]], device='cuda:0')\n",
            "Number of tokens in sequence: 78\n",
            "Shape of outputs: torch.Size([1, 78, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert predictions to see how BAD random weights are :D\n",
        "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
      ],
      "metadata": {
        "id": "UhLGdo8RoowB",
        "outputId": "8810f770-e121-4cb9-915b-49d822f52505",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0      1      2      3      4      5      6         7      8   \\\n",
              "Tokens    <s>    ▁It    ▁is  ▁root     ed    ▁in   ▁our  ▁purpose     ▁‘   \n",
              "Tags    I-PER  B-ORG  B-ORG  I-ORG  B-ORG  I-ORG  I-ORG     B-ORG  B-ORG   \n",
              "\n",
              "           9   ...     68     69     70     71     72      73      74     75  \\\n",
              "Tokens     Th  ...     ▁–   ▁for    ▁us   ▁and   ▁our  ▁stake  holder      s   \n",
              "Tags    B-ORG  ...  B-ORG  B-ORG  B-ORG  I-ORG  I-ORG   B-ORG   I-ORG  I-ORG   \n",
              "\n",
              "           76     77  \n",
              "Tokens      .   </s>  \n",
              "Tags    B-ORG  I-PER  \n",
              "\n",
              "[2 rows x 78 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aeed894e-a019-440c-90c4-e170decedbef\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>68</th>\n",
              "      <th>69</th>\n",
              "      <th>70</th>\n",
              "      <th>71</th>\n",
              "      <th>72</th>\n",
              "      <th>73</th>\n",
              "      <th>74</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁It</td>\n",
              "      <td>▁is</td>\n",
              "      <td>▁root</td>\n",
              "      <td>ed</td>\n",
              "      <td>▁in</td>\n",
              "      <td>▁our</td>\n",
              "      <td>▁purpose</td>\n",
              "      <td>▁‘</td>\n",
              "      <td>Th</td>\n",
              "      <td>...</td>\n",
              "      <td>▁–</td>\n",
              "      <td>▁for</td>\n",
              "      <td>▁us</td>\n",
              "      <td>▁and</td>\n",
              "      <td>▁our</td>\n",
              "      <td>▁stake</td>\n",
              "      <td>holder</td>\n",
              "      <td>s</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>I-PER</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>...</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>I-ORG</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>I-PER</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2 rows × 78 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aeed894e-a019-440c-90c4-e170decedbef')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-aeed894e-a019-440c-90c4-e170decedbef button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-aeed894e-a019-440c-90c4-e170decedbef');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# helper steps for later (aggregating the test steps from before)\n",
        "def tag_text(text, tags, model, tokenizer):\n",
        "  # Get tokens with special characters\n",
        "  tokens = tokenizer(text).tokens()\n",
        "  # Encode the sequence into IDs\n",
        "  input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
        "  # Get predictions as distribution over 7 possible classes\n",
        "  outputs = model(input_ids)[0]\n",
        "  # Take argmax to get most likely class per token\n",
        "  predictions = torch.argmax(outputs, dim=2)\n",
        "  # Convert to DataFrame\n",
        "  preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "  return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
      ],
      "metadata": {
        "id": "k7YbPh2TSRsL"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Prepare input data for following training of the model XLMRobertaForTokenClassification (with our config=labels, device, ...)**"
      ],
      "metadata": {
        "id": "6URZDOPubFTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# show how labels are given in Pan-X subsets from the XTREME dataset and use the same \n",
        "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
        "print(f\"XTREME has {len(xtreme_subsets)} configurations\")\n",
        "\n",
        "# PAN-X subsets within XTREME dataset\n",
        "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
        "panx_subsets\n"
      ],
      "metadata": {
        "id": "gW4wWfq8igsK",
        "outputId": "30f3a9fa-73e0-4b78-dad1-bc6604ebc4d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XTREME has 183 configurations\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['PAN-X.af',\n",
              " 'PAN-X.ar',\n",
              " 'PAN-X.bg',\n",
              " 'PAN-X.bn',\n",
              " 'PAN-X.de',\n",
              " 'PAN-X.el',\n",
              " 'PAN-X.en',\n",
              " 'PAN-X.es',\n",
              " 'PAN-X.et',\n",
              " 'PAN-X.eu',\n",
              " 'PAN-X.fa',\n",
              " 'PAN-X.fi',\n",
              " 'PAN-X.fr',\n",
              " 'PAN-X.he',\n",
              " 'PAN-X.hi',\n",
              " 'PAN-X.hu',\n",
              " 'PAN-X.id',\n",
              " 'PAN-X.it',\n",
              " 'PAN-X.ja',\n",
              " 'PAN-X.jv',\n",
              " 'PAN-X.ka',\n",
              " 'PAN-X.kk',\n",
              " 'PAN-X.ko',\n",
              " 'PAN-X.ml',\n",
              " 'PAN-X.mr',\n",
              " 'PAN-X.ms',\n",
              " 'PAN-X.my',\n",
              " 'PAN-X.nl',\n",
              " 'PAN-X.pt',\n",
              " 'PAN-X.ru',\n",
              " 'PAN-X.sw',\n",
              " 'PAN-X.ta',\n",
              " 'PAN-X.te',\n",
              " 'PAN-X.th',\n",
              " 'PAN-X.tl',\n",
              " 'PAN-X.tr',\n",
              " 'PAN-X.ur',\n",
              " 'PAN-X.vi',\n",
              " 'PAN-X.yo',\n",
              " 'PAN-X.zh']"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare dataset\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "langs = [\"en\"] # e.g. [\"de\",\"en\"]\n",
        "fracs = [1.0] # e.g. [0.5,0.5]\n",
        "# panx_ch contains keys for each language and one level lower keys for all splits - here only eng and all data is selected\n",
        "for lang, frac in zip(langs, fracs):\n",
        "    # Load monolingual corpus\n",
        "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\")\n",
        "    # Shuffle and downsample each split according to spoken proportion\n",
        "    for split in ds:\n",
        "        panx_ch[lang][split] = (\n",
        "            ds[split]\n",
        "            .shuffle(seed=0)\n",
        "            .select(range(int(frac * ds[split].num_rows))))\n",
        "print(panx_ch)\n",
        "panx_ch_element = panx_ch[\"en\"][\"train\"][111]\n",
        "for key, value in panx_ch_element.items():\n",
        "    print(f\"{key}: {value}\")"
      ],
      "metadata": {
        "id": "2fNZnVQTkaOB",
        "outputId": "4468b977-4687-44f0-df0d-97878c7d753b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 453,
          "referenced_widgets": [
            "79526ed32928410c843edf773ab49ed2",
            "ed61e9db22a84f8084ed6dd454d47de9",
            "07766b8a3cb94ed7b5646badc6b10268",
            "201c3da4a45143c6b2db3cc474fa0212",
            "4c3128422302490abb62029c9ef6724d",
            "7e4ec6916a13490988fff0cd7c02ebd7",
            "3a50e12d19bf4afabb8fbd3b2f27d431",
            "7b9c7761fd8946fa88727ac5c0b2ee41",
            "3623138e8f734bbda55bd32f03ad6ca6",
            "147cf949a9954e60bb60ac75f6c60d80",
            "5092b83a123341ff95bdc9fd4a702025"
          ]
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.builder:Reusing dataset xtreme (/root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "79526ed32928410c843edf773ab49ed2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-2292d48c0b6f8502.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-56d73ebf7717cb83.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-5117c26f1eb0d215.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "defaultdict(<class 'datasets.dataset_dict.DatasetDict'>, {'en': DatasetDict({\n",
            "    validation: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'langs'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    test: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'langs'],\n",
            "        num_rows: 10000\n",
            "    })\n",
            "    train: Dataset({\n",
            "        features: ['tokens', 'ner_tags', 'langs'],\n",
            "        num_rows: 20000\n",
            "    })\n",
            "})})\n",
            "tokens: ['Lyon', 'County', ',', 'Nevada']\n",
            "ner_tags: [5, 6, 6, 6]\n",
            "langs: ['en', 'en', 'en', 'en']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# show info about tag feature --> we already defined the varibale tags earlier\n",
        "# --> DatasetDict holds information about all features used (like infos on columns in dataframe)\n",
        "print('----------features----------------')\n",
        "print(panx_ch[\"en\"][\"train\"].features)\n",
        "print('----------feature ner_tags----------------')\n",
        "print(panx_ch[\"en\"][\"train\"].features[\"ner_tags\"].feature)\n"
      ],
      "metadata": {
        "id": "CstJjQ3LkdRK",
        "outputId": "b1491552-a447-4d7b-8bb3-cb1c4e0c86c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------features----------------\n",
            "{'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None), 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None), 'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}\n",
            "----------feature ner_tags----------------\n",
            "ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# examples\n",
        "print(panx_ch[\"en\"][\"train\"][4:5])\n",
        "print(panx_ch[\"en\"][\"train\"][4:5][\"tokens\"])\n",
        "print(panx_ch[\"en\"][\"train\"][4:5][\"ner_tags\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_bdY_1CBKSkM",
        "outputId": "f46aefa8-5153-4e10-ecfb-b0374ea09de5"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'tokens': [['Black', 'Canyon', 'City', ',', 'Arizona']], 'ner_tags': [[5, 6, 6, 6, 6]], 'langs': [['en', 'en', 'en', 'en', 'en']]}\n",
            "[['Black', 'Canyon', 'City', ',', 'Arizona']]\n",
            "[[5, 6, 6, 6, 6]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# the library datasets provides a fast way to tokenize dataset objects with the map() operation.\n",
        "# the returned input ids need to be augmented with the attention mask and the label ids, that encode the information about with token is associated with each NER tag\n",
        "\n",
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)  # sequence is already split in words\n",
        "  labels = []\n",
        "  for idx, label in enumerate(examples[\"ner_tags\"]):\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=idx) # get word ids to associate subwords\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx is None or word_idx == previous_word_idx:\n",
        "        label_ids.append(-100) # -100 is chose, since the PyTorch cross-entropy loss class torch.nn.CrossEntropyLoss has an attribute ignore_index, whose value is -100, which is therefor ignored during training\n",
        "      else:\n",
        "        label_ids.append(label[word_idx])\n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  return tokenized_inputs\n",
        "\n",
        "def encode_panx_dataset(corpus):\n",
        "  return corpus.map(tokenize_and_align_labels, batched=True,remove_columns=['langs', 'ner_tags', 'tokens'])\n",
        "\n"
      ],
      "metadata": {
        "id": "SMABOQXJbqIB"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# encode dataset\n",
        "panx_en_encoded = encode_panx_dataset(panx_ch[\"en\"])\n",
        "panx_en_encoded\n",
        "print(panx_en_encoded[\"train\"][2])\n",
        "print(panx_ch[\"en\"][\"train\"][2])"
      ],
      "metadata": {
        "id": "8j8BLG0UczR8",
        "outputId": "7edc5137-ffef-4f63-f868-3bbd978a5b49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-23b8c1e9392456de.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-1a3d1fa7bc8960a9.arrow\n",
            "WARNING:datasets.arrow_dataset:Loading cached processed dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.en/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-bd9c66b3ad3c2d6d.arrow\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'input_ids': [0, 9079, 7113, 202104, 11491, 6, 4, 9079, 7113, 15, 5106, 210298, 1104, 151210, 6, 4, 20271, 30839, 6, 167618, 5106, 1388, 2], 'labels': [-100, 5, -100, 6, 6, 0, -100, 5, -100, 0, 0, -100, -100, -100, 0, -100, 0, 3, 4, -100, 0, 0, -100]}\n",
            "{'tokens': ['Vaivara', 'concentration', 'camp', ',', 'Vaivara', '(', \"''1943–1944\", ',', 'during', 'German', 'occupation', \"''\", ')'], 'ner_tags': [5, 6, 6, 0, 5, 0, 0, 0, 0, 3, 4, 0, 0], 'langs': ['en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en', 'en']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define performance measures**"
      ],
      "metadata": {
        "id": "H7MP2P0sOJjU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# common approach: results for precision, recall, F1-score\n",
        "# in NER: all words of an entity need to be predicted correctly in order for a prediction to be counted as correct\n",
        "# libary seqeval: expects predictions and labels as lists of lists \n",
        "\n",
        "\n",
        "# during training we need to convert the outputs of the model into such a list that sequeval expects\n",
        "def align_predictions(predictions, label_ids):\n",
        "  preds = np.argmax(predictions, axis=2)\n",
        "  batch_size, seq_len = preds.shape\n",
        "  labels_list, preds_list = [], []\n",
        "\n",
        "  for batch_idx in range(batch_size):\n",
        "    example_labels, example_preds = [], []\n",
        "    for seq_idx in range(seq_len):\n",
        "      # Ignore label IDs = -100\n",
        "      if label_ids[batch_idx, seq_idx] != -100:\n",
        "        example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "        example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "    labels_list.append(example_labels)\n",
        "    preds_list.append(example_preds)\n",
        "  return preds_list, labels_list\n",
        "\n",
        "# helper function for calculation of F1-score for validation set\n",
        "def compute_metrics(eval_pred):\n",
        "  y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
        "  return {\"f1\": f1_score(y_true, y_pred),\n",
        "          \"precision\": precision_score(y_true, y_pred),\n",
        "          \"recall\": recall_score(y_true, y_pred),\n",
        "          \"accuracy\": f1_score(y_true, y_pred),\n",
        "          \"classification_report\": classification_report(y_true, y_pred, mode='strict', scheme=IOB2)\n",
        "          }\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "FRNOGPAWOP8v"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Finetuning XLM-RoBERTa and Upload to Huggingface**"
      ],
      "metadata": {
        "id": "Eje9DztnXAH5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "batch_size = 24\n",
        "logging_steps = len(panx_en_encoded[\"train\"]) // batch_size # for panx_en_encoded = 833\n",
        "model_name = f\"{xlmr_model_name}-finetuned-panx-en\"\n",
        "training_args = TrainingArguments(output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  evaluation_strategy=\"steps\", eval_steps=batch_size, # \"steps\": Evaluation is done (and logged) every eval_steps. The evaluation strategy to adopt during training.\n",
        "                                  save_strategy=\"steps\", save_steps=1e6, \n",
        "                                  weight_decay=0.01,\n",
        "                                  disable_tqdm=False, \n",
        "                                  logging_strategy=\"steps\", logging_steps=batch_size,  # \"epoch\": Logging is done at the end of each epoch. The logging strategy to adopt during training.\n",
        "                                  push_to_hub=True)"
      ],
      "metadata": {
        "id": "9gqBOLqxVxbu"
      },
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359,
          "referenced_widgets": [
            "19d19f391f31488d82d5f98ccb472d30",
            "c9f2cf7cf15048f5b1fa29e7cae6b75e",
            "5619e418937747c2bb23ee66917534a7",
            "32728b64f99b47d699c0b8c942fb2163",
            "fd735e7855ee4a0194f5188d912bf9b9",
            "e41754377b274ee19f0a48a6863a15e6",
            "4e13e08f0d84428c9198697637bf0a25",
            "e3be4d6d48624fccbddf3fd2c1e6d101",
            "adad0dafc0aa44938bc83b8236f9e21f",
            "8d1fb831efd340cfbcfe4a168a9af265",
            "e2306127cfc84816b459733ac70dbe46",
            "a025a79dbb3b4053ac6227438c8c1580",
            "e7dd974585da4637b835bbb426716756",
            "08835a7aeff04494a82657034d83881d",
            "dd5e85f4361043f0aba742d3991e80fa",
            "6d6ff1e2307e4d2ca5da42bf1d92d48f",
            "a5ad016a215c4732a1ae1d5d4f0271fe"
          ]
        },
        "id": "-TMMSMcwXHT5",
        "outputId": "c023d196-bb86-437f-d153-457beac45b69"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token is valid.\n",
            "Your token has been saved to /root/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# this model needs to be crated at huggingface:\n",
        "f\"{xlmr_model_name}-finetuned-panx-en\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "HVvVjLRscWul",
        "outputId": "1d260517-6ed8-4309-8655-424a66eea1b3"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'xlm-roberta-base-finetuned-panx-en'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# pad each input sequence to the largest sequence length in a batch\n",
        "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "3tD9vKZ2YZ1t"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# init method, to avoid initializing a new model for every Trainer (it loads the untrained model and is called at the beginning of the train() call)\n",
        "def model_init():\n",
        "  return (XLMRobertaForTokenClassification\n",
        "          .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
        "          .to(device))"
      ],
      "metadata": {
        "id": "oR33DK-0YjKA"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model_init=model_init, args=training_args,\n",
        "                  data_collator=data_collator,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=panx_en_encoded[\"train\"],\n",
        "                  eval_dataset=panx_en_encoded[\"validation\"],\n",
        "                  tokenizer=xlmr_tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYQLyzuSZ-zn",
        "outputId": "ee265dc8-22e9-4526-ada8-7a4cd57a171d"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/xlm-roberta-base-finetuned-panx-en is already a clone of https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en. Make sure you pull the latest changes with `repo.git_pull()`.\n",
            "WARNING:huggingface_hub.repository:/content/xlm-roberta-base-finetuned-panx-en is already a clone of https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en. Make sure you pull the latest changes with `repo.git_pull()`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Z5N1kmrQaKgX",
        "outputId": "65979fb5-510e-4e30-f523-5a600e976eeb"
      },
      "execution_count": 114,
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1801' max='2502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1801/2502 15:24 < 06:00, 1.95 it/s, Epoch 2.16/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Classification Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.264400</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.421248</td>\n",
              "      <td>0.369598</td>\n",
              "      <td>0.489679</td>\n",
              "      <td>0.421248</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.28      0.18      0.22      4834\n",
              "         ORG       0.39      0.15      0.22      4677\n",
              "         PER       0.66      0.72      0.69      4635\n",
              "\n",
              "   micro avg       0.49      0.35      0.41     14146\n",
              "   macro avg       0.44      0.35      0.38     14146\n",
              "weighted avg       0.44      0.35      0.37     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.720900</td>\n",
              "      <td>0.563264</td>\n",
              "      <td>0.481697</td>\n",
              "      <td>0.418967</td>\n",
              "      <td>0.566521</td>\n",
              "      <td>0.481697</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.35      0.49      0.41      4834\n",
              "         ORG       0.47      0.51      0.49      4677\n",
              "         PER       0.77      0.69      0.73      4635\n",
              "\n",
              "   micro avg       0.50      0.56      0.53     14146\n",
              "   macro avg       0.53      0.57      0.54     14146\n",
              "weighted avg       0.53      0.56      0.54     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.595100</td>\n",
              "      <td>0.467027</td>\n",
              "      <td>0.605884</td>\n",
              "      <td>0.558773</td>\n",
              "      <td>0.661671</td>\n",
              "      <td>0.605884</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.60      0.63      0.61      4834\n",
              "         ORG       0.57      0.51      0.54      4677\n",
              "         PER       0.74      0.81      0.78      4635\n",
              "\n",
              "   micro avg       0.64      0.65      0.65     14146\n",
              "   macro avg       0.64      0.65      0.64     14146\n",
              "weighted avg       0.64      0.65      0.64     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.447500</td>\n",
              "      <td>0.442492</td>\n",
              "      <td>0.665884</td>\n",
              "      <td>0.633618</td>\n",
              "      <td>0.701612</td>\n",
              "      <td>0.665884</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.65      0.75      0.70      4834\n",
              "         ORG       0.65      0.51      0.57      4677\n",
              "         PER       0.80      0.82      0.81      4635\n",
              "\n",
              "   micro avg       0.70      0.70      0.70     14146\n",
              "   macro avg       0.70      0.70      0.69     14146\n",
              "weighted avg       0.70      0.70      0.69     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.497800</td>\n",
              "      <td>0.446937</td>\n",
              "      <td>0.637484</td>\n",
              "      <td>0.592957</td>\n",
              "      <td>0.689241</td>\n",
              "      <td>0.637484</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.66      0.68      0.67      4834\n",
              "         ORG       0.60      0.52      0.56      4677\n",
              "         PER       0.72      0.85      0.78      4635\n",
              "\n",
              "   micro avg       0.66      0.68      0.67     14146\n",
              "   macro avg       0.66      0.68      0.67     14146\n",
              "weighted avg       0.66      0.68      0.67     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.438300</td>\n",
              "      <td>0.409320</td>\n",
              "      <td>0.700302</td>\n",
              "      <td>0.666773</td>\n",
              "      <td>0.737382</td>\n",
              "      <td>0.700302</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.75      0.71      0.73      4834\n",
              "         ORG       0.61      0.63      0.62      4677\n",
              "         PER       0.77      0.86      0.81      4635\n",
              "\n",
              "   micro avg       0.71      0.73      0.72     14146\n",
              "   macro avg       0.71      0.73      0.72     14146\n",
              "weighted avg       0.71      0.73      0.72     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.368846</td>\n",
              "      <td>0.712246</td>\n",
              "      <td>0.687660</td>\n",
              "      <td>0.738654</td>\n",
              "      <td>0.712246</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.71      0.74      0.73      4834\n",
              "         ORG       0.66      0.64      0.65      4677\n",
              "         PER       0.86      0.81      0.84      4635\n",
              "\n",
              "   micro avg       0.74      0.73      0.74     14146\n",
              "   macro avg       0.74      0.73      0.74     14146\n",
              "weighted avg       0.74      0.73      0.74     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.451300</td>\n",
              "      <td>0.369968</td>\n",
              "      <td>0.723576</td>\n",
              "      <td>0.708127</td>\n",
              "      <td>0.739714</td>\n",
              "      <td>0.723576</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.71      0.74      4834\n",
              "         ORG       0.66      0.63      0.64      4677\n",
              "         PER       0.84      0.85      0.84      4635\n",
              "\n",
              "   micro avg       0.76      0.73      0.74     14146\n",
              "   macro avg       0.76      0.73      0.74     14146\n",
              "weighted avg       0.76      0.73      0.74     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.378600</td>\n",
              "      <td>0.366571</td>\n",
              "      <td>0.730411</td>\n",
              "      <td>0.712490</td>\n",
              "      <td>0.749258</td>\n",
              "      <td>0.730411</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.74      0.80      0.77      4834\n",
              "         ORG       0.67      0.61      0.64      4677\n",
              "         PER       0.88      0.81      0.84      4635\n",
              "\n",
              "   micro avg       0.76      0.74      0.75     14146\n",
              "   macro avg       0.77      0.74      0.75     14146\n",
              "weighted avg       0.77      0.74      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.365239</td>\n",
              "      <td>0.704618</td>\n",
              "      <td>0.687374</td>\n",
              "      <td>0.722748</td>\n",
              "      <td>0.704618</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.74      0.72      0.73      4834\n",
              "         ORG       0.64      0.58      0.61      4677\n",
              "         PER       0.83      0.86      0.84      4635\n",
              "\n",
              "   micro avg       0.74      0.72      0.73     14146\n",
              "   macro avg       0.74      0.72      0.73     14146\n",
              "weighted avg       0.74      0.72      0.73     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.401400</td>\n",
              "      <td>0.343832</td>\n",
              "      <td>0.724615</td>\n",
              "      <td>0.696415</td>\n",
              "      <td>0.755196</td>\n",
              "      <td>0.724615</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.75      0.75      0.75      4834\n",
              "         ORG       0.70      0.63      0.66      4677\n",
              "         PER       0.80      0.86      0.83      4635\n",
              "\n",
              "   micro avg       0.75      0.75      0.75     14146\n",
              "   macro avg       0.75      0.75      0.75     14146\n",
              "weighted avg       0.75      0.75      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.378900</td>\n",
              "      <td>0.353318</td>\n",
              "      <td>0.720792</td>\n",
              "      <td>0.692178</td>\n",
              "      <td>0.751873</td>\n",
              "      <td>0.720792</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.72      0.75      4834\n",
              "         ORG       0.65      0.66      0.65      4677\n",
              "         PER       0.77      0.86      0.81      4635\n",
              "\n",
              "   micro avg       0.73      0.75      0.74     14146\n",
              "   macro avg       0.73      0.75      0.74     14146\n",
              "weighted avg       0.73      0.75      0.74     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.403200</td>\n",
              "      <td>0.356667</td>\n",
              "      <td>0.725152</td>\n",
              "      <td>0.712463</td>\n",
              "      <td>0.738301</td>\n",
              "      <td>0.725152</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.74      0.73      0.74      4834\n",
              "         ORG       0.67      0.62      0.64      4677\n",
              "         PER       0.88      0.84      0.86      4635\n",
              "\n",
              "   micro avg       0.77      0.73      0.75     14146\n",
              "   macro avg       0.77      0.73      0.75     14146\n",
              "weighted avg       0.76      0.73      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>0.328210</td>\n",
              "      <td>0.743277</td>\n",
              "      <td>0.725468</td>\n",
              "      <td>0.761982</td>\n",
              "      <td>0.743277</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.77      0.77      4834\n",
              "         ORG       0.71      0.64      0.67      4677\n",
              "         PER       0.88      0.85      0.86      4635\n",
              "\n",
              "   micro avg       0.79      0.75      0.77     14146\n",
              "   macro avg       0.79      0.75      0.77     14146\n",
              "weighted avg       0.79      0.75      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.339700</td>\n",
              "      <td>0.330421</td>\n",
              "      <td>0.752240</td>\n",
              "      <td>0.731229</td>\n",
              "      <td>0.774495</td>\n",
              "      <td>0.752240</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.76      0.80      4834\n",
              "         ORG       0.65      0.68      0.67      4677\n",
              "         PER       0.84      0.87      0.86      4635\n",
              "\n",
              "   micro avg       0.77      0.77      0.77     14146\n",
              "   macro avg       0.78      0.77      0.77     14146\n",
              "weighted avg       0.78      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>384</td>\n",
              "      <td>0.387100</td>\n",
              "      <td>0.324439</td>\n",
              "      <td>0.742709</td>\n",
              "      <td>0.716029</td>\n",
              "      <td>0.771455</td>\n",
              "      <td>0.742709</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.77      0.78      4834\n",
              "         ORG       0.67      0.67      0.67      4677\n",
              "         PER       0.83      0.86      0.85      4635\n",
              "\n",
              "   micro avg       0.76      0.77      0.77     14146\n",
              "   macro avg       0.76      0.77      0.77     14146\n",
              "weighted avg       0.76      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>0.346100</td>\n",
              "      <td>0.328409</td>\n",
              "      <td>0.752022</td>\n",
              "      <td>0.729812</td>\n",
              "      <td>0.775626</td>\n",
              "      <td>0.752022</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.77      0.81      0.79      4834\n",
              "         ORG       0.69      0.64      0.66      4677\n",
              "         PER       0.83      0.87      0.85      4635\n",
              "\n",
              "   micro avg       0.77      0.77      0.77     14146\n",
              "   macro avg       0.77      0.77      0.77     14146\n",
              "weighted avg       0.77      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>0.350400</td>\n",
              "      <td>0.304922</td>\n",
              "      <td>0.757413</td>\n",
              "      <td>0.741782</td>\n",
              "      <td>0.773717</td>\n",
              "      <td>0.757413</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.80      0.79      4834\n",
              "         ORG       0.70      0.67      0.68      4677\n",
              "         PER       0.87      0.84      0.85      4635\n",
              "\n",
              "   micro avg       0.79      0.77      0.78     14146\n",
              "   macro avg       0.79      0.77      0.78     14146\n",
              "weighted avg       0.79      0.77      0.78     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>456</td>\n",
              "      <td>0.338700</td>\n",
              "      <td>0.317797</td>\n",
              "      <td>0.771710</td>\n",
              "      <td>0.753690</td>\n",
              "      <td>0.790612</td>\n",
              "      <td>0.771710</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.81      0.80      4834\n",
              "         ORG       0.70      0.71      0.71      4677\n",
              "         PER       0.88      0.85      0.86      4635\n",
              "\n",
              "   micro avg       0.79      0.79      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.325900</td>\n",
              "      <td>0.302561</td>\n",
              "      <td>0.773845</td>\n",
              "      <td>0.763645</td>\n",
              "      <td>0.784321</td>\n",
              "      <td>0.773845</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.79      0.80      4834\n",
              "         ORG       0.73      0.67      0.70      4677\n",
              "         PER       0.88      0.86      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.78      0.79     14146\n",
              "   macro avg       0.81      0.78      0.79     14146\n",
              "weighted avg       0.81      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>504</td>\n",
              "      <td>0.347300</td>\n",
              "      <td>0.325356</td>\n",
              "      <td>0.732381</td>\n",
              "      <td>0.708973</td>\n",
              "      <td>0.757387</td>\n",
              "      <td>0.732381</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.69      0.74      4834\n",
              "         ORG       0.65      0.70      0.67      4677\n",
              "         PER       0.83      0.87      0.85      4635\n",
              "\n",
              "   micro avg       0.75      0.75      0.75     14146\n",
              "   macro avg       0.75      0.75      0.75     14146\n",
              "weighted avg       0.75      0.75      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>528</td>\n",
              "      <td>0.289300</td>\n",
              "      <td>0.310175</td>\n",
              "      <td>0.768851</td>\n",
              "      <td>0.757075</td>\n",
              "      <td>0.780998</td>\n",
              "      <td>0.768851</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.79      0.80      4834\n",
              "         ORG       0.69      0.67      0.68      4677\n",
              "         PER       0.88      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.79      0.78      0.79     14146\n",
              "   macro avg       0.79      0.78      0.79     14146\n",
              "weighted avg       0.79      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>552</td>\n",
              "      <td>0.366900</td>\n",
              "      <td>0.311943</td>\n",
              "      <td>0.763090</td>\n",
              "      <td>0.752751</td>\n",
              "      <td>0.773717</td>\n",
              "      <td>0.763090</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.83      0.81      4834\n",
              "         ORG       0.72      0.60      0.65      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.77      0.78     14146\n",
              "   macro avg       0.79      0.77      0.78     14146\n",
              "weighted avg       0.78      0.77      0.78     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>576</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>0.296288</td>\n",
              "      <td>0.781849</td>\n",
              "      <td>0.773413</td>\n",
              "      <td>0.790471</td>\n",
              "      <td>0.781849</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.80      0.81      4834\n",
              "         ORG       0.74      0.69      0.71      4677\n",
              "         PER       0.86      0.86      0.86      4635\n",
              "\n",
              "   micro avg       0.80      0.79      0.80     14146\n",
              "   macro avg       0.80      0.79      0.79     14146\n",
              "weighted avg       0.80      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.297000</td>\n",
              "      <td>0.321664</td>\n",
              "      <td>0.754214</td>\n",
              "      <td>0.733195</td>\n",
              "      <td>0.776474</td>\n",
              "      <td>0.754214</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.73      0.76      4834\n",
              "         ORG       0.67      0.72      0.69      4677\n",
              "         PER       0.84      0.88      0.86      4635\n",
              "\n",
              "   micro avg       0.77      0.77      0.77     14146\n",
              "   macro avg       0.77      0.78      0.77     14146\n",
              "weighted avg       0.77      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>624</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.303848</td>\n",
              "      <td>0.773248</td>\n",
              "      <td>0.757996</td>\n",
              "      <td>0.789128</td>\n",
              "      <td>0.773248</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.76      0.80      4834\n",
              "         ORG       0.67      0.71      0.69      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.78      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>648</td>\n",
              "      <td>0.351400</td>\n",
              "      <td>0.291328</td>\n",
              "      <td>0.779431</td>\n",
              "      <td>0.766899</td>\n",
              "      <td>0.792379</td>\n",
              "      <td>0.779431</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.81      0.82      4834\n",
              "         ORG       0.72      0.66      0.69      4677\n",
              "         PER       0.86      0.89      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.80      0.79      0.79     14146\n",
              "weighted avg       0.80      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>672</td>\n",
              "      <td>0.282400</td>\n",
              "      <td>0.300798</td>\n",
              "      <td>0.781331</td>\n",
              "      <td>0.775188</td>\n",
              "      <td>0.787572</td>\n",
              "      <td>0.781331</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.81      0.80      4834\n",
              "         ORG       0.76      0.67      0.71      4677\n",
              "         PER       0.85      0.87      0.86      4635\n",
              "\n",
              "   micro avg       0.81      0.78      0.79     14146\n",
              "   macro avg       0.80      0.78      0.79     14146\n",
              "weighted avg       0.80      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>696</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.291482</td>\n",
              "      <td>0.780678</td>\n",
              "      <td>0.764061</td>\n",
              "      <td>0.798035</td>\n",
              "      <td>0.780678</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.81      0.80      4834\n",
              "         ORG       0.72      0.70      0.71      4677\n",
              "         PER       0.86      0.87      0.87      4635\n",
              "\n",
              "   micro avg       0.80      0.79      0.80     14146\n",
              "   macro avg       0.80      0.79      0.80     14146\n",
              "weighted avg       0.80      0.79      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.294122</td>\n",
              "      <td>0.783831</td>\n",
              "      <td>0.775533</td>\n",
              "      <td>0.792309</td>\n",
              "      <td>0.783831</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.83      0.81      4834\n",
              "         ORG       0.74      0.66      0.70      4677\n",
              "         PER       0.87      0.87      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.81      0.79      0.79     14146\n",
              "weighted avg       0.80      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.317400</td>\n",
              "      <td>0.298566</td>\n",
              "      <td>0.776970</td>\n",
              "      <td>0.760911</td>\n",
              "      <td>0.793723</td>\n",
              "      <td>0.776970</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.77      0.84      0.80      4834\n",
              "         ORG       0.73      0.66      0.70      4677\n",
              "         PER       0.87      0.86      0.86      4635\n",
              "\n",
              "   micro avg       0.79      0.79      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>768</td>\n",
              "      <td>0.326400</td>\n",
              "      <td>0.278257</td>\n",
              "      <td>0.778759</td>\n",
              "      <td>0.763042</td>\n",
              "      <td>0.795136</td>\n",
              "      <td>0.778759</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.77      0.82      0.79      4834\n",
              "         ORG       0.75      0.68      0.71      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.79      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>792</td>\n",
              "      <td>0.281500</td>\n",
              "      <td>0.286117</td>\n",
              "      <td>0.784822</td>\n",
              "      <td>0.770394</td>\n",
              "      <td>0.799802</td>\n",
              "      <td>0.784822</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.81      0.81      4834\n",
              "         ORG       0.70      0.73      0.72      4677\n",
              "         PER       0.88      0.85      0.86      4635\n",
              "\n",
              "   micro avg       0.80      0.80      0.80     14146\n",
              "   macro avg       0.80      0.80      0.80     14146\n",
              "weighted avg       0.80      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>816</td>\n",
              "      <td>0.289500</td>\n",
              "      <td>0.279878</td>\n",
              "      <td>0.784232</td>\n",
              "      <td>0.770174</td>\n",
              "      <td>0.798812</td>\n",
              "      <td>0.784232</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.80      0.80      4834\n",
              "         ORG       0.73      0.72      0.73      4677\n",
              "         PER       0.90      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.81      0.79      0.80     14146\n",
              "weighted avg       0.81      0.79      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.281848</td>\n",
              "      <td>0.787642</td>\n",
              "      <td>0.772156</td>\n",
              "      <td>0.803761</td>\n",
              "      <td>0.787642</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.71      0.71      0.71      4677\n",
              "         PER       0.88      0.86      0.87      4635\n",
              "\n",
              "   micro avg       0.80      0.80      0.80     14146\n",
              "   macro avg       0.80      0.80      0.80     14146\n",
              "weighted avg       0.80      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>864</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.783642</td>\n",
              "      <td>0.775028</td>\n",
              "      <td>0.792450</td>\n",
              "      <td>0.783642</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.79      0.82      4834\n",
              "         ORG       0.70      0.70      0.70      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.81      0.79      0.80     14146\n",
              "weighted avg       0.81      0.79      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>888</td>\n",
              "      <td>0.281900</td>\n",
              "      <td>0.286104</td>\n",
              "      <td>0.776127</td>\n",
              "      <td>0.769600</td>\n",
              "      <td>0.782765</td>\n",
              "      <td>0.776127</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.80      0.81      4834\n",
              "         ORG       0.77      0.63      0.69      4677\n",
              "         PER       0.81      0.91      0.85      4635\n",
              "\n",
              "   micro avg       0.81      0.78      0.79     14146\n",
              "   macro avg       0.80      0.78      0.79     14146\n",
              "weighted avg       0.80      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>912</td>\n",
              "      <td>0.269200</td>\n",
              "      <td>0.292363</td>\n",
              "      <td>0.775573</td>\n",
              "      <td>0.767967</td>\n",
              "      <td>0.783331</td>\n",
              "      <td>0.775573</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.77      0.80      4834\n",
              "         ORG       0.75      0.68      0.71      4677\n",
              "         PER       0.82      0.89      0.85      4635\n",
              "\n",
              "   micro avg       0.80      0.78      0.79     14146\n",
              "   macro avg       0.80      0.78      0.79     14146\n",
              "weighted avg       0.80      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.247800</td>\n",
              "      <td>0.296327</td>\n",
              "      <td>0.783297</td>\n",
              "      <td>0.759870</td>\n",
              "      <td>0.808214</td>\n",
              "      <td>0.783297</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.85      0.82      4834\n",
              "         ORG       0.72      0.68      0.70      4677\n",
              "         PER       0.87      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.80      0.80     14146\n",
              "   macro avg       0.79      0.80      0.80     14146\n",
              "weighted avg       0.79      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.255700</td>\n",
              "      <td>0.295956</td>\n",
              "      <td>0.778267</td>\n",
              "      <td>0.781428</td>\n",
              "      <td>0.775131</td>\n",
              "      <td>0.778267</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.73      0.77      4834\n",
              "         ORG       0.73      0.71      0.72      4677\n",
              "         PER       0.89      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.81      0.77      0.79     14146\n",
              "   macro avg       0.81      0.77      0.79     14146\n",
              "weighted avg       0.81      0.77      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>984</td>\n",
              "      <td>0.300300</td>\n",
              "      <td>0.265615</td>\n",
              "      <td>0.786220</td>\n",
              "      <td>0.772696</td>\n",
              "      <td>0.800226</td>\n",
              "      <td>0.786220</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.73      0.68      0.71      4677\n",
              "         PER       0.88      0.87      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.80      0.80     14146\n",
              "   macro avg       0.81      0.80      0.80     14146\n",
              "weighted avg       0.81      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1008</td>\n",
              "      <td>0.225400</td>\n",
              "      <td>0.279130</td>\n",
              "      <td>0.800738</td>\n",
              "      <td>0.788954</td>\n",
              "      <td>0.812880</td>\n",
              "      <td>0.800738</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.82      0.82      4834\n",
              "         ORG       0.73      0.73      0.73      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1032</td>\n",
              "      <td>0.249600</td>\n",
              "      <td>0.270179</td>\n",
              "      <td>0.787747</td>\n",
              "      <td>0.770088</td>\n",
              "      <td>0.806235</td>\n",
              "      <td>0.787747</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.85      0.81      4834\n",
              "         ORG       0.74      0.68      0.71      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.80      0.81      0.80     14146\n",
              "   macro avg       0.80      0.80      0.80     14146\n",
              "weighted avg       0.80      0.81      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1056</td>\n",
              "      <td>0.212400</td>\n",
              "      <td>0.288848</td>\n",
              "      <td>0.795228</td>\n",
              "      <td>0.789466</td>\n",
              "      <td>0.801075</td>\n",
              "      <td>0.795228</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.79      0.82      4834\n",
              "         ORG       0.75      0.71      0.73      4677\n",
              "         PER       0.85      0.89      0.87      4635\n",
              "\n",
              "   micro avg       0.82      0.80      0.81     14146\n",
              "   macro avg       0.82      0.80      0.81     14146\n",
              "weighted avg       0.82      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.284100</td>\n",
              "      <td>0.276123</td>\n",
              "      <td>0.794581</td>\n",
              "      <td>0.787032</td>\n",
              "      <td>0.802276</td>\n",
              "      <td>0.794581</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.83      4834\n",
              "         ORG       0.73      0.68      0.70      4677\n",
              "         PER       0.89      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.80      0.81     14146\n",
              "   macro avg       0.81      0.80      0.81     14146\n",
              "weighted avg       0.81      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1104</td>\n",
              "      <td>0.251700</td>\n",
              "      <td>0.265948</td>\n",
              "      <td>0.802619</td>\n",
              "      <td>0.790940</td>\n",
              "      <td>0.814647</td>\n",
              "      <td>0.802619</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.84      0.82      4834\n",
              "         ORG       0.76      0.72      0.74      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1128</td>\n",
              "      <td>0.235500</td>\n",
              "      <td>0.268074</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.787597</td>\n",
              "      <td>0.813375</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.82      0.82      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.88      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1152</td>\n",
              "      <td>0.240200</td>\n",
              "      <td>0.270146</td>\n",
              "      <td>0.799148</td>\n",
              "      <td>0.789205</td>\n",
              "      <td>0.809345</td>\n",
              "      <td>0.799148</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.81      0.82      4834\n",
              "         ORG       0.73      0.73      0.73      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1176</td>\n",
              "      <td>0.229600</td>\n",
              "      <td>0.275281</td>\n",
              "      <td>0.794576</td>\n",
              "      <td>0.781853</td>\n",
              "      <td>0.807719</td>\n",
              "      <td>0.794576</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.76      0.70      0.73      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.81      0.81     14146\n",
              "   macro avg       0.81      0.81      0.81     14146\n",
              "weighted avg       0.81      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.245300</td>\n",
              "      <td>0.269645</td>\n",
              "      <td>0.802897</td>\n",
              "      <td>0.791215</td>\n",
              "      <td>0.814930</td>\n",
              "      <td>0.802897</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.82      0.83      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.87      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1224</td>\n",
              "      <td>0.268900</td>\n",
              "      <td>0.270039</td>\n",
              "      <td>0.793593</td>\n",
              "      <td>0.781940</td>\n",
              "      <td>0.805599</td>\n",
              "      <td>0.793593</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.76      0.70      0.73      4677\n",
              "         PER       0.89      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.80      0.81     14146\n",
              "   macro avg       0.82      0.80      0.81     14146\n",
              "weighted avg       0.82      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1248</td>\n",
              "      <td>0.236200</td>\n",
              "      <td>0.270506</td>\n",
              "      <td>0.802777</td>\n",
              "      <td>0.800464</td>\n",
              "      <td>0.805104</td>\n",
              "      <td>0.802777</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.83      0.83      4834\n",
              "         ORG       0.77      0.70      0.73      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.80      0.82     14146\n",
              "   macro avg       0.83      0.80      0.81     14146\n",
              "weighted avg       0.83      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1272</td>\n",
              "      <td>0.226000</td>\n",
              "      <td>0.264204</td>\n",
              "      <td>0.804240</td>\n",
              "      <td>0.790963</td>\n",
              "      <td>0.817970</td>\n",
              "      <td>0.804240</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.84      0.84      4834\n",
              "         ORG       0.74      0.72      0.73      4677\n",
              "         PER       0.86      0.89      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.82      0.81     14146\n",
              "   macro avg       0.81      0.82      0.81     14146\n",
              "weighted avg       0.81      0.82      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1296</td>\n",
              "      <td>0.213900</td>\n",
              "      <td>0.268963</td>\n",
              "      <td>0.801261</td>\n",
              "      <td>0.794222</td>\n",
              "      <td>0.808426</td>\n",
              "      <td>0.801261</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.86      0.78      0.82      4834\n",
              "         ORG       0.72      0.76      0.74      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.274400</td>\n",
              "      <td>0.261904</td>\n",
              "      <td>0.799917</td>\n",
              "      <td>0.784138</td>\n",
              "      <td>0.816344</td>\n",
              "      <td>0.799917</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.81      0.82      4834\n",
              "         ORG       0.71      0.75      0.73      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.81      0.81     14146\n",
              "   macro avg       0.81      0.81      0.81     14146\n",
              "weighted avg       0.81      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1344</td>\n",
              "      <td>0.201500</td>\n",
              "      <td>0.263989</td>\n",
              "      <td>0.806633</td>\n",
              "      <td>0.803521</td>\n",
              "      <td>0.809770</td>\n",
              "      <td>0.806633</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.83      0.83      4834\n",
              "         ORG       0.76      0.71      0.74      4677\n",
              "         PER       0.89      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1368</td>\n",
              "      <td>0.194900</td>\n",
              "      <td>0.274984</td>\n",
              "      <td>0.807542</td>\n",
              "      <td>0.802274</td>\n",
              "      <td>0.812880</td>\n",
              "      <td>0.807542</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.84      0.83      4834\n",
              "         ORG       0.77      0.70      0.73      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1392</td>\n",
              "      <td>0.225900</td>\n",
              "      <td>0.266891</td>\n",
              "      <td>0.809165</td>\n",
              "      <td>0.799669</td>\n",
              "      <td>0.818889</td>\n",
              "      <td>0.809165</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.86      0.83      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.89      0.86      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1416</td>\n",
              "      <td>0.188400</td>\n",
              "      <td>0.272946</td>\n",
              "      <td>0.806096</td>\n",
              "      <td>0.799014</td>\n",
              "      <td>0.813304</td>\n",
              "      <td>0.806096</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.83      0.83      4834\n",
              "         ORG       0.75      0.73      0.74      4677\n",
              "         PER       0.91      0.87      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.186800</td>\n",
              "      <td>0.267854</td>\n",
              "      <td>0.808290</td>\n",
              "      <td>0.800666</td>\n",
              "      <td>0.816061</td>\n",
              "      <td>0.808290</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.83      0.84      4834\n",
              "         ORG       0.77      0.71      0.74      4677\n",
              "         PER       0.86      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1464</td>\n",
              "      <td>0.229200</td>\n",
              "      <td>0.265799</td>\n",
              "      <td>0.805514</td>\n",
              "      <td>0.795437</td>\n",
              "      <td>0.815849</td>\n",
              "      <td>0.805514</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.83      0.83      4834\n",
              "         ORG       0.76      0.73      0.74      4677\n",
              "         PER       0.87      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.82      0.81      0.82     14146\n",
              "weighted avg       0.82      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1488</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.260955</td>\n",
              "      <td>0.806553</td>\n",
              "      <td>0.800599</td>\n",
              "      <td>0.812597</td>\n",
              "      <td>0.806553</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.83      0.83      4834\n",
              "         ORG       0.76      0.72      0.74      4677\n",
              "         PER       0.89      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1512</td>\n",
              "      <td>0.233500</td>\n",
              "      <td>0.261289</td>\n",
              "      <td>0.799655</td>\n",
              "      <td>0.781625</td>\n",
              "      <td>0.818535</td>\n",
              "      <td>0.799655</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.87      0.83      4834\n",
              "         ORG       0.77      0.68      0.72      4677\n",
              "         PER       0.86      0.90      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.82      0.81     14146\n",
              "   macro avg       0.81      0.82      0.81     14146\n",
              "weighted avg       0.81      0.82      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1536</td>\n",
              "      <td>0.237900</td>\n",
              "      <td>0.249511</td>\n",
              "      <td>0.808119</td>\n",
              "      <td>0.797494</td>\n",
              "      <td>0.819030</td>\n",
              "      <td>0.808119</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.83      0.83      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.87      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.239400</td>\n",
              "      <td>0.261924</td>\n",
              "      <td>0.806259</td>\n",
              "      <td>0.795147</td>\n",
              "      <td>0.817687</td>\n",
              "      <td>0.806259</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.83      0.83      4834\n",
              "         ORG       0.74      0.75      0.74      4677\n",
              "         PER       0.91      0.86      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1584</td>\n",
              "      <td>0.252600</td>\n",
              "      <td>0.250163</td>\n",
              "      <td>0.811626</td>\n",
              "      <td>0.803198</td>\n",
              "      <td>0.820232</td>\n",
              "      <td>0.811626</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.82      0.84      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.86      0.90      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1608</td>\n",
              "      <td>0.216700</td>\n",
              "      <td>0.252825</td>\n",
              "      <td>0.813414</td>\n",
              "      <td>0.799986</td>\n",
              "      <td>0.827301</td>\n",
              "      <td>0.813414</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.86      0.84      4834\n",
              "         ORG       0.75      0.73      0.74      4677\n",
              "         PER       0.88      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1632</td>\n",
              "      <td>0.235400</td>\n",
              "      <td>0.244899</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>0.801259</td>\n",
              "      <td>0.818818</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.84      0.84      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1656</td>\n",
              "      <td>0.280800</td>\n",
              "      <td>0.246937</td>\n",
              "      <td>0.806745</td>\n",
              "      <td>0.793828</td>\n",
              "      <td>0.820090</td>\n",
              "      <td>0.806745</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.82      0.83      4834\n",
              "         ORG       0.76      0.74      0.75      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>0.248668</td>\n",
              "      <td>0.807674</td>\n",
              "      <td>0.792984</td>\n",
              "      <td>0.822918</td>\n",
              "      <td>0.807674</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.83      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1704</td>\n",
              "      <td>0.149800</td>\n",
              "      <td>0.261860</td>\n",
              "      <td>0.812700</td>\n",
              "      <td>0.801526</td>\n",
              "      <td>0.824191</td>\n",
              "      <td>0.812700</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.84      0.84      4834\n",
              "         ORG       0.73      0.75      0.74      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1728</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.259046</td>\n",
              "      <td>0.813297</td>\n",
              "      <td>0.804440</td>\n",
              "      <td>0.822353</td>\n",
              "      <td>0.813297</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.85      0.84      4834\n",
              "         ORG       0.77      0.71      0.74      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1752</td>\n",
              "      <td>0.151000</td>\n",
              "      <td>0.262297</td>\n",
              "      <td>0.806603</td>\n",
              "      <td>0.794947</td>\n",
              "      <td>0.818606</td>\n",
              "      <td>0.806603</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.84      4834\n",
              "         ORG       0.75      0.71      0.73      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1776</td>\n",
              "      <td>0.164600</td>\n",
              "      <td>0.263232</td>\n",
              "      <td>0.818648</td>\n",
              "      <td>0.813731</td>\n",
              "      <td>0.823625</td>\n",
              "      <td>0.818648</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.86      0.83      0.84      4834\n",
              "         ORG       0.76      0.74      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.82      0.83     14146\n",
              "   macro avg       0.84      0.82      0.83     14146\n",
              "weighted avg       0.84      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='97' max='417' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 97/417 00:01 < 00:06, 50.86 it/s]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2502' max='2502' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2502/2502 21:37, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Classification Report</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>1.264400</td>\n",
              "      <td>0.817467</td>\n",
              "      <td>0.421248</td>\n",
              "      <td>0.369598</td>\n",
              "      <td>0.489679</td>\n",
              "      <td>0.421248</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.28      0.18      0.22      4834\n",
              "         ORG       0.39      0.15      0.22      4677\n",
              "         PER       0.66      0.72      0.69      4635\n",
              "\n",
              "   micro avg       0.49      0.35      0.41     14146\n",
              "   macro avg       0.44      0.35      0.38     14146\n",
              "weighted avg       0.44      0.35      0.37     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.720900</td>\n",
              "      <td>0.563264</td>\n",
              "      <td>0.481697</td>\n",
              "      <td>0.418967</td>\n",
              "      <td>0.566521</td>\n",
              "      <td>0.481697</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.35      0.49      0.41      4834\n",
              "         ORG       0.47      0.51      0.49      4677\n",
              "         PER       0.77      0.69      0.73      4635\n",
              "\n",
              "   micro avg       0.50      0.56      0.53     14146\n",
              "   macro avg       0.53      0.57      0.54     14146\n",
              "weighted avg       0.53      0.56      0.54     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>72</td>\n",
              "      <td>0.595100</td>\n",
              "      <td>0.467027</td>\n",
              "      <td>0.605884</td>\n",
              "      <td>0.558773</td>\n",
              "      <td>0.661671</td>\n",
              "      <td>0.605884</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.60      0.63      0.61      4834\n",
              "         ORG       0.57      0.51      0.54      4677\n",
              "         PER       0.74      0.81      0.78      4635\n",
              "\n",
              "   micro avg       0.64      0.65      0.65     14146\n",
              "   macro avg       0.64      0.65      0.64     14146\n",
              "weighted avg       0.64      0.65      0.64     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>96</td>\n",
              "      <td>0.447500</td>\n",
              "      <td>0.442492</td>\n",
              "      <td>0.665884</td>\n",
              "      <td>0.633618</td>\n",
              "      <td>0.701612</td>\n",
              "      <td>0.665884</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.65      0.75      0.70      4834\n",
              "         ORG       0.65      0.51      0.57      4677\n",
              "         PER       0.80      0.82      0.81      4635\n",
              "\n",
              "   micro avg       0.70      0.70      0.70     14146\n",
              "   macro avg       0.70      0.70      0.69     14146\n",
              "weighted avg       0.70      0.70      0.69     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.497800</td>\n",
              "      <td>0.446937</td>\n",
              "      <td>0.637484</td>\n",
              "      <td>0.592957</td>\n",
              "      <td>0.689241</td>\n",
              "      <td>0.637484</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.66      0.68      0.67      4834\n",
              "         ORG       0.60      0.52      0.56      4677\n",
              "         PER       0.72      0.85      0.78      4635\n",
              "\n",
              "   micro avg       0.66      0.68      0.67     14146\n",
              "   macro avg       0.66      0.68      0.67     14146\n",
              "weighted avg       0.66      0.68      0.67     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>144</td>\n",
              "      <td>0.438300</td>\n",
              "      <td>0.409320</td>\n",
              "      <td>0.700302</td>\n",
              "      <td>0.666773</td>\n",
              "      <td>0.737382</td>\n",
              "      <td>0.700302</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.75      0.71      0.73      4834\n",
              "         ORG       0.61      0.63      0.62      4677\n",
              "         PER       0.77      0.86      0.81      4635\n",
              "\n",
              "   micro avg       0.71      0.73      0.72     14146\n",
              "   macro avg       0.71      0.73      0.72     14146\n",
              "weighted avg       0.71      0.73      0.72     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>168</td>\n",
              "      <td>0.414800</td>\n",
              "      <td>0.368846</td>\n",
              "      <td>0.712246</td>\n",
              "      <td>0.687660</td>\n",
              "      <td>0.738654</td>\n",
              "      <td>0.712246</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.71      0.74      0.73      4834\n",
              "         ORG       0.66      0.64      0.65      4677\n",
              "         PER       0.86      0.81      0.84      4635\n",
              "\n",
              "   micro avg       0.74      0.73      0.74     14146\n",
              "   macro avg       0.74      0.73      0.74     14146\n",
              "weighted avg       0.74      0.73      0.74     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>192</td>\n",
              "      <td>0.451300</td>\n",
              "      <td>0.369968</td>\n",
              "      <td>0.723576</td>\n",
              "      <td>0.708127</td>\n",
              "      <td>0.739714</td>\n",
              "      <td>0.723576</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.71      0.74      4834\n",
              "         ORG       0.66      0.63      0.64      4677\n",
              "         PER       0.84      0.85      0.84      4635\n",
              "\n",
              "   micro avg       0.76      0.73      0.74     14146\n",
              "   macro avg       0.76      0.73      0.74     14146\n",
              "weighted avg       0.76      0.73      0.74     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>216</td>\n",
              "      <td>0.378600</td>\n",
              "      <td>0.366571</td>\n",
              "      <td>0.730411</td>\n",
              "      <td>0.712490</td>\n",
              "      <td>0.749258</td>\n",
              "      <td>0.730411</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.74      0.80      0.77      4834\n",
              "         ORG       0.67      0.61      0.64      4677\n",
              "         PER       0.88      0.81      0.84      4635\n",
              "\n",
              "   micro avg       0.76      0.74      0.75     14146\n",
              "   macro avg       0.77      0.74      0.75     14146\n",
              "weighted avg       0.77      0.74      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>240</td>\n",
              "      <td>0.425000</td>\n",
              "      <td>0.365239</td>\n",
              "      <td>0.704618</td>\n",
              "      <td>0.687374</td>\n",
              "      <td>0.722748</td>\n",
              "      <td>0.704618</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.74      0.72      0.73      4834\n",
              "         ORG       0.64      0.58      0.61      4677\n",
              "         PER       0.83      0.86      0.84      4635\n",
              "\n",
              "   micro avg       0.74      0.72      0.73     14146\n",
              "   macro avg       0.74      0.72      0.73     14146\n",
              "weighted avg       0.74      0.72      0.73     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>264</td>\n",
              "      <td>0.401400</td>\n",
              "      <td>0.343832</td>\n",
              "      <td>0.724615</td>\n",
              "      <td>0.696415</td>\n",
              "      <td>0.755196</td>\n",
              "      <td>0.724615</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.75      0.75      0.75      4834\n",
              "         ORG       0.70      0.63      0.66      4677\n",
              "         PER       0.80      0.86      0.83      4635\n",
              "\n",
              "   micro avg       0.75      0.75      0.75     14146\n",
              "   macro avg       0.75      0.75      0.75     14146\n",
              "weighted avg       0.75      0.75      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>288</td>\n",
              "      <td>0.378900</td>\n",
              "      <td>0.353318</td>\n",
              "      <td>0.720792</td>\n",
              "      <td>0.692178</td>\n",
              "      <td>0.751873</td>\n",
              "      <td>0.720792</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.72      0.75      4834\n",
              "         ORG       0.65      0.66      0.65      4677\n",
              "         PER       0.77      0.86      0.81      4635\n",
              "\n",
              "   micro avg       0.73      0.75      0.74     14146\n",
              "   macro avg       0.73      0.75      0.74     14146\n",
              "weighted avg       0.73      0.75      0.74     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>312</td>\n",
              "      <td>0.403200</td>\n",
              "      <td>0.356667</td>\n",
              "      <td>0.725152</td>\n",
              "      <td>0.712463</td>\n",
              "      <td>0.738301</td>\n",
              "      <td>0.725152</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.74      0.73      0.74      4834\n",
              "         ORG       0.67      0.62      0.64      4677\n",
              "         PER       0.88      0.84      0.86      4635\n",
              "\n",
              "   micro avg       0.77      0.73      0.75     14146\n",
              "   macro avg       0.77      0.73      0.75     14146\n",
              "weighted avg       0.76      0.73      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>336</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>0.328210</td>\n",
              "      <td>0.743277</td>\n",
              "      <td>0.725468</td>\n",
              "      <td>0.761982</td>\n",
              "      <td>0.743277</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.77      0.77      4834\n",
              "         ORG       0.71      0.64      0.67      4677\n",
              "         PER       0.88      0.85      0.86      4635\n",
              "\n",
              "   micro avg       0.79      0.75      0.77     14146\n",
              "   macro avg       0.79      0.75      0.77     14146\n",
              "weighted avg       0.79      0.75      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>360</td>\n",
              "      <td>0.339700</td>\n",
              "      <td>0.330421</td>\n",
              "      <td>0.752240</td>\n",
              "      <td>0.731229</td>\n",
              "      <td>0.774495</td>\n",
              "      <td>0.752240</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.76      0.80      4834\n",
              "         ORG       0.65      0.68      0.67      4677\n",
              "         PER       0.84      0.87      0.86      4635\n",
              "\n",
              "   micro avg       0.77      0.77      0.77     14146\n",
              "   macro avg       0.78      0.77      0.77     14146\n",
              "weighted avg       0.78      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>384</td>\n",
              "      <td>0.387100</td>\n",
              "      <td>0.324439</td>\n",
              "      <td>0.742709</td>\n",
              "      <td>0.716029</td>\n",
              "      <td>0.771455</td>\n",
              "      <td>0.742709</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.77      0.78      4834\n",
              "         ORG       0.67      0.67      0.67      4677\n",
              "         PER       0.83      0.86      0.85      4635\n",
              "\n",
              "   micro avg       0.76      0.77      0.77     14146\n",
              "   macro avg       0.76      0.77      0.77     14146\n",
              "weighted avg       0.76      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>408</td>\n",
              "      <td>0.346100</td>\n",
              "      <td>0.328409</td>\n",
              "      <td>0.752022</td>\n",
              "      <td>0.729812</td>\n",
              "      <td>0.775626</td>\n",
              "      <td>0.752022</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.77      0.81      0.79      4834\n",
              "         ORG       0.69      0.64      0.66      4677\n",
              "         PER       0.83      0.87      0.85      4635\n",
              "\n",
              "   micro avg       0.77      0.77      0.77     14146\n",
              "   macro avg       0.77      0.77      0.77     14146\n",
              "weighted avg       0.77      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>432</td>\n",
              "      <td>0.350400</td>\n",
              "      <td>0.304922</td>\n",
              "      <td>0.757413</td>\n",
              "      <td>0.741782</td>\n",
              "      <td>0.773717</td>\n",
              "      <td>0.757413</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.80      0.79      4834\n",
              "         ORG       0.70      0.67      0.68      4677\n",
              "         PER       0.87      0.84      0.85      4635\n",
              "\n",
              "   micro avg       0.79      0.77      0.78     14146\n",
              "   macro avg       0.79      0.77      0.78     14146\n",
              "weighted avg       0.79      0.77      0.78     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>456</td>\n",
              "      <td>0.338700</td>\n",
              "      <td>0.317797</td>\n",
              "      <td>0.771710</td>\n",
              "      <td>0.753690</td>\n",
              "      <td>0.790612</td>\n",
              "      <td>0.771710</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.81      0.80      4834\n",
              "         ORG       0.70      0.71      0.71      4677\n",
              "         PER       0.88      0.85      0.86      4635\n",
              "\n",
              "   micro avg       0.79      0.79      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>480</td>\n",
              "      <td>0.325900</td>\n",
              "      <td>0.302561</td>\n",
              "      <td>0.773845</td>\n",
              "      <td>0.763645</td>\n",
              "      <td>0.784321</td>\n",
              "      <td>0.773845</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.79      0.80      4834\n",
              "         ORG       0.73      0.67      0.70      4677\n",
              "         PER       0.88      0.86      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.78      0.79     14146\n",
              "   macro avg       0.81      0.78      0.79     14146\n",
              "weighted avg       0.81      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>504</td>\n",
              "      <td>0.347300</td>\n",
              "      <td>0.325356</td>\n",
              "      <td>0.732381</td>\n",
              "      <td>0.708973</td>\n",
              "      <td>0.757387</td>\n",
              "      <td>0.732381</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.69      0.74      4834\n",
              "         ORG       0.65      0.70      0.67      4677\n",
              "         PER       0.83      0.87      0.85      4635\n",
              "\n",
              "   micro avg       0.75      0.75      0.75     14146\n",
              "   macro avg       0.75      0.75      0.75     14146\n",
              "weighted avg       0.75      0.75      0.75     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>528</td>\n",
              "      <td>0.289300</td>\n",
              "      <td>0.310175</td>\n",
              "      <td>0.768851</td>\n",
              "      <td>0.757075</td>\n",
              "      <td>0.780998</td>\n",
              "      <td>0.768851</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.79      0.80      4834\n",
              "         ORG       0.69      0.67      0.68      4677\n",
              "         PER       0.88      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.79      0.78      0.79     14146\n",
              "   macro avg       0.79      0.78      0.79     14146\n",
              "weighted avg       0.79      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>552</td>\n",
              "      <td>0.366900</td>\n",
              "      <td>0.311943</td>\n",
              "      <td>0.763090</td>\n",
              "      <td>0.752751</td>\n",
              "      <td>0.773717</td>\n",
              "      <td>0.763090</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.83      0.81      4834\n",
              "         ORG       0.72      0.60      0.65      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.77      0.78     14146\n",
              "   macro avg       0.79      0.77      0.78     14146\n",
              "weighted avg       0.78      0.77      0.78     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>576</td>\n",
              "      <td>0.312000</td>\n",
              "      <td>0.296288</td>\n",
              "      <td>0.781849</td>\n",
              "      <td>0.773413</td>\n",
              "      <td>0.790471</td>\n",
              "      <td>0.781849</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.80      0.81      4834\n",
              "         ORG       0.74      0.69      0.71      4677\n",
              "         PER       0.86      0.86      0.86      4635\n",
              "\n",
              "   micro avg       0.80      0.79      0.80     14146\n",
              "   macro avg       0.80      0.79      0.79     14146\n",
              "weighted avg       0.80      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.297000</td>\n",
              "      <td>0.321664</td>\n",
              "      <td>0.754214</td>\n",
              "      <td>0.733195</td>\n",
              "      <td>0.776474</td>\n",
              "      <td>0.754214</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.73      0.76      4834\n",
              "         ORG       0.67      0.72      0.69      4677\n",
              "         PER       0.84      0.88      0.86      4635\n",
              "\n",
              "   micro avg       0.77      0.77      0.77     14146\n",
              "   macro avg       0.77      0.78      0.77     14146\n",
              "weighted avg       0.77      0.77      0.77     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>624</td>\n",
              "      <td>0.309500</td>\n",
              "      <td>0.303848</td>\n",
              "      <td>0.773248</td>\n",
              "      <td>0.757996</td>\n",
              "      <td>0.789128</td>\n",
              "      <td>0.773248</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.76      0.80      4834\n",
              "         ORG       0.67      0.71      0.69      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.78      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>648</td>\n",
              "      <td>0.351400</td>\n",
              "      <td>0.291328</td>\n",
              "      <td>0.779431</td>\n",
              "      <td>0.766899</td>\n",
              "      <td>0.792379</td>\n",
              "      <td>0.779431</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.81      0.82      4834\n",
              "         ORG       0.72      0.66      0.69      4677\n",
              "         PER       0.86      0.89      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.80      0.79      0.79     14146\n",
              "weighted avg       0.80      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>672</td>\n",
              "      <td>0.282400</td>\n",
              "      <td>0.300798</td>\n",
              "      <td>0.781331</td>\n",
              "      <td>0.775188</td>\n",
              "      <td>0.787572</td>\n",
              "      <td>0.781331</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.81      0.80      4834\n",
              "         ORG       0.76      0.67      0.71      4677\n",
              "         PER       0.85      0.87      0.86      4635\n",
              "\n",
              "   micro avg       0.81      0.78      0.79     14146\n",
              "   macro avg       0.80      0.78      0.79     14146\n",
              "weighted avg       0.80      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>696</td>\n",
              "      <td>0.320300</td>\n",
              "      <td>0.291482</td>\n",
              "      <td>0.780678</td>\n",
              "      <td>0.764061</td>\n",
              "      <td>0.798035</td>\n",
              "      <td>0.780678</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.81      0.80      4834\n",
              "         ORG       0.72      0.70      0.71      4677\n",
              "         PER       0.86      0.87      0.87      4635\n",
              "\n",
              "   micro avg       0.80      0.79      0.80     14146\n",
              "   macro avg       0.80      0.79      0.80     14146\n",
              "weighted avg       0.80      0.79      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>720</td>\n",
              "      <td>0.308900</td>\n",
              "      <td>0.294122</td>\n",
              "      <td>0.783831</td>\n",
              "      <td>0.775533</td>\n",
              "      <td>0.792309</td>\n",
              "      <td>0.783831</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.83      0.81      4834\n",
              "         ORG       0.74      0.66      0.70      4677\n",
              "         PER       0.87      0.87      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.81      0.79      0.79     14146\n",
              "weighted avg       0.80      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>744</td>\n",
              "      <td>0.317400</td>\n",
              "      <td>0.298566</td>\n",
              "      <td>0.776970</td>\n",
              "      <td>0.760911</td>\n",
              "      <td>0.793723</td>\n",
              "      <td>0.776970</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.77      0.84      0.80      4834\n",
              "         ORG       0.73      0.66      0.70      4677\n",
              "         PER       0.87      0.86      0.86      4635\n",
              "\n",
              "   micro avg       0.79      0.79      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>768</td>\n",
              "      <td>0.326400</td>\n",
              "      <td>0.278257</td>\n",
              "      <td>0.778759</td>\n",
              "      <td>0.763042</td>\n",
              "      <td>0.795136</td>\n",
              "      <td>0.778759</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.77      0.82      0.79      4834\n",
              "         ORG       0.75      0.68      0.71      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.79      0.79     14146\n",
              "   macro avg       0.79      0.79      0.79     14146\n",
              "weighted avg       0.79      0.79      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>792</td>\n",
              "      <td>0.281500</td>\n",
              "      <td>0.286117</td>\n",
              "      <td>0.784822</td>\n",
              "      <td>0.770394</td>\n",
              "      <td>0.799802</td>\n",
              "      <td>0.784822</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.81      0.81      4834\n",
              "         ORG       0.70      0.73      0.72      4677\n",
              "         PER       0.88      0.85      0.86      4635\n",
              "\n",
              "   micro avg       0.80      0.80      0.80     14146\n",
              "   macro avg       0.80      0.80      0.80     14146\n",
              "weighted avg       0.80      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>816</td>\n",
              "      <td>0.289500</td>\n",
              "      <td>0.279878</td>\n",
              "      <td>0.784232</td>\n",
              "      <td>0.770174</td>\n",
              "      <td>0.798812</td>\n",
              "      <td>0.784232</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.80      0.80      0.80      4834\n",
              "         ORG       0.73      0.72      0.73      4677\n",
              "         PER       0.90      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.81      0.79      0.80     14146\n",
              "weighted avg       0.81      0.79      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>840</td>\n",
              "      <td>0.302300</td>\n",
              "      <td>0.281848</td>\n",
              "      <td>0.787642</td>\n",
              "      <td>0.772156</td>\n",
              "      <td>0.803761</td>\n",
              "      <td>0.787642</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.71      0.71      0.71      4677\n",
              "         PER       0.88      0.86      0.87      4635\n",
              "\n",
              "   micro avg       0.80      0.80      0.80     14146\n",
              "   macro avg       0.80      0.80      0.80     14146\n",
              "weighted avg       0.80      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>864</td>\n",
              "      <td>0.235800</td>\n",
              "      <td>0.292413</td>\n",
              "      <td>0.783642</td>\n",
              "      <td>0.775028</td>\n",
              "      <td>0.792450</td>\n",
              "      <td>0.783642</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.79      0.82      4834\n",
              "         ORG       0.70      0.70      0.70      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.79      0.80     14146\n",
              "   macro avg       0.81      0.79      0.80     14146\n",
              "weighted avg       0.81      0.79      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>888</td>\n",
              "      <td>0.281900</td>\n",
              "      <td>0.286104</td>\n",
              "      <td>0.776127</td>\n",
              "      <td>0.769600</td>\n",
              "      <td>0.782765</td>\n",
              "      <td>0.776127</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.80      0.81      4834\n",
              "         ORG       0.77      0.63      0.69      4677\n",
              "         PER       0.81      0.91      0.85      4635\n",
              "\n",
              "   micro avg       0.81      0.78      0.79     14146\n",
              "   macro avg       0.80      0.78      0.79     14146\n",
              "weighted avg       0.80      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>912</td>\n",
              "      <td>0.269200</td>\n",
              "      <td>0.292363</td>\n",
              "      <td>0.775573</td>\n",
              "      <td>0.767967</td>\n",
              "      <td>0.783331</td>\n",
              "      <td>0.775573</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.77      0.80      4834\n",
              "         ORG       0.75      0.68      0.71      4677\n",
              "         PER       0.82      0.89      0.85      4635\n",
              "\n",
              "   micro avg       0.80      0.78      0.79     14146\n",
              "   macro avg       0.80      0.78      0.79     14146\n",
              "weighted avg       0.80      0.78      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>936</td>\n",
              "      <td>0.247800</td>\n",
              "      <td>0.296327</td>\n",
              "      <td>0.783297</td>\n",
              "      <td>0.759870</td>\n",
              "      <td>0.808214</td>\n",
              "      <td>0.783297</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.85      0.82      4834\n",
              "         ORG       0.72      0.68      0.70      4677\n",
              "         PER       0.87      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.79      0.80      0.80     14146\n",
              "   macro avg       0.79      0.80      0.80     14146\n",
              "weighted avg       0.79      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>960</td>\n",
              "      <td>0.255700</td>\n",
              "      <td>0.295956</td>\n",
              "      <td>0.778267</td>\n",
              "      <td>0.781428</td>\n",
              "      <td>0.775131</td>\n",
              "      <td>0.778267</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.73      0.77      4834\n",
              "         ORG       0.73      0.71      0.72      4677\n",
              "         PER       0.89      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.81      0.77      0.79     14146\n",
              "   macro avg       0.81      0.77      0.79     14146\n",
              "weighted avg       0.81      0.77      0.79     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>984</td>\n",
              "      <td>0.300300</td>\n",
              "      <td>0.265615</td>\n",
              "      <td>0.786220</td>\n",
              "      <td>0.772696</td>\n",
              "      <td>0.800226</td>\n",
              "      <td>0.786220</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.73      0.68      0.71      4677\n",
              "         PER       0.88      0.87      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.80      0.80     14146\n",
              "   macro avg       0.81      0.80      0.80     14146\n",
              "weighted avg       0.81      0.80      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1008</td>\n",
              "      <td>0.225400</td>\n",
              "      <td>0.279130</td>\n",
              "      <td>0.800738</td>\n",
              "      <td>0.788954</td>\n",
              "      <td>0.812880</td>\n",
              "      <td>0.800738</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.82      0.82      4834\n",
              "         ORG       0.73      0.73      0.73      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1032</td>\n",
              "      <td>0.249600</td>\n",
              "      <td>0.270179</td>\n",
              "      <td>0.787747</td>\n",
              "      <td>0.770088</td>\n",
              "      <td>0.806235</td>\n",
              "      <td>0.787747</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.78      0.85      0.81      4834\n",
              "         ORG       0.74      0.68      0.71      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.80      0.81      0.80     14146\n",
              "   macro avg       0.80      0.80      0.80     14146\n",
              "weighted avg       0.80      0.81      0.80     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1056</td>\n",
              "      <td>0.212400</td>\n",
              "      <td>0.288848</td>\n",
              "      <td>0.795228</td>\n",
              "      <td>0.789466</td>\n",
              "      <td>0.801075</td>\n",
              "      <td>0.795228</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.79      0.82      4834\n",
              "         ORG       0.75      0.71      0.73      4677\n",
              "         PER       0.85      0.89      0.87      4635\n",
              "\n",
              "   micro avg       0.82      0.80      0.81     14146\n",
              "   macro avg       0.82      0.80      0.81     14146\n",
              "weighted avg       0.82      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1080</td>\n",
              "      <td>0.284100</td>\n",
              "      <td>0.276123</td>\n",
              "      <td>0.794581</td>\n",
              "      <td>0.787032</td>\n",
              "      <td>0.802276</td>\n",
              "      <td>0.794581</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.83      4834\n",
              "         ORG       0.73      0.68      0.70      4677\n",
              "         PER       0.89      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.80      0.81     14146\n",
              "   macro avg       0.81      0.80      0.81     14146\n",
              "weighted avg       0.81      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1104</td>\n",
              "      <td>0.251700</td>\n",
              "      <td>0.265948</td>\n",
              "      <td>0.802619</td>\n",
              "      <td>0.790940</td>\n",
              "      <td>0.814647</td>\n",
              "      <td>0.802619</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.84      0.82      4834\n",
              "         ORG       0.76      0.72      0.74      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1128</td>\n",
              "      <td>0.235500</td>\n",
              "      <td>0.268074</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>0.787597</td>\n",
              "      <td>0.813375</td>\n",
              "      <td>0.800278</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.82      0.82      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.88      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1152</td>\n",
              "      <td>0.240200</td>\n",
              "      <td>0.270146</td>\n",
              "      <td>0.799148</td>\n",
              "      <td>0.789205</td>\n",
              "      <td>0.809345</td>\n",
              "      <td>0.799148</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.81      0.82      4834\n",
              "         ORG       0.73      0.73      0.73      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1176</td>\n",
              "      <td>0.229600</td>\n",
              "      <td>0.275281</td>\n",
              "      <td>0.794576</td>\n",
              "      <td>0.781853</td>\n",
              "      <td>0.807719</td>\n",
              "      <td>0.794576</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.76      0.70      0.73      4677\n",
              "         PER       0.86      0.88      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.81      0.81     14146\n",
              "   macro avg       0.81      0.81      0.81     14146\n",
              "weighted avg       0.81      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.245300</td>\n",
              "      <td>0.269645</td>\n",
              "      <td>0.802897</td>\n",
              "      <td>0.791215</td>\n",
              "      <td>0.814930</td>\n",
              "      <td>0.802897</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.82      0.83      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.87      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1224</td>\n",
              "      <td>0.268900</td>\n",
              "      <td>0.270039</td>\n",
              "      <td>0.793593</td>\n",
              "      <td>0.781940</td>\n",
              "      <td>0.805599</td>\n",
              "      <td>0.793593</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.83      0.82      4834\n",
              "         ORG       0.76      0.70      0.73      4677\n",
              "         PER       0.89      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.80      0.81     14146\n",
              "   macro avg       0.82      0.80      0.81     14146\n",
              "weighted avg       0.82      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1248</td>\n",
              "      <td>0.236200</td>\n",
              "      <td>0.270506</td>\n",
              "      <td>0.802777</td>\n",
              "      <td>0.800464</td>\n",
              "      <td>0.805104</td>\n",
              "      <td>0.802777</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.83      0.83      4834\n",
              "         ORG       0.77      0.70      0.73      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.80      0.82     14146\n",
              "   macro avg       0.83      0.80      0.81     14146\n",
              "weighted avg       0.83      0.80      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1272</td>\n",
              "      <td>0.226000</td>\n",
              "      <td>0.264204</td>\n",
              "      <td>0.804240</td>\n",
              "      <td>0.790963</td>\n",
              "      <td>0.817970</td>\n",
              "      <td>0.804240</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.84      0.84      4834\n",
              "         ORG       0.74      0.72      0.73      4677\n",
              "         PER       0.86      0.89      0.87      4635\n",
              "\n",
              "   micro avg       0.81      0.82      0.81     14146\n",
              "   macro avg       0.81      0.82      0.81     14146\n",
              "weighted avg       0.81      0.82      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1296</td>\n",
              "      <td>0.213900</td>\n",
              "      <td>0.268963</td>\n",
              "      <td>0.801261</td>\n",
              "      <td>0.794222</td>\n",
              "      <td>0.808426</td>\n",
              "      <td>0.801261</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.86      0.78      0.82      4834\n",
              "         ORG       0.72      0.76      0.74      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.81     14146\n",
              "   macro avg       0.82      0.81      0.81     14146\n",
              "weighted avg       0.82      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1320</td>\n",
              "      <td>0.274400</td>\n",
              "      <td>0.261904</td>\n",
              "      <td>0.799917</td>\n",
              "      <td>0.784138</td>\n",
              "      <td>0.816344</td>\n",
              "      <td>0.799917</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.81      0.82      4834\n",
              "         ORG       0.71      0.75      0.73      4677\n",
              "         PER       0.88      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.81      0.81     14146\n",
              "   macro avg       0.81      0.81      0.81     14146\n",
              "weighted avg       0.81      0.81      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1344</td>\n",
              "      <td>0.201500</td>\n",
              "      <td>0.263989</td>\n",
              "      <td>0.806633</td>\n",
              "      <td>0.803521</td>\n",
              "      <td>0.809770</td>\n",
              "      <td>0.806633</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.83      0.83      4834\n",
              "         ORG       0.76      0.71      0.74      4677\n",
              "         PER       0.89      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1368</td>\n",
              "      <td>0.194900</td>\n",
              "      <td>0.274984</td>\n",
              "      <td>0.807542</td>\n",
              "      <td>0.802274</td>\n",
              "      <td>0.812880</td>\n",
              "      <td>0.807542</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.84      0.83      4834\n",
              "         ORG       0.77      0.70      0.73      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1392</td>\n",
              "      <td>0.225900</td>\n",
              "      <td>0.266891</td>\n",
              "      <td>0.809165</td>\n",
              "      <td>0.799669</td>\n",
              "      <td>0.818889</td>\n",
              "      <td>0.809165</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.81      0.86      0.83      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.89      0.86      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1416</td>\n",
              "      <td>0.188400</td>\n",
              "      <td>0.272946</td>\n",
              "      <td>0.806096</td>\n",
              "      <td>0.799014</td>\n",
              "      <td>0.813304</td>\n",
              "      <td>0.806096</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.83      0.83      4834\n",
              "         ORG       0.75      0.73      0.74      4677\n",
              "         PER       0.91      0.87      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1440</td>\n",
              "      <td>0.186800</td>\n",
              "      <td>0.267854</td>\n",
              "      <td>0.808290</td>\n",
              "      <td>0.800666</td>\n",
              "      <td>0.816061</td>\n",
              "      <td>0.808290</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.83      0.84      4834\n",
              "         ORG       0.77      0.71      0.74      4677\n",
              "         PER       0.86      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1464</td>\n",
              "      <td>0.229200</td>\n",
              "      <td>0.265799</td>\n",
              "      <td>0.805514</td>\n",
              "      <td>0.795437</td>\n",
              "      <td>0.815849</td>\n",
              "      <td>0.805514</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.83      0.83      4834\n",
              "         ORG       0.76      0.73      0.74      4677\n",
              "         PER       0.87      0.88      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.82      0.81      0.82     14146\n",
              "weighted avg       0.82      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1488</td>\n",
              "      <td>0.220000</td>\n",
              "      <td>0.260955</td>\n",
              "      <td>0.806553</td>\n",
              "      <td>0.800599</td>\n",
              "      <td>0.812597</td>\n",
              "      <td>0.806553</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.83      0.83      4834\n",
              "         ORG       0.76      0.72      0.74      4677\n",
              "         PER       0.89      0.87      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1512</td>\n",
              "      <td>0.233500</td>\n",
              "      <td>0.261289</td>\n",
              "      <td>0.799655</td>\n",
              "      <td>0.781625</td>\n",
              "      <td>0.818535</td>\n",
              "      <td>0.799655</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.79      0.87      0.83      4834\n",
              "         ORG       0.77      0.68      0.72      4677\n",
              "         PER       0.86      0.90      0.88      4635\n",
              "\n",
              "   micro avg       0.81      0.82      0.81     14146\n",
              "   macro avg       0.81      0.82      0.81     14146\n",
              "weighted avg       0.81      0.82      0.81     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1536</td>\n",
              "      <td>0.237900</td>\n",
              "      <td>0.249511</td>\n",
              "      <td>0.808119</td>\n",
              "      <td>0.797494</td>\n",
              "      <td>0.819030</td>\n",
              "      <td>0.808119</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.83      0.83      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.87      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1560</td>\n",
              "      <td>0.239400</td>\n",
              "      <td>0.261924</td>\n",
              "      <td>0.806259</td>\n",
              "      <td>0.795147</td>\n",
              "      <td>0.817687</td>\n",
              "      <td>0.806259</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.83      0.83      4834\n",
              "         ORG       0.74      0.75      0.74      4677\n",
              "         PER       0.91      0.86      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1584</td>\n",
              "      <td>0.252600</td>\n",
              "      <td>0.250163</td>\n",
              "      <td>0.811626</td>\n",
              "      <td>0.803198</td>\n",
              "      <td>0.820232</td>\n",
              "      <td>0.811626</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.82      0.84      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.86      0.90      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1608</td>\n",
              "      <td>0.216700</td>\n",
              "      <td>0.252825</td>\n",
              "      <td>0.813414</td>\n",
              "      <td>0.799986</td>\n",
              "      <td>0.827301</td>\n",
              "      <td>0.813414</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.86      0.84      4834\n",
              "         ORG       0.75      0.73      0.74      4677\n",
              "         PER       0.88      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1632</td>\n",
              "      <td>0.235400</td>\n",
              "      <td>0.244899</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>0.801259</td>\n",
              "      <td>0.818818</td>\n",
              "      <td>0.809943</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.84      0.84      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1656</td>\n",
              "      <td>0.280800</td>\n",
              "      <td>0.246937</td>\n",
              "      <td>0.806745</td>\n",
              "      <td>0.793828</td>\n",
              "      <td>0.820090</td>\n",
              "      <td>0.806745</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.82      0.83      4834\n",
              "         ORG       0.76      0.74      0.75      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1680</td>\n",
              "      <td>0.192400</td>\n",
              "      <td>0.248668</td>\n",
              "      <td>0.807674</td>\n",
              "      <td>0.792984</td>\n",
              "      <td>0.822918</td>\n",
              "      <td>0.807674</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.83      4834\n",
              "         ORG       0.75      0.72      0.74      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1704</td>\n",
              "      <td>0.149800</td>\n",
              "      <td>0.261860</td>\n",
              "      <td>0.812700</td>\n",
              "      <td>0.801526</td>\n",
              "      <td>0.824191</td>\n",
              "      <td>0.812700</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.84      0.84      4834\n",
              "         ORG       0.73      0.75      0.74      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1728</td>\n",
              "      <td>0.200000</td>\n",
              "      <td>0.259046</td>\n",
              "      <td>0.813297</td>\n",
              "      <td>0.804440</td>\n",
              "      <td>0.822353</td>\n",
              "      <td>0.813297</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.85      0.84      4834\n",
              "         ORG       0.77      0.71      0.74      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1752</td>\n",
              "      <td>0.151000</td>\n",
              "      <td>0.262297</td>\n",
              "      <td>0.806603</td>\n",
              "      <td>0.794947</td>\n",
              "      <td>0.818606</td>\n",
              "      <td>0.806603</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.84      4834\n",
              "         ORG       0.75      0.71      0.73      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.82      0.82      0.82     14146\n",
              "   macro avg       0.82      0.82      0.82     14146\n",
              "weighted avg       0.82      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1776</td>\n",
              "      <td>0.164600</td>\n",
              "      <td>0.263232</td>\n",
              "      <td>0.818648</td>\n",
              "      <td>0.813731</td>\n",
              "      <td>0.823625</td>\n",
              "      <td>0.818648</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.86      0.83      0.84      4834\n",
              "         ORG       0.76      0.74      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.82      0.83     14146\n",
              "   macro avg       0.84      0.82      0.83     14146\n",
              "weighted avg       0.84      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1800</td>\n",
              "      <td>0.165900</td>\n",
              "      <td>0.256119</td>\n",
              "      <td>0.818773</td>\n",
              "      <td>0.809606</td>\n",
              "      <td>0.828149</td>\n",
              "      <td>0.818773</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.86      0.84      4834\n",
              "         ORG       0.76      0.74      0.75      4677\n",
              "         PER       0.90      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.83      0.83     14146\n",
              "   macro avg       0.83      0.83      0.83     14146\n",
              "weighted avg       0.83      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1824</td>\n",
              "      <td>0.188800</td>\n",
              "      <td>0.254924</td>\n",
              "      <td>0.813630</td>\n",
              "      <td>0.803808</td>\n",
              "      <td>0.823696</td>\n",
              "      <td>0.813630</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.86      0.83      0.84      4834\n",
              "         ORG       0.75      0.74      0.75      4677\n",
              "         PER       0.87      0.89      0.88      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.83     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1848</td>\n",
              "      <td>0.208400</td>\n",
              "      <td>0.255667</td>\n",
              "      <td>0.814141</td>\n",
              "      <td>0.808690</td>\n",
              "      <td>0.819666</td>\n",
              "      <td>0.814141</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.82      0.85      0.84      4834\n",
              "         ORG       0.78      0.71      0.74      4677\n",
              "         PER       0.90      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.83     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1872</td>\n",
              "      <td>0.157100</td>\n",
              "      <td>0.269708</td>\n",
              "      <td>0.814960</td>\n",
              "      <td>0.805258</td>\n",
              "      <td>0.824897</td>\n",
              "      <td>0.814960</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.85      0.84      4834\n",
              "         ORG       0.74      0.76      0.75      4677\n",
              "         PER       0.92      0.86      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.83     14146\n",
              "weighted avg       0.83      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1896</td>\n",
              "      <td>0.154100</td>\n",
              "      <td>0.260531</td>\n",
              "      <td>0.819118</td>\n",
              "      <td>0.812118</td>\n",
              "      <td>0.826241</td>\n",
              "      <td>0.819118</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.86      0.85      4834\n",
              "         ORG       0.77      0.72      0.74      4677\n",
              "         PER       0.89      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.83     14146\n",
              "   macro avg       0.83      0.82      0.83     14146\n",
              "weighted avg       0.83      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1920</td>\n",
              "      <td>0.158600</td>\n",
              "      <td>0.274206</td>\n",
              "      <td>0.810853</td>\n",
              "      <td>0.807302</td>\n",
              "      <td>0.814435</td>\n",
              "      <td>0.810853</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.84      0.84      4834\n",
              "         ORG       0.76      0.73      0.74      4677\n",
              "         PER       0.91      0.86      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.81      0.82     14146\n",
              "   macro avg       0.83      0.81      0.82     14146\n",
              "weighted avg       0.83      0.81      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1944</td>\n",
              "      <td>0.164100</td>\n",
              "      <td>0.267870</td>\n",
              "      <td>0.814849</td>\n",
              "      <td>0.810433</td>\n",
              "      <td>0.819313</td>\n",
              "      <td>0.814849</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.85      0.84      4834\n",
              "         ORG       0.76      0.72      0.74      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.82     14146\n",
              "   macro avg       0.83      0.82      0.82     14146\n",
              "weighted avg       0.83      0.82      0.82     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1968</td>\n",
              "      <td>0.191400</td>\n",
              "      <td>0.259611</td>\n",
              "      <td>0.815911</td>\n",
              "      <td>0.805567</td>\n",
              "      <td>0.826523</td>\n",
              "      <td>0.815911</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.86      0.85      4834\n",
              "         ORG       0.76      0.72      0.74      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.83     14146\n",
              "   macro avg       0.83      0.82      0.83     14146\n",
              "weighted avg       0.83      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1992</td>\n",
              "      <td>0.144100</td>\n",
              "      <td>0.264441</td>\n",
              "      <td>0.818268</td>\n",
              "      <td>0.813947</td>\n",
              "      <td>0.822635</td>\n",
              "      <td>0.818268</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.84      0.85      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.89      0.88      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.82      0.83     14146\n",
              "   macro avg       0.84      0.82      0.83     14146\n",
              "weighted avg       0.84      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2016</td>\n",
              "      <td>0.167200</td>\n",
              "      <td>0.265200</td>\n",
              "      <td>0.818001</td>\n",
              "      <td>0.808098</td>\n",
              "      <td>0.828149</td>\n",
              "      <td>0.818001</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.84      0.84      4834\n",
              "         ORG       0.77      0.75      0.76      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.83      0.83     14146\n",
              "   macro avg       0.83      0.83      0.83     14146\n",
              "weighted avg       0.83      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2040</td>\n",
              "      <td>0.185200</td>\n",
              "      <td>0.257577</td>\n",
              "      <td>0.820529</td>\n",
              "      <td>0.810072</td>\n",
              "      <td>0.831260</td>\n",
              "      <td>0.820529</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.87      0.85      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.83      0.83     14146\n",
              "   macro avg       0.83      0.83      0.83     14146\n",
              "weighted avg       0.83      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2064</td>\n",
              "      <td>0.192000</td>\n",
              "      <td>0.245895</td>\n",
              "      <td>0.817878</td>\n",
              "      <td>0.806250</td>\n",
              "      <td>0.829846</td>\n",
              "      <td>0.817878</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.85      0.84      4834\n",
              "         ORG       0.77      0.74      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.83      0.83     14146\n",
              "   macro avg       0.83      0.83      0.83     14146\n",
              "weighted avg       0.83      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2088</td>\n",
              "      <td>0.169800</td>\n",
              "      <td>0.248236</td>\n",
              "      <td>0.821281</td>\n",
              "      <td>0.814936</td>\n",
              "      <td>0.827725</td>\n",
              "      <td>0.821281</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.86      0.85      4834\n",
              "         ORG       0.79      0.72      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2112</td>\n",
              "      <td>0.180200</td>\n",
              "      <td>0.251892</td>\n",
              "      <td>0.815548</td>\n",
              "      <td>0.806610</td>\n",
              "      <td>0.824685</td>\n",
              "      <td>0.815548</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.87      0.85      4834\n",
              "         ORG       0.79      0.70      0.74      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.82      0.83     14146\n",
              "   macro avg       0.83      0.82      0.83     14146\n",
              "weighted avg       0.83      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2136</td>\n",
              "      <td>0.161900</td>\n",
              "      <td>0.258154</td>\n",
              "      <td>0.817506</td>\n",
              "      <td>0.803606</td>\n",
              "      <td>0.831896</td>\n",
              "      <td>0.817506</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.85      0.84      4834\n",
              "         ORG       0.75      0.75      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.83      0.83      0.83     14146\n",
              "   macro avg       0.83      0.83      0.83     14146\n",
              "weighted avg       0.83      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2160</td>\n",
              "      <td>0.197400</td>\n",
              "      <td>0.253466</td>\n",
              "      <td>0.818376</td>\n",
              "      <td>0.810796</td>\n",
              "      <td>0.826099</td>\n",
              "      <td>0.818376</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.83      0.86      0.85      4834\n",
              "         ORG       0.78      0.71      0.75      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.82      0.83     14146\n",
              "   macro avg       0.83      0.82      0.83     14146\n",
              "weighted avg       0.83      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2184</td>\n",
              "      <td>0.165500</td>\n",
              "      <td>0.251374</td>\n",
              "      <td>0.822948</td>\n",
              "      <td>0.816505</td>\n",
              "      <td>0.829492</td>\n",
              "      <td>0.822948</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.84      0.85      4834\n",
              "         ORG       0.77      0.74      0.76      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2208</td>\n",
              "      <td>0.184400</td>\n",
              "      <td>0.253584</td>\n",
              "      <td>0.820754</td>\n",
              "      <td>0.815202</td>\n",
              "      <td>0.826382</td>\n",
              "      <td>0.820754</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.85      0.85      4834\n",
              "         ORG       0.77      0.73      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.82      0.83     14146\n",
              "   macro avg       0.84      0.82      0.83     14146\n",
              "weighted avg       0.84      0.82      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2232</td>\n",
              "      <td>0.160100</td>\n",
              "      <td>0.253066</td>\n",
              "      <td>0.819405</td>\n",
              "      <td>0.810370</td>\n",
              "      <td>0.828644</td>\n",
              "      <td>0.819405</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.85      0.85      4834\n",
              "         ORG       0.76      0.73      0.75      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2256</td>\n",
              "      <td>0.161000</td>\n",
              "      <td>0.250770</td>\n",
              "      <td>0.822632</td>\n",
              "      <td>0.814453</td>\n",
              "      <td>0.830977</td>\n",
              "      <td>0.822632</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.75      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2280</td>\n",
              "      <td>0.167200</td>\n",
              "      <td>0.252675</td>\n",
              "      <td>0.821577</td>\n",
              "      <td>0.813744</td>\n",
              "      <td>0.829563</td>\n",
              "      <td>0.821577</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.84      0.85      4834\n",
              "         ORG       0.77      0.74      0.76      4677\n",
              "         PER       0.88      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2304</td>\n",
              "      <td>0.205300</td>\n",
              "      <td>0.248152</td>\n",
              "      <td>0.820817</td>\n",
              "      <td>0.811240</td>\n",
              "      <td>0.830623</td>\n",
              "      <td>0.820817</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.75      4677\n",
              "         PER       0.89      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2328</td>\n",
              "      <td>0.177600</td>\n",
              "      <td>0.248635</td>\n",
              "      <td>0.821469</td>\n",
              "      <td>0.814280</td>\n",
              "      <td>0.828786</td>\n",
              "      <td>0.821469</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.75      4677\n",
              "         PER       0.89      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2352</td>\n",
              "      <td>0.155900</td>\n",
              "      <td>0.249455</td>\n",
              "      <td>0.823332</td>\n",
              "      <td>0.815622</td>\n",
              "      <td>0.831189</td>\n",
              "      <td>0.823332</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.76      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2376</td>\n",
              "      <td>0.150900</td>\n",
              "      <td>0.247238</td>\n",
              "      <td>0.823073</td>\n",
              "      <td>0.814164</td>\n",
              "      <td>0.832179</td>\n",
              "      <td>0.823073</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.84      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.76      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2400</td>\n",
              "      <td>0.169500</td>\n",
              "      <td>0.246471</td>\n",
              "      <td>0.822888</td>\n",
              "      <td>0.813398</td>\n",
              "      <td>0.832603</td>\n",
              "      <td>0.822888</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.75      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2424</td>\n",
              "      <td>0.152300</td>\n",
              "      <td>0.246575</td>\n",
              "      <td>0.823381</td>\n",
              "      <td>0.815446</td>\n",
              "      <td>0.831472</td>\n",
              "      <td>0.823381</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.86      0.85      4834\n",
              "         ORG       0.78      0.73      0.75      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2448</td>\n",
              "      <td>0.152500</td>\n",
              "      <td>0.247779</td>\n",
              "      <td>0.824147</td>\n",
              "      <td>0.816542</td>\n",
              "      <td>0.831896</td>\n",
              "      <td>0.824147</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.86      0.85      4834\n",
              "         ORG       0.78      0.74      0.76      4677\n",
              "         PER       0.88      0.90      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2472</td>\n",
              "      <td>0.138600</td>\n",
              "      <td>0.248587</td>\n",
              "      <td>0.823571</td>\n",
              "      <td>0.816363</td>\n",
              "      <td>0.830906</td>\n",
              "      <td>0.823571</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.85      0.85      4834\n",
              "         ORG       0.78      0.74      0.76      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2496</td>\n",
              "      <td>0.153200</td>\n",
              "      <td>0.248740</td>\n",
              "      <td>0.823665</td>\n",
              "      <td>0.816345</td>\n",
              "      <td>0.831118</td>\n",
              "      <td>0.823665</td>\n",
              "      <td>              precision    recall  f1-score   support\n",
              "\n",
              "         LOC       0.85      0.85      0.85      4834\n",
              "         ORG       0.78      0.74      0.76      4677\n",
              "         PER       0.89      0.89      0.89      4635\n",
              "\n",
              "   micro avg       0.84      0.83      0.83     14146\n",
              "   macro avg       0.84      0.83      0.83     14146\n",
              "weighted avg       0.84      0.83      0.83     14146\n",
              "</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2502, training_loss=0.26952576098872794, metrics={'train_runtime': 1297.3455, 'train_samples_per_second': 46.248, 'train_steps_per_second': 1.929, 'total_flos': 1178415902403696.0, 'train_loss': 0.26952576098872794, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.push_to_hub(commit_message=\"Training completed!\")"
      ],
      "metadata": {
        "id": "h8a9fHXNcrc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 499,
          "referenced_widgets": [
            "2bd902565da3409cb441dd8d9c1e5fa9",
            "f6c772409b5248a696b7663e604e98ca",
            "f733929bd8aa48e6b7115aacd245a558",
            "6c93104af8a84130988d3716e403a34e",
            "b67b4b2ddafd42aeb82021d358ff41dc",
            "78e6f3da4ce349dbb065608e703cf566",
            "061b2f0f66144553813a0ad856d40cd9",
            "95581e28744341cfb8e2b425858c2c28",
            "18355ff63cf94f1cb83548bf41fb19ab",
            "6d7bdf9bfdbf40208861ccf665472ef1",
            "41f5d400f65145e58163b9adadee6e43",
            "4229582572dc44c598064b32c93a95e1",
            "4af31c739e2e43f1ba112147911d377b",
            "2717bfca4ff9464298f9c9a01aed3764",
            "ed8f15fe667b43d7ba2fb193573174e2",
            "e24eb9a5f3dd46c3b7bb838f498cfa44",
            "6dd21778c05e43678d12839bfc2a0144",
            "800aac9c0d4a4344a4f28b082a675c85",
            "6480352cac5d4817be0b79f6974ea2a8",
            "a7b003855c3840238a42d33d8c793307",
            "4b136e92ea014d5381321e311dff4193",
            "812ab68c1726436483bbe36723a469f6",
            "4916f09e34d646d68e0e7852a503621c",
            "f01c19169c1d4f22ac84129b2b996619",
            "eaf985d32e484885a828839aaac78e9b",
            "e06590f8e6a34492a0b31530fa420354",
            "1a751103c0e24f288db2f8cd9116676d",
            "95f825d1965245e8a65838380499d81a",
            "d1ba6e38802e4269aa03d0ccdaf2fc66",
            "1813578b10044392b8f0f08559366f22",
            "55f9a258f9084e7c90a8e98cee4a83c9",
            "6897c957756147d68ca2a26714364e5c",
            "60d3f1889c3747b7ab99e3f848868254",
            "509e4199d93942eebdbf99ccb35ee6ec",
            "0e3a57c4debe45059414d73617aa164e",
            "0ab8083d5d0d4e46bc111366154484fe",
            "af706c4ce1a04c1c9ff6c88dd8eb892e",
            "e3def8ec302e46c79e1754c1c7492929",
            "38728af8b711466ab7510d5cc4de23d5",
            "f7a49df0a6e640b0829419b586097546",
            "b7f9289e5e954791a1183873a3844ee1",
            "e75f9345347c4ad29ec3c4ab451be13c",
            "39555820013f45a1a0ef8fc72fd462f3",
            "b4714e1f4c41437f99beb37fb7b832f0",
            "0ce179a36504419da80fc25372613d1e",
            "1c76b4f7792d496e8b10eb821a2b44ea",
            "d39cf3cdfd6544d6b40313de8290efd1",
            "ba1e9472a2f74ee0989061b3aab83e1d",
            "3909d3f91ff243328a1700c528114cfa",
            "deccb00a6c68446ea717cedd3bea350e",
            "7e4ce39479564642a30b389132747de2",
            "ed5e341c847a41d2afdbf214864ae88a",
            "b64e166771cb4b0c92e9dd454ac463dc",
            "20eae14efe634a549b3e1dd0c8103a05",
            "6edc9187e5fb431782e53814dceab32a"
          ]
        },
        "outputId": "b5ac931c-8118-4829-bd7c-75fb02edbefa"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file pytorch_model.bin:   0%|          | 1.00/1.03G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2bd902565da3409cb441dd8d9c1e5fa9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file sentencepiece.bpe.model:   0%|          | 1.00/4.83M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4229582572dc44c598064b32c93a95e1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file training_args.bin:   0%|          | 1.00/2.81k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4916f09e34d646d68e0e7852a503621c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file runs/Apr14_14-04-19_7ded55b56291/1681481133.6566057/events.out.tfevents.1681481133.7ded55b56291.48…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "509e4199d93942eebdbf99ccb35ee6ec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Upload file runs/Apr14_14-04-19_7ded55b56291/events.out.tfevents.1681481133.7ded55b56291.48074.12:   0%|      …"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0ce179a36504419da80fc25372613d1e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "To https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en\n",
            "   902b70b..2ce5da4  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en\n",
            "   902b70b..2ce5da4  main -> main\n",
            "\n",
            "To https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en\n",
            "   2ce5da4..1de6d86  main -> main\n",
            "\n",
            "WARNING:huggingface_hub.repository:To https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en\n",
            "   2ce5da4..1de6d86  main -> main\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'https://huggingface.co/maren-hugg/xlm-roberta-base-finetuned-panx-en/commit/2ce5da4f205928dfdfe761485ed0931a9b4c5088'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "metrics_train=trainer.state.log_history\n",
        "for item in metrics_train:\n",
        "  print(item)"
      ],
      "metadata": {
        "id": "-XKfz8q0mypE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bf9ba6c-b068-48c3-956d-a1f2dc044bed"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'loss': 1.2644, 'learning_rate': 4.9520383693045564e-05, 'epoch': 0.03, 'step': 24}\n",
            "{'eval_loss': 0.8174670934677124, 'eval_f1': 0.4212478715640963, 'eval_precision': 0.3695976950165404, 'eval_recall': 0.48967906121871907, 'eval_accuracy': 0.4212478715640963, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.28      0.18      0.22      4834\\n         ORG       0.39      0.15      0.22      4677\\n         PER       0.66      0.72      0.69      4635\\n\\n   micro avg       0.49      0.35      0.41     14146\\n   macro avg       0.44      0.35      0.38     14146\\nweighted avg       0.44      0.35      0.37     14146\\n', 'eval_runtime': 10.5164, 'eval_samples_per_second': 950.892, 'eval_steps_per_second': 39.652, 'epoch': 0.03, 'step': 24}\n",
            "{'loss': 0.7209, 'learning_rate': 4.904076738609113e-05, 'epoch': 0.06, 'step': 48}\n",
            "{'eval_loss': 0.5632641315460205, 'eval_f1': 0.48169742141011, 'eval_precision': 0.4189669594312003, 'eval_recall': 0.566520571186201, 'eval_accuracy': 0.48169742141011, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.35      0.49      0.41      4834\\n         ORG       0.47      0.51      0.49      4677\\n         PER       0.77      0.69      0.73      4635\\n\\n   micro avg       0.50      0.56      0.53     14146\\n   macro avg       0.53      0.57      0.54     14146\\nweighted avg       0.53      0.56      0.54     14146\\n', 'eval_runtime': 10.8464, 'eval_samples_per_second': 921.968, 'eval_steps_per_second': 38.446, 'epoch': 0.06, 'step': 48}\n",
            "{'loss': 0.5951, 'learning_rate': 4.8561151079136694e-05, 'epoch': 0.09, 'step': 72}\n",
            "{'eval_loss': 0.4670272469520569, 'eval_f1': 0.6058840664142149, 'eval_precision': 0.5587726105904125, 'eval_recall': 0.6616711437862294, 'eval_accuracy': 0.6058840664142149, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.60      0.63      0.61      4834\\n         ORG       0.57      0.51      0.54      4677\\n         PER       0.74      0.81      0.78      4635\\n\\n   micro avg       0.64      0.65      0.65     14146\\n   macro avg       0.64      0.65      0.64     14146\\nweighted avg       0.64      0.65      0.64     14146\\n', 'eval_runtime': 10.5607, 'eval_samples_per_second': 946.909, 'eval_steps_per_second': 39.486, 'epoch': 0.09, 'step': 72}\n",
            "{'loss': 0.4475, 'learning_rate': 4.8081534772182255e-05, 'epoch': 0.12, 'step': 96}\n",
            "{'eval_loss': 0.44249188899993896, 'eval_f1': 0.6658839315665884, 'eval_precision': 0.6336184882533197, 'eval_recall': 0.7016117630425562, 'eval_accuracy': 0.6658839315665884, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.65      0.75      0.70      4834\\n         ORG       0.65      0.51      0.57      4677\\n         PER       0.80      0.82      0.81      4635\\n\\n   micro avg       0.70      0.70      0.70     14146\\n   macro avg       0.70      0.70      0.69     14146\\nweighted avg       0.70      0.70      0.69     14146\\n', 'eval_runtime': 10.5551, 'eval_samples_per_second': 947.413, 'eval_steps_per_second': 39.507, 'epoch': 0.12, 'step': 96}\n",
            "{'loss': 0.4978, 'learning_rate': 4.7601918465227817e-05, 'epoch': 0.14, 'step': 120}\n",
            "{'eval_loss': 0.4469367265701294, 'eval_f1': 0.6374840628984276, 'eval_precision': 0.5929574895092137, 'eval_recall': 0.6892407747773223, 'eval_accuracy': 0.6374840628984276, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.66      0.68      0.67      4834\\n         ORG       0.60      0.52      0.56      4677\\n         PER       0.72      0.85      0.78      4635\\n\\n   micro avg       0.66      0.68      0.67     14146\\n   macro avg       0.66      0.68      0.67     14146\\nweighted avg       0.66      0.68      0.67     14146\\n', 'eval_runtime': 10.7964, 'eval_samples_per_second': 926.231, 'eval_steps_per_second': 38.624, 'epoch': 0.14, 'step': 120}\n",
            "{'loss': 0.4383, 'learning_rate': 4.7122302158273385e-05, 'epoch': 0.17, 'step': 144}\n",
            "{'eval_loss': 0.4093199074268341, 'eval_f1': 0.7003021148036254, 'eval_precision': 0.6667732037841985, 'eval_recall': 0.7373815919694613, 'eval_accuracy': 0.7003021148036254, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.75      0.71      0.73      4834\\n         ORG       0.61      0.63      0.62      4677\\n         PER       0.77      0.86      0.81      4635\\n\\n   micro avg       0.71      0.73      0.72     14146\\n   macro avg       0.71      0.73      0.72     14146\\nweighted avg       0.71      0.73      0.72     14146\\n', 'eval_runtime': 10.5726, 'eval_samples_per_second': 945.844, 'eval_steps_per_second': 39.442, 'epoch': 0.17, 'step': 144}\n",
            "{'loss': 0.4148, 'learning_rate': 4.6642685851318946e-05, 'epoch': 0.2, 'step': 168}\n",
            "{'eval_loss': 0.3688462972640991, 'eval_f1': 0.7122456630653352, 'eval_precision': 0.6876604146100691, 'eval_recall': 0.7386540364767425, 'eval_accuracy': 0.7122456630653352, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.71      0.74      0.73      4834\\n         ORG       0.66      0.64      0.65      4677\\n         PER       0.86      0.81      0.84      4635\\n\\n   micro avg       0.74      0.73      0.74     14146\\n   macro avg       0.74      0.73      0.74     14146\\nweighted avg       0.74      0.73      0.74     14146\\n', 'eval_runtime': 10.7978, 'eval_samples_per_second': 926.112, 'eval_steps_per_second': 38.619, 'epoch': 0.2, 'step': 168}\n",
            "{'loss': 0.4513, 'learning_rate': 4.6163069544364515e-05, 'epoch': 0.23, 'step': 192}\n",
            "{'eval_loss': 0.369968444108963, 'eval_f1': 0.7235763924904056, 'eval_precision': 0.7081274954320904, 'eval_recall': 0.7397144068994769, 'eval_accuracy': 0.7235763924904056, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.71      0.74      4834\\n         ORG       0.66      0.63      0.64      4677\\n         PER       0.84      0.85      0.84      4635\\n\\n   micro avg       0.76      0.73      0.74     14146\\n   macro avg       0.76      0.73      0.74     14146\\nweighted avg       0.76      0.73      0.74     14146\\n', 'eval_runtime': 10.5477, 'eval_samples_per_second': 948.078, 'eval_steps_per_second': 39.535, 'epoch': 0.23, 'step': 192}\n",
            "{'loss': 0.3786, 'learning_rate': 4.5683453237410076e-05, 'epoch': 0.26, 'step': 216}\n",
            "{'eval_loss': 0.3665705621242523, 'eval_f1': 0.7304114120322515, 'eval_precision': 0.7124899166442592, 'eval_recall': 0.7492577407040859, 'eval_accuracy': 0.7304114120322515, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.74      0.80      0.77      4834\\n         ORG       0.67      0.61      0.64      4677\\n         PER       0.88      0.81      0.84      4635\\n\\n   micro avg       0.76      0.74      0.75     14146\\n   macro avg       0.77      0.74      0.75     14146\\nweighted avg       0.77      0.74      0.75     14146\\n', 'eval_runtime': 10.5743, 'eval_samples_per_second': 945.686, 'eval_steps_per_second': 39.435, 'epoch': 0.26, 'step': 216}\n",
            "{'loss': 0.425, 'learning_rate': 4.520383693045564e-05, 'epoch': 0.29, 'step': 240}\n",
            "{'eval_loss': 0.3652386963367462, 'eval_f1': 0.7046175051688491, 'eval_precision': 0.6873739411052844, 'eval_recall': 0.7227484801357275, 'eval_accuracy': 0.7046175051688491, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.74      0.72      0.73      4834\\n         ORG       0.64      0.58      0.61      4677\\n         PER       0.83      0.86      0.84      4635\\n\\n   micro avg       0.74      0.72      0.73     14146\\n   macro avg       0.74      0.72      0.73     14146\\nweighted avg       0.74      0.72      0.73     14146\\n', 'eval_runtime': 10.8499, 'eval_samples_per_second': 921.67, 'eval_steps_per_second': 38.434, 'epoch': 0.29, 'step': 240}\n",
            "{'loss': 0.4014, 'learning_rate': 4.47242206235012e-05, 'epoch': 0.32, 'step': 264}\n",
            "{'eval_loss': 0.3438316583633423, 'eval_f1': 0.7246150715593841, 'eval_precision': 0.6964146023468057, 'eval_recall': 0.7551958150713983, 'eval_accuracy': 0.7246150715593841, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.75      0.75      0.75      4834\\n         ORG       0.70      0.63      0.66      4677\\n         PER       0.80      0.86      0.83      4635\\n\\n   micro avg       0.75      0.75      0.75     14146\\n   macro avg       0.75      0.75      0.75     14146\\nweighted avg       0.75      0.75      0.75     14146\\n', 'eval_runtime': 10.5569, 'eval_samples_per_second': 947.249, 'eval_steps_per_second': 39.5, 'epoch': 0.32, 'step': 264}\n",
            "{'loss': 0.3789, 'learning_rate': 4.424460431654677e-05, 'epoch': 0.35, 'step': 288}\n",
            "{'eval_loss': 0.3533177673816681, 'eval_f1': 0.720791542423421, 'eval_precision': 0.6921775348171287, 'eval_recall': 0.751873321080164, 'eval_accuracy': 0.720791542423421, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.72      0.75      4834\\n         ORG       0.65      0.66      0.65      4677\\n         PER       0.77      0.86      0.81      4635\\n\\n   micro avg       0.73      0.75      0.74     14146\\n   macro avg       0.73      0.75      0.74     14146\\nweighted avg       0.73      0.75      0.74     14146\\n', 'eval_runtime': 10.5732, 'eval_samples_per_second': 945.788, 'eval_steps_per_second': 39.439, 'epoch': 0.35, 'step': 288}\n",
            "{'loss': 0.4032, 'learning_rate': 4.376498800959233e-05, 'epoch': 0.37, 'step': 312}\n",
            "{'eval_loss': 0.356666624546051, 'eval_f1': 0.7251518833535844, 'eval_precision': 0.7124633331059418, 'eval_recall': 0.7383005796691644, 'eval_accuracy': 0.7251518833535844, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.74      0.73      0.74      4834\\n         ORG       0.67      0.62      0.64      4677\\n         PER       0.88      0.84      0.86      4635\\n\\n   micro avg       0.77      0.73      0.75     14146\\n   macro avg       0.77      0.73      0.75     14146\\nweighted avg       0.76      0.73      0.75     14146\\n', 'eval_runtime': 10.8507, 'eval_samples_per_second': 921.6, 'eval_steps_per_second': 38.431, 'epoch': 0.37, 'step': 312}\n",
            "{'loss': 0.371, 'learning_rate': 4.328537170263789e-05, 'epoch': 0.4, 'step': 336}\n",
            "{'eval_loss': 0.3282099664211273, 'eval_f1': 0.7432767894083575, 'eval_precision': 0.7254677614752995, 'eval_recall': 0.761982185776898, 'eval_accuracy': 0.7432767894083575, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.77      0.77      4834\\n         ORG       0.71      0.64      0.67      4677\\n         PER       0.88      0.85      0.86      4635\\n\\n   micro avg       0.79      0.75      0.77     14146\\n   macro avg       0.79      0.75      0.77     14146\\nweighted avg       0.79      0.75      0.77     14146\\n', 'eval_runtime': 10.6031, 'eval_samples_per_second': 943.123, 'eval_steps_per_second': 39.328, 'epoch': 0.4, 'step': 336}\n",
            "{'loss': 0.3397, 'learning_rate': 4.280575539568346e-05, 'epoch': 0.43, 'step': 360}\n",
            "{'eval_loss': 0.33042147755622864, 'eval_f1': 0.7522400357032512, 'eval_precision': 0.7312287258893413, 'eval_recall': 0.7744945567651633, 'eval_accuracy': 0.7522400357032512, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.76      0.80      4834\\n         ORG       0.65      0.68      0.67      4677\\n         PER       0.84      0.87      0.86      4635\\n\\n   micro avg       0.77      0.77      0.77     14146\\n   macro avg       0.78      0.77      0.77     14146\\nweighted avg       0.78      0.77      0.77     14146\\n', 'eval_runtime': 10.537, 'eval_samples_per_second': 949.033, 'eval_steps_per_second': 39.575, 'epoch': 0.43, 'step': 360}\n",
            "{'loss': 0.3871, 'learning_rate': 4.232613908872902e-05, 'epoch': 0.46, 'step': 384}\n",
            "{'eval_loss': 0.32443851232528687, 'eval_f1': 0.7427093612821997, 'eval_precision': 0.7160291319467227, 'eval_recall': 0.7714548282199916, 'eval_accuracy': 0.7427093612821997, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.79      0.77      0.78      4834\\n         ORG       0.67      0.67      0.67      4677\\n         PER       0.83      0.86      0.85      4635\\n\\n   micro avg       0.76      0.77      0.77     14146\\n   macro avg       0.76      0.77      0.77     14146\\nweighted avg       0.76      0.77      0.77     14146\\n', 'eval_runtime': 10.7803, 'eval_samples_per_second': 927.619, 'eval_steps_per_second': 38.682, 'epoch': 0.46, 'step': 384}\n",
            "{'loss': 0.3461, 'learning_rate': 4.184652278177458e-05, 'epoch': 0.49, 'step': 408}\n",
            "{'eval_loss': 0.3284088373184204, 'eval_f1': 0.752021932830706, 'eval_precision': 0.7298124251696155, 'eval_recall': 0.7756256185494133, 'eval_accuracy': 0.752021932830706, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.77      0.81      0.79      4834\\n         ORG       0.69      0.64      0.66      4677\\n         PER       0.83      0.87      0.85      4635\\n\\n   micro avg       0.77      0.77      0.77     14146\\n   macro avg       0.77      0.77      0.77     14146\\nweighted avg       0.77      0.77      0.77     14146\\n', 'eval_runtime': 10.5753, 'eval_samples_per_second': 945.596, 'eval_steps_per_second': 39.431, 'epoch': 0.49, 'step': 408}\n",
            "{'loss': 0.3504, 'learning_rate': 4.136690647482014e-05, 'epoch': 0.52, 'step': 432}\n",
            "{'eval_loss': 0.3049219250679016, 'eval_f1': 0.7574132382962527, 'eval_precision': 0.7417824466282616, 'eval_recall': 0.7737169517884914, 'eval_accuracy': 0.7574132382962527, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.79      0.80      0.79      4834\\n         ORG       0.70      0.67      0.68      4677\\n         PER       0.87      0.84      0.85      4635\\n\\n   micro avg       0.79      0.77      0.78     14146\\n   macro avg       0.79      0.77      0.78     14146\\nweighted avg       0.79      0.77      0.78     14146\\n', 'eval_runtime': 10.8576, 'eval_samples_per_second': 921.017, 'eval_steps_per_second': 38.406, 'epoch': 0.52, 'step': 432}\n",
            "{'loss': 0.3387, 'learning_rate': 4.088729016786571e-05, 'epoch': 0.55, 'step': 456}\n",
            "{'eval_loss': 0.317796915769577, 'eval_f1': 0.771709504916336, 'eval_precision': 0.7536896017251836, 'eval_recall': 0.7906121871907253, 'eval_accuracy': 0.771709504916336, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.79      0.81      0.80      4834\\n         ORG       0.70      0.71      0.71      4677\\n         PER       0.88      0.85      0.86      4635\\n\\n   micro avg       0.79      0.79      0.79     14146\\n   macro avg       0.79      0.79      0.79     14146\\nweighted avg       0.79      0.79      0.79     14146\\n', 'eval_runtime': 10.5466, 'eval_samples_per_second': 948.17, 'eval_steps_per_second': 39.539, 'epoch': 0.55, 'step': 456}\n",
            "{'loss': 0.3259, 'learning_rate': 4.040767386091127e-05, 'epoch': 0.58, 'step': 480}\n",
            "{'eval_loss': 0.3025607764720917, 'eval_f1': 0.7738448125544901, 'eval_precision': 0.7636451235460114, 'eval_recall': 0.7843206560158349, 'eval_accuracy': 0.7738448125544901, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.79      0.80      4834\\n         ORG       0.73      0.67      0.70      4677\\n         PER       0.88      0.86      0.87      4635\\n\\n   micro avg       0.81      0.78      0.79     14146\\n   macro avg       0.81      0.78      0.79     14146\\nweighted avg       0.81      0.78      0.79     14146\\n', 'eval_runtime': 10.5465, 'eval_samples_per_second': 948.182, 'eval_steps_per_second': 39.539, 'epoch': 0.58, 'step': 480}\n",
            "{'loss': 0.3473, 'learning_rate': 3.992805755395684e-05, 'epoch': 0.6, 'step': 504}\n",
            "{'eval_loss': 0.32535645365715027, 'eval_f1': 0.732380887278693, 'eval_precision': 0.7089730015881419, 'eval_recall': 0.7573872472783826, 'eval_accuracy': 0.732380887278693, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.79      0.69      0.74      4834\\n         ORG       0.65      0.70      0.67      4677\\n         PER       0.83      0.87      0.85      4635\\n\\n   micro avg       0.75      0.75      0.75     14146\\n   macro avg       0.75      0.75      0.75     14146\\nweighted avg       0.75      0.75      0.75     14146\\n', 'eval_runtime': 10.7717, 'eval_samples_per_second': 928.356, 'eval_steps_per_second': 38.712, 'epoch': 0.6, 'step': 504}\n",
            "{'loss': 0.2893, 'learning_rate': 3.9448441247002396e-05, 'epoch': 0.63, 'step': 528}\n",
            "{'eval_loss': 0.3101753890514374, 'eval_f1': 0.7688506906990502, 'eval_precision': 0.7570753100801755, 'eval_recall': 0.7809981620246006, 'eval_accuracy': 0.7688506906990502, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.79      0.80      4834\\n         ORG       0.69      0.67      0.68      4677\\n         PER       0.88      0.87      0.88      4635\\n\\n   micro avg       0.79      0.78      0.79     14146\\n   macro avg       0.79      0.78      0.79     14146\\nweighted avg       0.79      0.78      0.79     14146\\n', 'eval_runtime': 10.5722, 'eval_samples_per_second': 945.875, 'eval_steps_per_second': 39.443, 'epoch': 0.63, 'step': 528}\n",
            "{'loss': 0.3669, 'learning_rate': 3.8968824940047964e-05, 'epoch': 0.66, 'step': 552}\n",
            "{'eval_loss': 0.3119426667690277, 'eval_f1': 0.7630900090636548, 'eval_precision': 0.7527510316368639, 'eval_recall': 0.7737169517884914, 'eval_accuracy': 0.7630900090636548, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.83      0.81      4834\\n         ORG       0.72      0.60      0.65      4677\\n         PER       0.86      0.88      0.87      4635\\n\\n   micro avg       0.79      0.77      0.78     14146\\n   macro avg       0.79      0.77      0.78     14146\\nweighted avg       0.78      0.77      0.78     14146\\n', 'eval_runtime': 10.5761, 'eval_samples_per_second': 945.526, 'eval_steps_per_second': 39.428, 'epoch': 0.66, 'step': 552}\n",
            "{'loss': 0.312, 'learning_rate': 3.8489208633093525e-05, 'epoch': 0.69, 'step': 576}\n",
            "{'eval_loss': 0.29628825187683105, 'eval_f1': 0.7818486924905608, 'eval_precision': 0.773412643519159, 'eval_recall': 0.790470804467694, 'eval_accuracy': 0.7818486924905608, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.80      0.81      4834\\n         ORG       0.74      0.69      0.71      4677\\n         PER       0.86      0.86      0.86      4635\\n\\n   micro avg       0.80      0.79      0.80     14146\\n   macro avg       0.80      0.79      0.79     14146\\nweighted avg       0.80      0.79      0.79     14146\\n', 'eval_runtime': 10.8557, 'eval_samples_per_second': 921.172, 'eval_steps_per_second': 38.413, 'epoch': 0.69, 'step': 576}\n",
            "{'loss': 0.297, 'learning_rate': 3.8009592326139094e-05, 'epoch': 0.72, 'step': 600}\n",
            "{'eval_loss': 0.3216639757156372, 'eval_f1': 0.754214302880489, 'eval_precision': 0.7331953808156999, 'eval_recall': 0.7764739148876008, 'eval_accuracy': 0.754214302880489, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.73      0.76      4834\\n         ORG       0.67      0.72      0.69      4677\\n         PER       0.84      0.88      0.86      4635\\n\\n   micro avg       0.77      0.77      0.77     14146\\n   macro avg       0.77      0.78      0.77     14146\\nweighted avg       0.77      0.77      0.77     14146\\n', 'eval_runtime': 10.5495, 'eval_samples_per_second': 947.915, 'eval_steps_per_second': 39.528, 'epoch': 0.72, 'step': 600}\n",
            "{'loss': 0.3095, 'learning_rate': 3.7529976019184655e-05, 'epoch': 0.75, 'step': 624}\n",
            "{'eval_loss': 0.30384814739227295, 'eval_f1': 0.7732483635230145, 'eval_precision': 0.7579955184355266, 'eval_recall': 0.7891276685988973, 'eval_accuracy': 0.7732483635230145, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.76      0.80      4834\\n         ORG       0.67      0.71      0.69      4677\\n         PER       0.86      0.88      0.87      4635\\n\\n   micro avg       0.79      0.78      0.79     14146\\n   macro avg       0.79      0.79      0.79     14146\\nweighted avg       0.79      0.78      0.79     14146\\n', 'eval_runtime': 10.8069, 'eval_samples_per_second': 925.335, 'eval_steps_per_second': 38.586, 'epoch': 0.75, 'step': 624}\n",
            "{'loss': 0.3514, 'learning_rate': 3.7050359712230217e-05, 'epoch': 0.78, 'step': 648}\n",
            "{'eval_loss': 0.2913283705711365, 'eval_f1': 0.779431193936444, 'eval_precision': 0.7668992884510126, 'eval_recall': 0.7923794712286159, 'eval_accuracy': 0.779431193936444, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.81      0.82      4834\\n         ORG       0.72      0.66      0.69      4677\\n         PER       0.86      0.89      0.87      4635\\n\\n   micro avg       0.81      0.79      0.80     14146\\n   macro avg       0.80      0.79      0.79     14146\\nweighted avg       0.80      0.79      0.79     14146\\n', 'eval_runtime': 10.5711, 'eval_samples_per_second': 945.979, 'eval_steps_per_second': 39.447, 'epoch': 0.78, 'step': 648}\n",
            "{'loss': 0.2824, 'learning_rate': 3.657074340527578e-05, 'epoch': 0.81, 'step': 672}\n",
            "{'eval_loss': 0.3007977604866028, 'eval_f1': 0.7813310891366856, 'eval_precision': 0.7751878652936265, 'eval_recall': 0.7875724586455535, 'eval_accuracy': 0.7813310891366856, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.81      0.80      4834\\n         ORG       0.76      0.67      0.71      4677\\n         PER       0.85      0.87      0.86      4635\\n\\n   micro avg       0.81      0.78      0.79     14146\\n   macro avg       0.80      0.78      0.79     14146\\nweighted avg       0.80      0.78      0.79     14146\\n', 'eval_runtime': 10.5862, 'eval_samples_per_second': 944.625, 'eval_steps_per_second': 39.391, 'epoch': 0.81, 'step': 672}\n",
            "{'loss': 0.3203, 'learning_rate': 3.609112709832134e-05, 'epoch': 0.83, 'step': 696}\n",
            "{'eval_loss': 0.29148194193840027, 'eval_f1': 0.7806783997787076, 'eval_precision': 0.7640609137055837, 'eval_recall': 0.7980347801498657, 'eval_accuracy': 0.7806783997787076, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.81      0.80      4834\\n         ORG       0.72      0.70      0.71      4677\\n         PER       0.86      0.87      0.87      4635\\n\\n   micro avg       0.80      0.79      0.80     14146\\n   macro avg       0.80      0.79      0.80     14146\\nweighted avg       0.80      0.79      0.80     14146\\n', 'eval_runtime': 10.8153, 'eval_samples_per_second': 924.614, 'eval_steps_per_second': 38.556, 'epoch': 0.83, 'step': 696}\n",
            "{'loss': 0.3089, 'learning_rate': 3.561151079136691e-05, 'epoch': 0.86, 'step': 720}\n",
            "{'eval_loss': 0.294121652841568, 'eval_f1': 0.7838310371354641, 'eval_precision': 0.7755327982286189, 'eval_recall': 0.7923087798671002, 'eval_accuracy': 0.7838310371354641, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.83      0.81      4834\\n         ORG       0.74      0.66      0.70      4677\\n         PER       0.87      0.87      0.87      4635\\n\\n   micro avg       0.81      0.79      0.80     14146\\n   macro avg       0.81      0.79      0.79     14146\\nweighted avg       0.80      0.79      0.79     14146\\n', 'eval_runtime': 10.6101, 'eval_samples_per_second': 942.501, 'eval_steps_per_second': 39.302, 'epoch': 0.86, 'step': 720}\n",
            "{'loss': 0.3174, 'learning_rate': 3.513189448441247e-05, 'epoch': 0.89, 'step': 744}\n",
            "{'eval_loss': 0.29856595396995544, 'eval_f1': 0.7769704518718427, 'eval_precision': 0.7609108159392789, 'eval_recall': 0.7937226070974127, 'eval_accuracy': 0.7769704518718427, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.77      0.84      0.80      4834\\n         ORG       0.73      0.66      0.70      4677\\n         PER       0.87      0.86      0.86      4635\\n\\n   micro avg       0.79      0.79      0.79     14146\\n   macro avg       0.79      0.79      0.79     14146\\nweighted avg       0.79      0.79      0.79     14146\\n', 'eval_runtime': 10.5918, 'eval_samples_per_second': 944.129, 'eval_steps_per_second': 39.37, 'epoch': 0.89, 'step': 744}\n",
            "{'loss': 0.3264, 'learning_rate': 3.465227817745804e-05, 'epoch': 0.92, 'step': 768}\n",
            "{'eval_loss': 0.27825742959976196, 'eval_f1': 0.7787586111399593, 'eval_precision': 0.763041856047758, 'eval_recall': 0.7951364343277252, 'eval_accuracy': 0.7787586111399593, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.77      0.82      0.79      4834\\n         ORG       0.75      0.68      0.71      4677\\n         PER       0.86      0.88      0.87      4635\\n\\n   micro avg       0.79      0.79      0.79     14146\\n   macro avg       0.79      0.79      0.79     14146\\nweighted avg       0.79      0.79      0.79     14146\\n', 'eval_runtime': 10.8444, 'eval_samples_per_second': 922.134, 'eval_steps_per_second': 38.453, 'epoch': 0.92, 'step': 768}\n",
            "{'loss': 0.2815, 'learning_rate': 3.41726618705036e-05, 'epoch': 0.95, 'step': 792}\n",
            "{'eval_loss': 0.2861168086528778, 'eval_f1': 0.7848224195338513, 'eval_precision': 0.770393572109492, 'eval_recall': 0.7998020641877562, 'eval_accuracy': 0.7848224195338513, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.81      0.81      4834\\n         ORG       0.70      0.73      0.72      4677\\n         PER       0.88      0.85      0.86      4635\\n\\n   micro avg       0.80      0.80      0.80     14146\\n   macro avg       0.80      0.80      0.80     14146\\nweighted avg       0.80      0.80      0.80     14146\\n', 'eval_runtime': 10.5727, 'eval_samples_per_second': 945.832, 'eval_steps_per_second': 39.441, 'epoch': 0.95, 'step': 792}\n",
            "{'loss': 0.2895, 'learning_rate': 3.369304556354916e-05, 'epoch': 0.98, 'step': 816}\n",
            "{'eval_loss': 0.2798776924610138, 'eval_f1': 0.7842320771739885, 'eval_precision': 0.770174482006543, 'eval_recall': 0.7988123851265375, 'eval_accuracy': 0.7842320771739885, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.80      0.80      0.80      4834\\n         ORG       0.73      0.72      0.73      4677\\n         PER       0.90      0.87      0.88      4635\\n\\n   micro avg       0.81      0.79      0.80     14146\\n   macro avg       0.81      0.79      0.80     14146\\nweighted avg       0.81      0.79      0.80     14146\\n', 'eval_runtime': 10.5603, 'eval_samples_per_second': 946.945, 'eval_steps_per_second': 39.488, 'epoch': 0.98, 'step': 816}\n",
            "{'loss': 0.3023, 'learning_rate': 3.321342925659472e-05, 'epoch': 1.01, 'step': 840}\n",
            "{'eval_loss': 0.2818475663661957, 'eval_f1': 0.7876415780541028, 'eval_precision': 0.7721561969439729, 'eval_recall': 0.8037607804326311, 'eval_accuracy': 0.7876415780541028, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.83      0.82      4834\\n         ORG       0.71      0.71      0.71      4677\\n         PER       0.88      0.86      0.87      4635\\n\\n   micro avg       0.80      0.80      0.80     14146\\n   macro avg       0.80      0.80      0.80     14146\\nweighted avg       0.80      0.80      0.80     14146\\n', 'eval_runtime': 10.804, 'eval_samples_per_second': 925.58, 'eval_steps_per_second': 38.597, 'epoch': 1.01, 'step': 840}\n",
            "{'loss': 0.2358, 'learning_rate': 3.273381294964029e-05, 'epoch': 1.04, 'step': 864}\n",
            "{'eval_loss': 0.2924128770828247, 'eval_f1': 0.7836420831876966, 'eval_precision': 0.7750276548672567, 'eval_recall': 0.7924501625901315, 'eval_accuracy': 0.7836420831876966, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.79      0.82      4834\\n         ORG       0.70      0.70      0.70      4677\\n         PER       0.88      0.88      0.88      4635\\n\\n   micro avg       0.81      0.79      0.80     14146\\n   macro avg       0.81      0.79      0.80     14146\\nweighted avg       0.81      0.79      0.80     14146\\n', 'eval_runtime': 10.5749, 'eval_samples_per_second': 945.635, 'eval_steps_per_second': 39.433, 'epoch': 1.04, 'step': 864}\n",
            "{'loss': 0.2819, 'learning_rate': 3.225419664268585e-05, 'epoch': 1.06, 'step': 888}\n",
            "{'eval_loss': 0.2861040532588959, 'eval_f1': 0.7761267260110746, 'eval_precision': 0.7695996663886572, 'eval_recall': 0.7827654460624912, 'eval_accuracy': 0.7761267260110746, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.80      0.81      4834\\n         ORG       0.77      0.63      0.69      4677\\n         PER       0.81      0.91      0.85      4635\\n\\n   micro avg       0.81      0.78      0.79     14146\\n   macro avg       0.80      0.78      0.79     14146\\nweighted avg       0.80      0.78      0.79     14146\\n', 'eval_runtime': 10.8463, 'eval_samples_per_second': 921.976, 'eval_steps_per_second': 38.446, 'epoch': 1.06, 'step': 888}\n",
            "{'loss': 0.2692, 'learning_rate': 3.177458033573142e-05, 'epoch': 1.09, 'step': 912}\n",
            "{'eval_loss': 0.29236340522766113, 'eval_f1': 0.775573053368329, 'eval_precision': 0.7679672881003534, 'eval_recall': 0.7833309769546162, 'eval_accuracy': 0.775573053368329, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.77      0.80      4834\\n         ORG       0.75      0.68      0.71      4677\\n         PER       0.82      0.89      0.85      4635\\n\\n   micro avg       0.80      0.78      0.79     14146\\n   macro avg       0.80      0.78      0.79     14146\\nweighted avg       0.80      0.78      0.79     14146\\n', 'eval_runtime': 10.63, 'eval_samples_per_second': 940.738, 'eval_steps_per_second': 39.229, 'epoch': 1.09, 'step': 912}\n",
            "{'loss': 0.2478, 'learning_rate': 3.129496402877698e-05, 'epoch': 1.12, 'step': 936}\n",
            "{'eval_loss': 0.29632699489593506, 'eval_f1': 0.7832967936420938, 'eval_precision': 0.759869732819354, 'eval_recall': 0.8082143362081153, 'eval_accuracy': 0.7832967936420938, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.79      0.85      0.82      4834\\n         ORG       0.72      0.68      0.70      4677\\n         PER       0.87      0.88      0.87      4635\\n\\n   micro avg       0.79      0.80      0.80     14146\\n   macro avg       0.79      0.80      0.80     14146\\nweighted avg       0.79      0.80      0.80     14146\\n', 'eval_runtime': 10.5557, 'eval_samples_per_second': 947.359, 'eval_steps_per_second': 39.505, 'epoch': 1.12, 'step': 936}\n",
            "{'loss': 0.2557, 'learning_rate': 3.081534772182254e-05, 'epoch': 1.15, 'step': 960}\n",
            "{'eval_loss': 0.295955628156662, 'eval_f1': 0.778266732912201, 'eval_precision': 0.7814281641961232, 'eval_recall': 0.7751307790188039, 'eval_accuracy': 0.778266732912201, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.73      0.77      4834\\n         ORG       0.73      0.71      0.72      4677\\n         PER       0.89      0.88      0.89      4635\\n\\n   micro avg       0.81      0.77      0.79     14146\\n   macro avg       0.81      0.77      0.79     14146\\nweighted avg       0.81      0.77      0.79     14146\\n', 'eval_runtime': 10.8023, 'eval_samples_per_second': 925.729, 'eval_steps_per_second': 38.603, 'epoch': 1.15, 'step': 960}\n",
            "{'loss': 0.3003, 'learning_rate': 3.0335731414868108e-05, 'epoch': 1.18, 'step': 984}\n",
            "{'eval_loss': 0.26561543345451355, 'eval_f1': 0.7862203083761633, 'eval_precision': 0.7726962457337884, 'eval_recall': 0.80022621235685, 'eval_accuracy': 0.7862203083761633, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.83      0.82      4834\\n         ORG       0.73      0.68      0.71      4677\\n         PER       0.88      0.87      0.87      4635\\n\\n   micro avg       0.81      0.80      0.80     14146\\n   macro avg       0.81      0.80      0.80     14146\\nweighted avg       0.81      0.80      0.80     14146\\n', 'eval_runtime': 10.5709, 'eval_samples_per_second': 945.996, 'eval_steps_per_second': 39.448, 'epoch': 1.18, 'step': 984}\n",
            "{'loss': 0.2254, 'learning_rate': 2.985611510791367e-05, 'epoch': 1.21, 'step': 1008}\n",
            "{'eval_loss': 0.2791295647621155, 'eval_f1': 0.8007381358587793, 'eval_precision': 0.7889536878216123, 'eval_recall': 0.8128799660681465, 'eval_accuracy': 0.8007381358587793, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.82      0.82      4834\\n         ORG       0.73      0.73      0.73      4677\\n         PER       0.88      0.88      0.88      4635\\n\\n   micro avg       0.82      0.81      0.81     14146\\n   macro avg       0.82      0.81      0.81     14146\\nweighted avg       0.82      0.81      0.81     14146\\n', 'eval_runtime': 10.6219, 'eval_samples_per_second': 941.447, 'eval_steps_per_second': 39.258, 'epoch': 1.21, 'step': 1008}\n",
            "{'loss': 0.2496, 'learning_rate': 2.9376498800959234e-05, 'epoch': 1.24, 'step': 1032}\n",
            "{'eval_loss': 0.27017897367477417, 'eval_f1': 0.7877469263710457, 'eval_precision': 0.7700877785280216, 'eval_recall': 0.8062349780856779, 'eval_accuracy': 0.7877469263710457, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.78      0.85      0.81      4834\\n         ORG       0.74      0.68      0.71      4677\\n         PER       0.88      0.89      0.89      4635\\n\\n   micro avg       0.80      0.81      0.80     14146\\n   macro avg       0.80      0.80      0.80     14146\\nweighted avg       0.80      0.81      0.80     14146\\n', 'eval_runtime': 10.8439, 'eval_samples_per_second': 922.173, 'eval_steps_per_second': 38.455, 'epoch': 1.24, 'step': 1032}\n",
            "{'loss': 0.2124, 'learning_rate': 2.8896882494004796e-05, 'epoch': 1.27, 'step': 1056}\n",
            "{'eval_loss': 0.2888476848602295, 'eval_f1': 0.7952280701754386, 'eval_precision': 0.7894663508429706, 'eval_recall': 0.8010745086950375, 'eval_accuracy': 0.7952280701754386, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.79      0.82      4834\\n         ORG       0.75      0.71      0.73      4677\\n         PER       0.85      0.89      0.87      4635\\n\\n   micro avg       0.82      0.80      0.81     14146\\n   macro avg       0.82      0.80      0.81     14146\\nweighted avg       0.82      0.80      0.81     14146\\n', 'eval_runtime': 10.6086, 'eval_samples_per_second': 942.628, 'eval_steps_per_second': 39.308, 'epoch': 1.27, 'step': 1056}\n",
            "{'loss': 0.2841, 'learning_rate': 2.841726618705036e-05, 'epoch': 1.29, 'step': 1080}\n",
            "{'eval_loss': 0.27612271904945374, 'eval_f1': 0.7945809703843731, 'eval_precision': 0.7870319001386963, 'eval_recall': 0.802276261840803, 'eval_accuracy': 0.7945809703843731, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.85      0.83      4834\\n         ORG       0.73      0.68      0.70      4677\\n         PER       0.89      0.87      0.88      4635\\n\\n   micro avg       0.82      0.80      0.81     14146\\n   macro avg       0.81      0.80      0.81     14146\\nweighted avg       0.81      0.80      0.81     14146\\n', 'eval_runtime': 10.601, 'eval_samples_per_second': 943.305, 'eval_steps_per_second': 39.336, 'epoch': 1.29, 'step': 1080}\n",
            "{'loss': 0.2517, 'learning_rate': 2.7937649880095922e-05, 'epoch': 1.32, 'step': 1104}\n",
            "{'eval_loss': 0.26594796776771545, 'eval_f1': 0.8026187491294052, 'eval_precision': 0.7909402882635552, 'eval_recall': 0.814647250106037, 'eval_accuracy': 0.8026187491294052, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.84      0.82      4834\\n         ORG       0.76      0.72      0.74      4677\\n         PER       0.88      0.88      0.88      4635\\n\\n   micro avg       0.82      0.81      0.82     14146\\n   macro avg       0.82      0.81      0.81     14146\\nweighted avg       0.82      0.81      0.81     14146\\n', 'eval_runtime': 10.8047, 'eval_samples_per_second': 925.522, 'eval_steps_per_second': 38.594, 'epoch': 1.32, 'step': 1104}\n",
            "{'loss': 0.2355, 'learning_rate': 2.745803357314149e-05, 'epoch': 1.35, 'step': 1128}\n",
            "{'eval_loss': 0.2680744528770447, 'eval_f1': 0.8002782124847853, 'eval_precision': 0.7875966869737833, 'eval_recall': 0.8133748055987559, 'eval_accuracy': 0.8002782124847853, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.82      0.82      4834\\n         ORG       0.75      0.72      0.74      4677\\n         PER       0.88      0.89      0.88      4635\\n\\n   micro avg       0.82      0.81      0.81     14146\\n   macro avg       0.82      0.81      0.81     14146\\nweighted avg       0.82      0.81      0.81     14146\\n', 'eval_runtime': 10.558, 'eval_samples_per_second': 947.148, 'eval_steps_per_second': 39.496, 'epoch': 1.35, 'step': 1128}\n",
            "{'loss': 0.2402, 'learning_rate': 2.697841726618705e-05, 'epoch': 1.38, 'step': 1152}\n",
            "{'eval_loss': 0.27014613151550293, 'eval_f1': 0.7991484312288416, 'eval_precision': 0.7892052112773144, 'eval_recall': 0.8093453979923654, 'eval_accuracy': 0.7991484312288416, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.81      0.82      4834\\n         ORG       0.73      0.73      0.73      4677\\n         PER       0.90      0.88      0.89      4635\\n\\n   micro avg       0.82      0.81      0.81     14146\\n   macro avg       0.82      0.81      0.81     14146\\nweighted avg       0.82      0.81      0.81     14146\\n', 'eval_runtime': 10.866, 'eval_samples_per_second': 920.302, 'eval_steps_per_second': 38.377, 'epoch': 1.38, 'step': 1152}\n",
            "{'loss': 0.2296, 'learning_rate': 2.6498800959232616e-05, 'epoch': 1.41, 'step': 1176}\n",
            "{'eval_loss': 0.2752807140350342, 'eval_f1': 0.7945757997218359, 'eval_precision': 0.781853017654304, 'eval_recall': 0.807719496677506, 'eval_accuracy': 0.7945757997218359, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.83      0.82      4834\\n         ORG       0.76      0.70      0.73      4677\\n         PER       0.86      0.88      0.87      4635\\n\\n   micro avg       0.81      0.81      0.81     14146\\n   macro avg       0.81      0.81      0.81     14146\\nweighted avg       0.81      0.81      0.81     14146\\n', 'eval_runtime': 10.6055, 'eval_samples_per_second': 942.907, 'eval_steps_per_second': 39.319, 'epoch': 1.41, 'step': 1176}\n",
            "{'loss': 0.2453, 'learning_rate': 2.6019184652278178e-05, 'epoch': 1.44, 'step': 1200}\n",
            "{'eval_loss': 0.26964476704597473, 'eval_f1': 0.8028973394623207, 'eval_precision': 0.7912148249828415, 'eval_recall': 0.8149300155520995, 'eval_accuracy': 0.8028973394623207, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.82      0.83      4834\\n         ORG       0.75      0.72      0.74      4677\\n         PER       0.87      0.89      0.88      4635\\n\\n   micro avg       0.82      0.81      0.82     14146\\n   macro avg       0.82      0.81      0.81     14146\\nweighted avg       0.82      0.81      0.81     14146\\n', 'eval_runtime': 10.6195, 'eval_samples_per_second': 941.666, 'eval_steps_per_second': 39.267, 'epoch': 1.44, 'step': 1200}\n",
            "{'loss': 0.2689, 'learning_rate': 2.5539568345323743e-05, 'epoch': 1.47, 'step': 1224}\n",
            "{'eval_loss': 0.2700394093990326, 'eval_f1': 0.7935933147632311, 'eval_precision': 0.781940441882805, 'eval_recall': 0.8055987558320373, 'eval_accuracy': 0.7935933147632311, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.83      0.82      4834\\n         ORG       0.76      0.70      0.73      4677\\n         PER       0.89      0.87      0.88      4635\\n\\n   micro avg       0.82      0.80      0.81     14146\\n   macro avg       0.82      0.80      0.81     14146\\nweighted avg       0.82      0.80      0.81     14146\\n', 'eval_runtime': 10.8716, 'eval_samples_per_second': 919.828, 'eval_steps_per_second': 38.357, 'epoch': 1.47, 'step': 1224}\n",
            "{'loss': 0.2362, 'learning_rate': 2.5059952038369304e-05, 'epoch': 1.5, 'step': 1248}\n",
            "{'eval_loss': 0.2705056369304657, 'eval_f1': 0.8027771903855642, 'eval_precision': 0.8004638740511667, 'eval_recall': 0.805103916301428, 'eval_accuracy': 0.8027771903855642, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.83      0.83      4834\\n         ORG       0.77      0.70      0.73      4677\\n         PER       0.90      0.88      0.89      4635\\n\\n   micro avg       0.83      0.80      0.82     14146\\n   macro avg       0.83      0.80      0.81     14146\\nweighted avg       0.83      0.80      0.81     14146\\n', 'eval_runtime': 10.5859, 'eval_samples_per_second': 944.649, 'eval_steps_per_second': 39.392, 'epoch': 1.5, 'step': 1248}\n",
            "{'loss': 0.226, 'learning_rate': 2.458033573141487e-05, 'epoch': 1.53, 'step': 1272}\n",
            "{'eval_loss': 0.26420360803604126, 'eval_f1': 0.8042397914856647, 'eval_precision': 0.7909631553763073, 'eval_recall': 0.8179697440972713, 'eval_accuracy': 0.8042397914856647, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.84      0.84      4834\\n         ORG       0.74      0.72      0.73      4677\\n         PER       0.86      0.89      0.87      4635\\n\\n   micro avg       0.81      0.82      0.81     14146\\n   macro avg       0.81      0.82      0.81     14146\\nweighted avg       0.81      0.82      0.81     14146\\n', 'eval_runtime': 10.591, 'eval_samples_per_second': 944.202, 'eval_steps_per_second': 39.373, 'epoch': 1.53, 'step': 1272}\n",
            "{'loss': 0.2139, 'learning_rate': 2.4100719424460434e-05, 'epoch': 1.55, 'step': 1296}\n",
            "{'eval_loss': 0.26896294951438904, 'eval_f1': 0.8012611665790856, 'eval_precision': 0.7942218209597889, 'eval_recall': 0.8084264102926623, 'eval_accuracy': 0.8012611665790856, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.86      0.78      0.82      4834\\n         ORG       0.72      0.76      0.74      4677\\n         PER       0.88      0.88      0.88      4635\\n\\n   micro avg       0.82      0.81      0.81     14146\\n   macro avg       0.82      0.81      0.81     14146\\nweighted avg       0.82      0.81      0.81     14146\\n', 'eval_runtime': 10.8548, 'eval_samples_per_second': 921.253, 'eval_steps_per_second': 38.416, 'epoch': 1.55, 'step': 1296}\n",
            "{'loss': 0.2744, 'learning_rate': 2.3621103117505996e-05, 'epoch': 1.58, 'step': 1320}\n",
            "{'eval_loss': 0.2619044780731201, 'eval_f1': 0.7999168773594707, 'eval_precision': 0.7841379778637876, 'eval_recall': 0.816343842782412, 'eval_accuracy': 0.7999168773594707, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.81      0.82      4834\\n         ORG       0.71      0.75      0.73      4677\\n         PER       0.88      0.88      0.88      4635\\n\\n   micro avg       0.81      0.81      0.81     14146\\n   macro avg       0.81      0.81      0.81     14146\\nweighted avg       0.81      0.81      0.81     14146\\n', 'eval_runtime': 10.5809, 'eval_samples_per_second': 945.099, 'eval_steps_per_second': 39.411, 'epoch': 1.58, 'step': 1320}\n",
            "{'loss': 0.2015, 'learning_rate': 2.314148681055156e-05, 'epoch': 1.61, 'step': 1344}\n",
            "{'eval_loss': 0.26398882269859314, 'eval_f1': 0.8066333356805859, 'eval_precision': 0.8035213243546577, 'eval_recall': 0.809769546161459, 'eval_accuracy': 0.8066333356805859, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.83      0.83      4834\\n         ORG       0.76      0.71      0.74      4677\\n         PER       0.89      0.88      0.89      4635\\n\\n   micro avg       0.83      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.8629, 'eval_samples_per_second': 920.567, 'eval_steps_per_second': 38.388, 'epoch': 1.61, 'step': 1344}\n",
            "{'loss': 0.1949, 'learning_rate': 2.2661870503597125e-05, 'epoch': 1.64, 'step': 1368}\n",
            "{'eval_loss': 0.2749839723110199, 'eval_f1': 0.8075423996629096, 'eval_precision': 0.8022744714993372, 'eval_recall': 0.8128799660681465, 'eval_accuracy': 0.8075423996629096, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.84      0.83      4834\\n         ORG       0.77      0.70      0.73      4677\\n         PER       0.90      0.88      0.89      4635\\n\\n   micro avg       0.83      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.5945, 'eval_samples_per_second': 943.884, 'eval_steps_per_second': 39.36, 'epoch': 1.64, 'step': 1368}\n",
            "{'loss': 0.2259, 'learning_rate': 2.2182254196642687e-05, 'epoch': 1.67, 'step': 1392}\n",
            "{'eval_loss': 0.2668905258178711, 'eval_f1': 0.8091645711092484, 'eval_precision': 0.7996686455888444, 'eval_recall': 0.8188887317969744, 'eval_accuracy': 0.8091645711092484, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.81      0.86      0.83      4834\\n         ORG       0.77      0.73      0.75      4677\\n         PER       0.89      0.86      0.88      4635\\n\\n   micro avg       0.82      0.82      0.82     14146\\n   macro avg       0.82      0.82      0.82     14146\\nweighted avg       0.82      0.82      0.82     14146\\n', 'eval_runtime': 10.5907, 'eval_samples_per_second': 944.225, 'eval_steps_per_second': 39.374, 'epoch': 1.67, 'step': 1392}\n",
            "{'loss': 0.1884, 'learning_rate': 2.170263788968825e-05, 'epoch': 1.7, 'step': 1416}\n",
            "{'eval_loss': 0.27294600009918213, 'eval_f1': 0.8060956384655807, 'eval_precision': 0.7990138204041948, 'eval_recall': 0.8133041142372402, 'eval_accuracy': 0.8060956384655807, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.83      0.83      4834\\n         ORG       0.75      0.73      0.74      4677\\n         PER       0.91      0.87      0.89      4635\\n\\n   micro avg       0.82      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.876, 'eval_samples_per_second': 919.453, 'eval_steps_per_second': 38.341, 'epoch': 1.7, 'step': 1416}\n",
            "{'loss': 0.1868, 'learning_rate': 2.1223021582733816e-05, 'epoch': 1.73, 'step': 1440}\n",
            "{'eval_loss': 0.2678537964820862, 'eval_f1': 0.8082901554404144, 'eval_precision': 0.8006658343736995, 'eval_recall': 0.8160610773363495, 'eval_accuracy': 0.8082901554404144, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.83      0.84      4834\\n         ORG       0.77      0.71      0.74      4677\\n         PER       0.86      0.89      0.88      4635\\n\\n   micro avg       0.83      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.6176, 'eval_samples_per_second': 941.833, 'eval_steps_per_second': 39.274, 'epoch': 1.73, 'step': 1440}\n",
            "{'loss': 0.2292, 'learning_rate': 2.0743405275779375e-05, 'epoch': 1.76, 'step': 1464}\n",
            "{'eval_loss': 0.265799343585968, 'eval_f1': 0.8055138719246205, 'eval_precision': 0.7954373147701427, 'eval_recall': 0.8158490032518027, 'eval_accuracy': 0.8055138719246205, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.83      0.83      4834\\n         ORG       0.76      0.73      0.74      4677\\n         PER       0.87      0.88      0.88      4635\\n\\n   micro avg       0.82      0.81      0.82     14146\\n   macro avg       0.82      0.81      0.82     14146\\nweighted avg       0.82      0.81      0.82     14146\\n', 'eval_runtime': 10.5828, 'eval_samples_per_second': 944.929, 'eval_steps_per_second': 39.404, 'epoch': 1.76, 'step': 1464}\n",
            "{'loss': 0.22, 'learning_rate': 2.026378896882494e-05, 'epoch': 1.78, 'step': 1488}\n",
            "{'eval_loss': 0.2609550654888153, 'eval_f1': 0.8065534661801853, 'eval_precision': 0.8005989692157682, 'eval_recall': 0.812597200622084, 'eval_accuracy': 0.8065534661801853, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.83      0.83      4834\\n         ORG       0.76      0.72      0.74      4677\\n         PER       0.89      0.87      0.88      4635\\n\\n   micro avg       0.83      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.858, 'eval_samples_per_second': 920.98, 'eval_steps_per_second': 38.405, 'epoch': 1.78, 'step': 1488}\n",
            "{'loss': 0.2335, 'learning_rate': 1.9784172661870504e-05, 'epoch': 1.81, 'step': 1512}\n",
            "{'eval_loss': 0.26128947734832764, 'eval_f1': 0.7996546961325967, 'eval_precision': 0.7816254894019171, 'eval_recall': 0.8185352749893963, 'eval_accuracy': 0.7996546961325967, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.79      0.87      0.83      4834\\n         ORG       0.77      0.68      0.72      4677\\n         PER       0.86      0.90      0.88      4635\\n\\n   micro avg       0.81      0.82      0.81     14146\\n   macro avg       0.81      0.82      0.81     14146\\nweighted avg       0.81      0.82      0.81     14146\\n', 'eval_runtime': 10.6147, 'eval_samples_per_second': 942.086, 'eval_steps_per_second': 39.285, 'epoch': 1.81, 'step': 1512}\n",
            "{'loss': 0.2379, 'learning_rate': 1.9304556354916066e-05, 'epoch': 1.84, 'step': 1536}\n",
            "{'eval_loss': 0.24951067566871643, 'eval_f1': 0.8081188533165934, 'eval_precision': 0.7974944933920705, 'eval_recall': 0.8190301145200056, 'eval_accuracy': 0.8081188533165934, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.83      0.83      4834\\n         ORG       0.77      0.73      0.75      4677\\n         PER       0.87      0.89      0.88      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.6189, 'eval_samples_per_second': 941.718, 'eval_steps_per_second': 39.27, 'epoch': 1.84, 'step': 1536}\n",
            "{'loss': 0.2394, 'learning_rate': 1.882494004796163e-05, 'epoch': 1.87, 'step': 1560}\n",
            "{'eval_loss': 0.26192358136177063, 'eval_f1': 0.8062593663959852, 'eval_precision': 0.7951467656561491, 'eval_recall': 0.8176869786512089, 'eval_accuracy': 0.8062593663959852, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.83      0.83      4834\\n         ORG       0.74      0.75      0.74      4677\\n         PER       0.91      0.86      0.88      4635\\n\\n   micro avg       0.82      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.823, 'eval_samples_per_second': 923.962, 'eval_steps_per_second': 38.529, 'epoch': 1.87, 'step': 1560}\n",
            "{'loss': 0.2526, 'learning_rate': 1.8345323741007196e-05, 'epoch': 1.9, 'step': 1584}\n",
            "{'eval_loss': 0.25016289949417114, 'eval_f1': 0.8116256295467263, 'eval_precision': 0.803198117125848, 'eval_recall': 0.8202318676657713, 'eval_accuracy': 0.8116256295467263, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.82      0.84      4834\\n         ORG       0.77      0.73      0.75      4677\\n         PER       0.86      0.90      0.88      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.6211, 'eval_samples_per_second': 941.522, 'eval_steps_per_second': 39.261, 'epoch': 1.9, 'step': 1584}\n",
            "{'loss': 0.2167, 'learning_rate': 1.7865707434052757e-05, 'epoch': 1.93, 'step': 1608}\n",
            "{'eval_loss': 0.25282523036003113, 'eval_f1': 0.813414422241529, 'eval_precision': 0.7999863285255315, 'eval_recall': 0.8273010038173335, 'eval_accuracy': 0.813414422241529, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.86      0.84      4834\\n         ORG       0.75      0.73      0.74      4677\\n         PER       0.88      0.89      0.88      4635\\n\\n   micro avg       0.82      0.82      0.82     14146\\n   macro avg       0.82      0.82      0.82     14146\\nweighted avg       0.82      0.82      0.82     14146\\n', 'eval_runtime': 10.9251, 'eval_samples_per_second': 915.326, 'eval_steps_per_second': 38.169, 'epoch': 1.93, 'step': 1608}\n",
            "{'loss': 0.2354, 'learning_rate': 1.7386091127098322e-05, 'epoch': 1.96, 'step': 1632}\n",
            "{'eval_loss': 0.24489927291870117, 'eval_f1': 0.8099433606041535, 'eval_precision': 0.8012589928057554, 'eval_recall': 0.8188180404354588, 'eval_accuracy': 0.8099433606041535, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.84      0.84      4834\\n         ORG       0.75      0.72      0.74      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.6573, 'eval_samples_per_second': 938.327, 'eval_steps_per_second': 39.128, 'epoch': 1.96, 'step': 1632}\n",
            "{'loss': 0.2808, 'learning_rate': 1.6906474820143887e-05, 'epoch': 1.99, 'step': 1656}\n",
            "{'eval_loss': 0.24693657457828522, 'eval_f1': 0.8067454798331014, 'eval_precision': 0.7938278363213357, 'eval_recall': 0.82009048494274, 'eval_accuracy': 0.8067454798331014, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.82      0.83      4834\\n         ORG       0.76      0.74      0.75      4677\\n         PER       0.88      0.89      0.89      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.6739, 'eval_samples_per_second': 936.867, 'eval_steps_per_second': 39.067, 'epoch': 1.99, 'step': 1656}\n",
            "{'loss': 0.1924, 'learning_rate': 1.6426858513189448e-05, 'epoch': 2.01, 'step': 1680}\n",
            "{'eval_loss': 0.24866801500320435, 'eval_f1': 0.8076736279747451, 'eval_precision': 0.792983651226158, 'eval_recall': 0.8229181394033649, 'eval_accuracy': 0.8076736279747451, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.85      0.83      4834\\n         ORG       0.75      0.72      0.74      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.82      0.82      0.82     14146\\n   macro avg       0.82      0.82      0.82     14146\\nweighted avg       0.82      0.82      0.82     14146\\n', 'eval_runtime': 10.8482, 'eval_samples_per_second': 921.813, 'eval_steps_per_second': 38.44, 'epoch': 2.01, 'step': 1680}\n",
            "{'loss': 0.1498, 'learning_rate': 1.5947242206235013e-05, 'epoch': 2.04, 'step': 1704}\n",
            "{'eval_loss': 0.2618604302406311, 'eval_f1': 0.8127004042938799, 'eval_precision': 0.8015261927677713, 'eval_recall': 0.8241905839106461, 'eval_accuracy': 0.8127004042938799, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.84      0.84      4834\\n         ORG       0.73      0.75      0.74      4677\\n         PER       0.90      0.88      0.89      4635\\n\\n   micro avg       0.82      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.6061, 'eval_samples_per_second': 942.853, 'eval_steps_per_second': 39.317, 'epoch': 2.04, 'step': 1704}\n",
            "{'loss': 0.2, 'learning_rate': 1.5467625899280578e-05, 'epoch': 2.07, 'step': 1728}\n",
            "{'eval_loss': 0.2590464949607849, 'eval_f1': 0.8132974446813717, 'eval_precision': 0.8044395270036651, 'eval_recall': 0.8223526085112399, 'eval_accuracy': 0.8132974446813717, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.85      0.84      4834\\n         ORG       0.77      0.71      0.74      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.6247, 'eval_samples_per_second': 941.199, 'eval_steps_per_second': 39.248, 'epoch': 2.07, 'step': 1728}\n",
            "{'loss': 0.151, 'learning_rate': 1.4988009592326141e-05, 'epoch': 2.1, 'step': 1752}\n",
            "{'eval_loss': 0.2622966468334198, 'eval_f1': 0.8066032807439139, 'eval_precision': 0.7949474840392668, 'eval_recall': 0.8186059663509119, 'eval_accuracy': 0.8066032807439139, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.85      0.84      4834\\n         ORG       0.75      0.71      0.73      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.82      0.82      0.82     14146\\n   macro avg       0.82      0.82      0.82     14146\\nweighted avg       0.82      0.82      0.82     14146\\n', 'eval_runtime': 10.8845, 'eval_samples_per_second': 918.74, 'eval_steps_per_second': 38.311, 'epoch': 2.1, 'step': 1752}\n",
            "{'loss': 0.1646, 'learning_rate': 1.4508393285371703e-05, 'epoch': 2.13, 'step': 1776}\n",
            "{'eval_loss': 0.26323202252388, 'eval_f1': 0.8186481169196178, 'eval_precision': 0.8137309680122922, 'eval_recall': 0.8236250530185212, 'eval_accuracy': 0.8186481169196178, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.86      0.83      0.84      4834\\n         ORG       0.76      0.74      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.82      0.83     14146\\n   macro avg       0.84      0.82      0.83     14146\\nweighted avg       0.84      0.82      0.83     14146\\n', 'eval_runtime': 10.6187, 'eval_samples_per_second': 941.732, 'eval_steps_per_second': 39.27, 'epoch': 2.13, 'step': 1776}\n",
            "{'loss': 0.1659, 'learning_rate': 1.4028776978417266e-05, 'epoch': 2.16, 'step': 1800}\n",
            "{'eval_loss': 0.2561187148094177, 'eval_f1': 0.8187727145652782, 'eval_precision': 0.8096060815480304, 'eval_recall': 0.828149300155521, 'eval_accuracy': 0.8187727145652782, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.86      0.84      4834\\n         ORG       0.76      0.74      0.75      4677\\n         PER       0.90      0.89      0.89      4635\\n\\n   micro avg       0.83      0.83      0.83     14146\\n   macro avg       0.83      0.83      0.83     14146\\nweighted avg       0.83      0.83      0.83     14146\\n', 'eval_runtime': 10.8434, 'eval_samples_per_second': 922.217, 'eval_steps_per_second': 38.456, 'epoch': 2.16, 'step': 1800}\n",
            "{'loss': 0.1888, 'learning_rate': 1.3549160671462829e-05, 'epoch': 2.19, 'step': 1824}\n",
            "{'eval_loss': 0.25492382049560547, 'eval_f1': 0.813630333077299, 'eval_precision': 0.8038079470198676, 'eval_recall': 0.8236957443800368, 'eval_accuracy': 0.813630333077299, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.86      0.83      0.84      4834\\n         ORG       0.75      0.74      0.75      4677\\n         PER       0.87      0.89      0.88      4635\\n\\n   micro avg       0.83      0.82      0.83     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.5592, 'eval_samples_per_second': 947.041, 'eval_steps_per_second': 39.492, 'epoch': 2.19, 'step': 1824}\n",
            "{'loss': 0.2084, 'learning_rate': 1.3069544364508394e-05, 'epoch': 2.22, 'step': 1848}\n",
            "{'eval_loss': 0.2556668817996979, 'eval_f1': 0.8141412722932173, 'eval_precision': 0.8086901938903612, 'eval_recall': 0.8196663367736463, 'eval_accuracy': 0.8141412722932173, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.82      0.85      0.84      4834\\n         ORG       0.78      0.71      0.74      4677\\n         PER       0.90      0.88      0.89      4635\\n\\n   micro avg       0.83      0.82      0.83     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.5962, 'eval_samples_per_second': 943.732, 'eval_steps_per_second': 39.354, 'epoch': 2.22, 'step': 1848}\n",
            "{'loss': 0.1571, 'learning_rate': 1.2589928057553957e-05, 'epoch': 2.24, 'step': 1872}\n",
            "{'eval_loss': 0.2697077691555023, 'eval_f1': 0.814959667562943, 'eval_precision': 0.8052584362707887, 'eval_recall': 0.8248974975258023, 'eval_accuracy': 0.814959667562943, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.85      0.84      4834\\n         ORG       0.74      0.76      0.75      4677\\n         PER       0.92      0.86      0.89      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.83     14146\\nweighted avg       0.83      0.82      0.83     14146\\n', 'eval_runtime': 10.8452, 'eval_samples_per_second': 922.068, 'eval_steps_per_second': 38.45, 'epoch': 2.24, 'step': 1872}\n",
            "{'loss': 0.1541, 'learning_rate': 1.211031175059952e-05, 'epoch': 2.27, 'step': 1896}\n",
            "{'eval_loss': 0.26053106784820557, 'eval_f1': 0.8191183684911346, 'eval_precision': 0.8121178432462479, 'eval_recall': 0.8262406333945992, 'eval_accuracy': 0.8191183684911346, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.86      0.85      4834\\n         ORG       0.77      0.72      0.74      4677\\n         PER       0.89      0.90      0.89      4635\\n\\n   micro avg       0.83      0.82      0.83     14146\\n   macro avg       0.83      0.82      0.83     14146\\nweighted avg       0.83      0.82      0.83     14146\\n', 'eval_runtime': 10.6459, 'eval_samples_per_second': 939.327, 'eval_steps_per_second': 39.17, 'epoch': 2.27, 'step': 1896}\n",
            "{'loss': 0.1586, 'learning_rate': 1.1630695443645085e-05, 'epoch': 2.3, 'step': 1920}\n",
            "{'eval_loss': 0.27420565485954285, 'eval_f1': 0.8108526586198402, 'eval_precision': 0.8073015205661832, 'eval_recall': 0.8144351760214902, 'eval_accuracy': 0.8108526586198402, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.84      0.84      4834\\n         ORG       0.76      0.73      0.74      4677\\n         PER       0.91      0.86      0.89      4635\\n\\n   micro avg       0.83      0.81      0.82     14146\\n   macro avg       0.83      0.81      0.82     14146\\nweighted avg       0.83      0.81      0.82     14146\\n', 'eval_runtime': 10.5781, 'eval_samples_per_second': 945.351, 'eval_steps_per_second': 39.421, 'epoch': 2.3, 'step': 1920}\n",
            "{'loss': 0.1641, 'learning_rate': 1.1151079136690648e-05, 'epoch': 2.33, 'step': 1944}\n",
            "{'eval_loss': 0.26786988973617554, 'eval_f1': 0.8148486659401695, 'eval_precision': 0.8104328368645549, 'eval_recall': 0.8193128799660682, 'eval_accuracy': 0.8148486659401695, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.85      0.84      4834\\n         ORG       0.76      0.72      0.74      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.83      0.82      0.82     14146\\n   macro avg       0.83      0.82      0.82     14146\\nweighted avg       0.83      0.82      0.82     14146\\n', 'eval_runtime': 10.8071, 'eval_samples_per_second': 925.314, 'eval_steps_per_second': 38.586, 'epoch': 2.33, 'step': 1944}\n",
            "{'loss': 0.1914, 'learning_rate': 1.0671462829736211e-05, 'epoch': 2.36, 'step': 1968}\n",
            "{'eval_loss': 0.2596113979816437, 'eval_f1': 0.815910676901605, 'eval_precision': 0.8055670387212347, 'eval_recall': 0.8265233988406616, 'eval_accuracy': 0.815910676901605, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.86      0.85      4834\\n         ORG       0.76      0.72      0.74      4677\\n         PER       0.88      0.89      0.89      4635\\n\\n   micro avg       0.83      0.82      0.83     14146\\n   macro avg       0.83      0.82      0.83     14146\\nweighted avg       0.83      0.82      0.83     14146\\n', 'eval_runtime': 10.5558, 'eval_samples_per_second': 947.347, 'eval_steps_per_second': 39.504, 'epoch': 2.36, 'step': 1968}\n",
            "{'loss': 0.1441, 'learning_rate': 1.0191846522781776e-05, 'epoch': 2.39, 'step': 1992}\n",
            "{'eval_loss': 0.2644413411617279, 'eval_f1': 0.8182681151777239, 'eval_precision': 0.8139469818843114, 'eval_recall': 0.8226353739573025, 'eval_accuracy': 0.8182681151777239, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.84      0.85      4834\\n         ORG       0.77      0.73      0.75      4677\\n         PER       0.89      0.88      0.89      4635\\n\\n   micro avg       0.84      0.82      0.83     14146\\n   macro avg       0.84      0.82      0.83     14146\\nweighted avg       0.84      0.82      0.83     14146\\n', 'eval_runtime': 10.5658, 'eval_samples_per_second': 946.449, 'eval_steps_per_second': 39.467, 'epoch': 2.39, 'step': 1992}\n",
            "{'loss': 0.1672, 'learning_rate': 9.71223021582734e-06, 'epoch': 2.42, 'step': 2016}\n",
            "{'eval_loss': 0.26520049571990967, 'eval_f1': 0.8180009077261461, 'eval_precision': 0.8080982272194247, 'eval_recall': 0.828149300155521, 'eval_accuracy': 0.8180009077261461, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.84      0.84      4834\\n         ORG       0.77      0.75      0.76      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.83      0.83      0.83     14146\\n   macro avg       0.83      0.83      0.83     14146\\nweighted avg       0.83      0.83      0.83     14146\\n', 'eval_runtime': 10.8087, 'eval_samples_per_second': 925.182, 'eval_steps_per_second': 38.58, 'epoch': 2.42, 'step': 2016}\n",
            "{'loss': 0.1852, 'learning_rate': 9.232613908872901e-06, 'epoch': 2.45, 'step': 2040}\n",
            "{'eval_loss': 0.2575770914554596, 'eval_f1': 0.8205289233130975, 'eval_precision': 0.8100716450812896, 'eval_recall': 0.8312597200622084, 'eval_accuracy': 0.8205289233130975, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.87      0.85      4834\\n         ORG       0.77      0.73      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.83      0.83      0.83     14146\\n   macro avg       0.83      0.83      0.83     14146\\nweighted avg       0.83      0.83      0.83     14146\\n', 'eval_runtime': 10.5642, 'eval_samples_per_second': 946.598, 'eval_steps_per_second': 39.473, 'epoch': 2.45, 'step': 2040}\n",
            "{'loss': 0.192, 'learning_rate': 8.752997601918466e-06, 'epoch': 2.47, 'step': 2064}\n",
            "{'eval_loss': 0.24589473009109497, 'eval_f1': 0.8178777955828049, 'eval_precision': 0.80625, 'eval_recall': 0.8298458928318959, 'eval_accuracy': 0.8178777955828049, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.85      0.84      4834\\n         ORG       0.77      0.74      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.83      0.83      0.83     14146\\n   macro avg       0.83      0.83      0.83     14146\\nweighted avg       0.83      0.83      0.83     14146\\n', 'eval_runtime': 10.8894, 'eval_samples_per_second': 918.321, 'eval_steps_per_second': 38.294, 'epoch': 2.47, 'step': 2064}\n",
            "{'loss': 0.1698, 'learning_rate': 8.273381294964029e-06, 'epoch': 2.5, 'step': 2088}\n",
            "{'eval_loss': 0.24823561310768127, 'eval_f1': 0.8212807743564564, 'eval_precision': 0.8149359688195991, 'eval_recall': 0.8277251519864273, 'eval_accuracy': 0.8212807743564564, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.86      0.85      4834\\n         ORG       0.79      0.72      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5605, 'eval_samples_per_second': 946.927, 'eval_steps_per_second': 39.487, 'epoch': 2.5, 'step': 2088}\n",
            "{'loss': 0.1802, 'learning_rate': 7.793764988009592e-06, 'epoch': 2.53, 'step': 2112}\n",
            "{'eval_loss': 0.25189176201820374, 'eval_f1': 0.8155475549652207, 'eval_precision': 0.8066099702689622, 'eval_recall': 0.8246854234412555, 'eval_accuracy': 0.8155475549652207, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.87      0.85      4834\\n         ORG       0.79      0.70      0.74      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.83      0.82      0.83     14146\\n   macro avg       0.83      0.82      0.83     14146\\nweighted avg       0.83      0.82      0.83     14146\\n', 'eval_runtime': 10.5669, 'eval_samples_per_second': 946.354, 'eval_steps_per_second': 39.463, 'epoch': 2.53, 'step': 2112}\n",
            "{'loss': 0.1619, 'learning_rate': 7.314148681055157e-06, 'epoch': 2.56, 'step': 2136}\n",
            "{'eval_loss': 0.25815367698669434, 'eval_f1': 0.817506078499479, 'eval_precision': 0.8036055722480197, 'eval_recall': 0.831895942315849, 'eval_accuracy': 0.817506078499479, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.85      0.84      4834\\n         ORG       0.75      0.75      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.83      0.83      0.83     14146\\n   macro avg       0.83      0.83      0.83     14146\\nweighted avg       0.83      0.83      0.83     14146\\n', 'eval_runtime': 10.8405, 'eval_samples_per_second': 922.469, 'eval_steps_per_second': 38.467, 'epoch': 2.56, 'step': 2136}\n",
            "{'loss': 0.1974, 'learning_rate': 6.83453237410072e-06, 'epoch': 2.59, 'step': 2160}\n",
            "{'eval_loss': 0.2534659206867218, 'eval_f1': 0.8183759935571974, 'eval_precision': 0.8107958093387914, 'eval_recall': 0.826099250671568, 'eval_accuracy': 0.8183759935571974, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.83      0.86      0.85      4834\\n         ORG       0.78      0.71      0.75      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.84      0.82      0.83     14146\\n   macro avg       0.83      0.82      0.83     14146\\nweighted avg       0.83      0.82      0.83     14146\\n', 'eval_runtime': 10.6455, 'eval_samples_per_second': 939.364, 'eval_steps_per_second': 39.171, 'epoch': 2.59, 'step': 2160}\n",
            "{'loss': 0.1655, 'learning_rate': 6.3549160671462825e-06, 'epoch': 2.62, 'step': 2184}\n",
            "{'eval_loss': 0.2513743042945862, 'eval_f1': 0.8229477153978328, 'eval_precision': 0.8165054623895345, 'eval_recall': 0.8294924360243179, 'eval_accuracy': 0.8229477153978328, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.84      0.85      4834\\n         ORG       0.77      0.74      0.76      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.6182, 'eval_samples_per_second': 941.776, 'eval_steps_per_second': 39.272, 'epoch': 2.62, 'step': 2184}\n",
            "{'loss': 0.1844, 'learning_rate': 5.875299760191847e-06, 'epoch': 2.65, 'step': 2208}\n",
            "{'eval_loss': 0.25358372926712036, 'eval_f1': 0.8207540546233237, 'eval_precision': 0.8152022315202232, 'eval_recall': 0.8263820161176304, 'eval_accuracy': 0.8207540546233237, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.85      0.85      4834\\n         ORG       0.77      0.73      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.82      0.83     14146\\n   macro avg       0.84      0.82      0.83     14146\\nweighted avg       0.84      0.82      0.83     14146\\n', 'eval_runtime': 10.8385, 'eval_samples_per_second': 922.634, 'eval_steps_per_second': 38.474, 'epoch': 2.65, 'step': 2208}\n",
            "{'loss': 0.1601, 'learning_rate': 5.3956834532374105e-06, 'epoch': 2.68, 'step': 2232}\n",
            "{'eval_loss': 0.25306642055511475, 'eval_f1': 0.8194051239033938, 'eval_precision': 0.8103698582786035, 'eval_recall': 0.8286441396861304, 'eval_accuracy': 0.8194051239033938, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.85      0.85      4834\\n         ORG       0.76      0.73      0.75      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5571, 'eval_samples_per_second': 947.229, 'eval_steps_per_second': 39.499, 'epoch': 2.68, 'step': 2232}\n",
            "{'loss': 0.161, 'learning_rate': 4.916067146282974e-06, 'epoch': 2.71, 'step': 2256}\n",
            "{'eval_loss': 0.2507703900337219, 'eval_f1': 0.8226320025193324, 'eval_precision': 0.814452989676436, 'eval_recall': 0.830976954616146, 'eval_accuracy': 0.8226320025193324, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.86      0.85      4834\\n         ORG       0.78      0.73      0.75      4677\\n         PER       0.88      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.8445, 'eval_samples_per_second': 922.127, 'eval_steps_per_second': 38.453, 'epoch': 2.71, 'step': 2256}\n",
            "{'loss': 0.1672, 'learning_rate': 4.436450839328538e-06, 'epoch': 2.73, 'step': 2280}\n",
            "{'eval_loss': 0.25267547369003296, 'eval_f1': 0.8215773444883957, 'eval_precision': 0.8137438457804591, 'eval_recall': 0.8295631273858335, 'eval_accuracy': 0.8215773444883957, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.84      0.85      4834\\n         ORG       0.77      0.74      0.76      4677\\n         PER       0.88      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5917, 'eval_samples_per_second': 944.137, 'eval_steps_per_second': 39.371, 'epoch': 2.73, 'step': 2280}\n",
            "{'loss': 0.2053, 'learning_rate': 3.956834532374101e-06, 'epoch': 2.76, 'step': 2304}\n",
            "{'eval_loss': 0.24815170466899872, 'eval_f1': 0.8208173244848063, 'eval_precision': 0.8112399889533278, 'eval_recall': 0.8306234978085678, 'eval_accuracy': 0.8208173244848063, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.86      0.85      4834\\n         ORG       0.78      0.73      0.75      4677\\n         PER       0.89      0.90      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5687, 'eval_samples_per_second': 946.192, 'eval_steps_per_second': 39.456, 'epoch': 2.76, 'step': 2304}\n",
            "{'loss': 0.1776, 'learning_rate': 3.4772182254196645e-06, 'epoch': 2.79, 'step': 2328}\n",
            "{'eval_loss': 0.24863524734973907, 'eval_f1': 0.8214686098654709, 'eval_precision': 0.8142797610779275, 'eval_recall': 0.8287855224091616, 'eval_accuracy': 0.8214686098654709, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.86      0.85      4834\\n         ORG       0.78      0.73      0.75      4677\\n         PER       0.89      0.90      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.8396, 'eval_samples_per_second': 922.54, 'eval_steps_per_second': 38.47, 'epoch': 2.79, 'step': 2328}\n",
            "{'loss': 0.1559, 'learning_rate': 2.997601918465228e-06, 'epoch': 2.82, 'step': 2352}\n",
            "{'eval_loss': 0.24945463240146637, 'eval_f1': 0.823331699460822, 'eval_precision': 0.8156215316315205, 'eval_recall': 0.8311890287006928, 'eval_accuracy': 0.823331699460822, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.86      0.85      4834\\n         ORG       0.78      0.73      0.76      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.635, 'eval_samples_per_second': 940.29, 'eval_steps_per_second': 39.21, 'epoch': 2.82, 'step': 2352}\n",
            "{'loss': 0.1509, 'learning_rate': 2.5179856115107916e-06, 'epoch': 2.85, 'step': 2376}\n",
            "{'eval_loss': 0.2472381889820099, 'eval_f1': 0.8230728893550079, 'eval_precision': 0.8141641883947714, 'eval_recall': 0.8321787077619115, 'eval_accuracy': 0.8230728893550079, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.84      0.86      0.85      4834\\n         ORG       0.78      0.73      0.76      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.579, 'eval_samples_per_second': 945.266, 'eval_steps_per_second': 39.418, 'epoch': 2.85, 'step': 2376}\n",
            "{'loss': 0.1695, 'learning_rate': 2.0383693045563552e-06, 'epoch': 2.88, 'step': 2400}\n",
            "{'eval_loss': 0.24647079408168793, 'eval_f1': 0.8228882833787466, 'eval_precision': 0.8133977900552486, 'eval_recall': 0.8326028559310052, 'eval_accuracy': 0.8228882833787466, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.86      0.85      4834\\n         ORG       0.78      0.73      0.75      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.8486, 'eval_samples_per_second': 921.774, 'eval_steps_per_second': 38.438, 'epoch': 2.88, 'step': 2400}\n",
            "{'loss': 0.1523, 'learning_rate': 1.5587529976019186e-06, 'epoch': 2.91, 'step': 2424}\n",
            "{'eval_loss': 0.24657461047172546, 'eval_f1': 0.8233811690584529, 'eval_precision': 0.8154464780920688, 'eval_recall': 0.8314717941467553, 'eval_accuracy': 0.8233811690584529, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.86      0.85      4834\\n         ORG       0.78      0.73      0.75      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5916, 'eval_samples_per_second': 944.145, 'eval_steps_per_second': 39.371, 'epoch': 2.91, 'step': 2424}\n",
            "{'loss': 0.1525, 'learning_rate': 1.0791366906474822e-06, 'epoch': 2.94, 'step': 2448}\n",
            "{'eval_loss': 0.24777860939502716, 'eval_f1': 0.8241473492541495, 'eval_precision': 0.8165417707466001, 'eval_recall': 0.831895942315849, 'eval_accuracy': 0.8241473492541495, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.86      0.85      4834\\n         ORG       0.78      0.74      0.76      4677\\n         PER       0.88      0.90      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.8795, 'eval_samples_per_second': 919.164, 'eval_steps_per_second': 38.329, 'epoch': 2.94, 'step': 2448}\n",
            "{'loss': 0.1386, 'learning_rate': 5.995203836930456e-07, 'epoch': 2.96, 'step': 2472}\n",
            "{'eval_loss': 0.24858742952346802, 'eval_f1': 0.8235706278026906, 'eval_precision': 0.816363383803306, 'eval_recall': 0.8309062632546302, 'eval_accuracy': 0.8235706278026906, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.85      0.85      4834\\n         ORG       0.78      0.74      0.76      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5879, 'eval_samples_per_second': 944.477, 'eval_steps_per_second': 39.385, 'epoch': 2.96, 'step': 2472}\n",
            "{'loss': 0.1532, 'learning_rate': 1.199040767386091e-07, 'epoch': 2.99, 'step': 2496}\n",
            "{'eval_loss': 0.24873991310596466, 'eval_f1': 0.8236654056326187, 'eval_precision': 0.8163449520899875, 'eval_recall': 0.8311183373391772, 'eval_accuracy': 0.8236654056326187, 'eval_classification_report': '              precision    recall  f1-score   support\\n\\n         LOC       0.85      0.85      0.85      4834\\n         ORG       0.78      0.74      0.76      4677\\n         PER       0.89      0.89      0.89      4635\\n\\n   micro avg       0.84      0.83      0.83     14146\\n   macro avg       0.84      0.83      0.83     14146\\nweighted avg       0.84      0.83      0.83     14146\\n', 'eval_runtime': 10.5909, 'eval_samples_per_second': 944.211, 'eval_steps_per_second': 39.374, 'epoch': 2.99, 'step': 2496}\n",
            "{'train_runtime': 1297.3455, 'train_samples_per_second': 46.248, 'train_steps_per_second': 1.929, 'total_flos': 1178415902403696.0, 'train_loss': 0.26952576098872794, 'epoch': 3.0, 'step': 2502}\n"
          ]
        }
      ]
    }
  ]
}